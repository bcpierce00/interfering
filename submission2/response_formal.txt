** Overview **

We thank the reviewers for their comments. The reviews identify 
some areas that the paper fails to explain adequately.
None of these issues are in the formalism itself, but meta questions: How does
the work improve on existing formalizations of stack safety? Do we have a plan to validate the model further?
Can our work be extended to cover more complex uses of the stack? We have answers to these questions, and we can
address them explicitly in the paper.

** Changes **

1. We will give a more thorough discussion of validation, discuss the feasibility of proofs
   and of randomized testing of more complex properties, and detail our roadmap for
   further validation of different versions of the property.

2. We will give an explicit, direct comparison to the work of Skorstengaard et. al. Currently
   we discuss it briefly in our related work section, but our novelty has not been
   obvious, so we will be more thorough in explaining the differences.

3. We will improve the presentation as suggested. We need to gradually
   introduce the examples and associated intuition (including our
   visual metaphors) as early as possible, starting in the
   introduction.

4. Our model avoids talking about language features other than the stack, but it is unclear at times
   whether those features could be added without compromising stack safety. We will more clearly call out
   common language features, such as heaps, that are compatible with stack safety.

[SNA: Do we want to promise to add callee-saves registers? I wasn't going to at first, but actually there's
      a good story here. Something like:]
5. We will add a discussion of how to extend the model to a callee-saves registers convention, which
   demonstrates a concrete use for observational properties and a clear advance over the state-of-the-art.

** Detailed Comments **

* Reviewer A *

We will extend the paper with a more detailed discussion of our roadmap for verification and
testing, and the issues that we expect to arise. Here is a rough
outline of how it would cover your concerns.

> ...discussion on whether it is feasible/desirable/in-progress/etc. to prove enforcement mechanisms correct.

These properties would absolutely be amenable to a correctness proof. Such a
proof would be a lot of work in a setting with a full ISA, but we see no
fundamental barriers.  We chose to concentrate on testing because it
is better aligned with our immediate goal of evaluating enforcement
mechanisms to uncover possible bugs -- it is lower effort, but if bugs are
found, still high reward.

> * The testing for the lazy tagging/clearing found mistakes but the "potential fix [is] itself a prime candidate for future testing" [line 868]
>
> * Any validation for the lazier observability definition (this is listed as future work.)^M
>
> * Any validation for the coroutine work.

At present we are working to implement
testing of observable properties, and to apply this to the putatively fixed version of the lazy tagging/clearing micro-policy.
Observational integrity testing is implemented, but observational confidentiality testing is not -- since the lazy policy enforces
normal, stepwise confidentiality this is sufficient to test it. [APT: Do we have the results of these tests?] But we did not have this ready before
the deadline. 

Our other immediate priority is to implement testing of a secondary enforcement mechanism. We will evaluate a Cheri
implementation of stack safety to demonstrate that our properties are not strictly tied to tag-based
enforcement. We are currently working on the QuickChick generators for Cheri programs, which have a
different calling convention -- a more complicated one, which is easier to get wrong.

Validation of the argument-passing and coroutining models are longer-term priorities.
The passing system has existing enforcement mechanisms and serves an important role in common stack
use-cases. Coroutines will require the development of an enforcement
mechanism (e.g., one based on tags) to validate.

> There is one topic beyond my evaluation above worth considering: callee-save registers.
> I fear these may be fairly tricky to support in your set-up.  Upon function entry, callee-save
> registers hold data private to the caller that may be passed arbitrarily deeper into the call stack,
> then saved into arbitrary stack locations, but then must be restored before return.
> Have you or the closely related prior work on enforcement mechanisms considered this complexity?
> The invariants are clear enough informally, but the issue seems to add substantial difficulty to
> tracking that a function faithfully implements the calling convention.

Callee-save registers are compatible with our approach, using a version of the sharing model
with its context initialization and updates modified to apply appropriate domains to registers.
They actually provide another use-case for observational properties! Focusing on integrity:
callee-save registers may be overwritten (violating stepwise integrity) but should always be
restored before a return. This requirement corresponds to observational integrity with the
callee-save registers sealed -- recall that observational integrity compares sealed
components at the start and end of a callee, so the interim changes are not violations.

Confidentiality can be applied similarly. A callee-save register should be secret, but
in observational confidentiality, if it is copied to the stack and then restored before
return, the property will allow the original register to be read normally after return.
But the property will not allow it to be leaked in any other way.

We had briefly considered adding this complexity and chosen to avoid it, because it is an extra layer
of detail to apply domains to registers. It is worth noting that the primary existing work in this
area, Skorstengaard et al., relies on a calling convention which clears all non-argument registers before
calls and all non-return registers before returns.


> Another minor question: The difference between [nested] call-by-reference and passing
> address-of-local was interesting, but I'm not sure how much it makes sense to argue the
> latter is "beyond the scope of stack safety per se" [line 939] without arguing the same
> of the former.  Perhaps the argument can be made that address-of-local can be put in the
> heap while a by-reference parameter cannot and since you don't guarantee heap safety,
> you shouldn't try to do anything useful with address-of-local?

Yes, this was exactly our thinking.  
We know what constitutes legal access to stack-allocated arguments, but for explicit pointers
this is much less clear, and depends on the intent of the programmer. We believe
an address-of-local should be treated similarly to the address of a heap object,
but with a different lifetime. For instance, if a heap safety model treats heap pointers like capabilities
(possession implies access rights), we would treat stack pointers the same.
Similarly, if the heap model permits pointer forging (restricted to
within compartments, say) we would expect to be able to forge pointers to address-taken locals
in the same circumstances. 

In the longer term we would like to extend our model with a heap, in the style of
Azevedo de Amorim et al.'s "The Meaning of Memory Safety," which is phrased in similar
terms to our model and should be compatible. Then the interplay between heap-derived and
stack-derived pointers (with similar behaviors but different lifespans) will
be much more interesting.

* Reviewer B *

> Q1. How does this work improve upon Skorstengaard et al? Neither the introduction nor related work section give a satisfying answer to this.^M

We improve upon Skorstengaard et. al. in the following ways.
1. We capture a desireable security characteristic of dynamically nested calls, that every caller is safe from its callee
2. We therefore do not assume a static division of trusted and untrusted code

Specifically, Skorstengaard et. al. divide the world into trusted functions, which feature
additional dynamic constraints on their behavior, and for which their properties hold,
and adversaries, which may violate the dynamic "reasonableness" constraints. Suppose we
have a single function that recursively traverses a linked list, loading data into local
memory. What if it has a bug, and certain data cause it to violate the reasonableness condition?
In Skorstengaard's model, it must be an adversary, and activations lower in the stack are not
guaranteed protection. In our model, only the badly behaved activation is an attacker, and its
caller(s) are guaranteed protection.

3. Skorstengaard's approach to proving safety via fully-abstract overlay semantics relies on the abstract
machine being architecturally similar to the concrete one (beyond the specific call and return semantics
that distinguish them). Therefore it is less portable: each architecture it applies to wants its own
abstract machine. Our properties should apply directly to a wide range of
architectures. 

We also differ from Skorstengaard et. al. in our focus. We use the language of formal security properties
to apply the established intuitions and formal techniques of non-interference. This demonstrates that stack
safety is expressible as a formal security property.

> Q2. In L117-121 you state certain assumptions about the language semantics. It is unclear to me if these assumptions restrict the languages to which your stack safety definition apply. For example, does a language with a heap allow you to break stack safety? What about a language with delimited continuations that manipulate the stack?^M

Our stack safety model applies regardless of how a language uses non-stack,
non-code memory, so it works for languages with a heap. It applies to any layout of memory as long as that is
known statically.

Delimited continuations are not supported by our base model, so a language that has them would violate
stack safety. We extend the base model with argument passing on the stack to demonstrate how it can
accommodate a programming language feature that shares stack data between callers and callees. A
similar extension to delimited continuations would be more complex.

This distinction, between a feature that could be added without changing the properties and one that
would require enhanced properties, is important, and we will clarify in section 2 which features fall
into which category.

> Q3. Why don't you assume well-bracketed control flow like Skorstengaard et al (L289-291)? What are the implications of that?

We want our properties to be applicable even to low-level code that may not keep function
footprints isolated from one another. Consider a program that mixes C code with hand-written
assembly -- the assembly may make calls and returns, which should be protected by stack safety,
as well as arbitrary jumps, which should not.

* Reviewer C *

> - It is a bit difficult to assess the merits of this work. Yes, the
>   stack safety property is important for security, but what new results
>   or new capabilities does the proposed definition bring in?

A formal definition of a type of security is valuable in its own right. It tells us whether
any given behavior is a violation, and we can therefore use it to identify bugs. In our case
study we identify a previously unknown bug in Roessler and Dehon's proposed "lazy tagging" micro-policy,
and also use randomized testing to increase confidence that their "depth isolation" micro-policy
correctly implements stack safety.

More broadly, it gives us the ability to reason
clearly about what is gained from applying a given enforcement mechanism to a system. Since
many enforcement mechanisms are quite costly in speed, dollars, and silicon, it is important
to understand precisely what they buy us.

>   The paper does not talk about data flow
>   across heap and stack, which is an important element for many
>   real-world memory corruption attacks.

We plan to combine our stack model with a heap model in the style of Acevedo de Amorim et al.
as future work.

> - The paper is titled "stack safety is a security property". I don't
>   see why this is surprising, or what's the novelty here. Memory safety
>   is almost always connected with security properties.

We agree that the title is confusing and should be changed. It refers to a concept in 
theoretical security: a formal notion of security property as a mathematical description of
the possible behaviors of a system. In that context, it was not actually obvious that stack
safety could be defined in these terms, but now we have done so. That said, the title should
not require readers to understand this specific terminology to be comprehensible.

