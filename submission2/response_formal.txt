# Overview

We thank the reviewers for their comments.

The reviews identify some areas that the paper fails to explain
adequately -- in particular, "framing" questions: How does the work improve
on existing formalizations of stack safety? Do we have a plan to validate
the model further?  Can our work be extended to cover more complex uses of
the stack?

In the next section, we outline the changes we plan to make in the paper to
clarify these questions.  We discuss the issues in more detail in the third
section.

## Changes

1. We will give a more thorough discussion of validation, discuss the
   feasibility of proofs and of randomized testing of more complex
   properties, and detail our roadmap for further validation of different
   versions of the property.

2. We will give a more explicit and direct comparison to the work of
   Skorstengaard et. al. Currently we discuss it briefly in our related work
   section, but the novelty of our work does not come through clearly
   enough; we will explain the differences more thoroughly. [LEO: I think
   we need a forward pointer here to make sure reviewers B+C see this.]

3. We will improve the presentation as suggested. In particular, we will
   gradually introduce the examples and associated intuitions (including our
   visual metaphors) as early as possible, starting in the introduction.

4. We will more clearly call out common language features, such as the heap,
   that are compatible with our treatment of stack safety.

5. [SNA: Do we want to promise to add callee-saves registers? I wasn't going to
   at first, but actually there's a good story here. Something like:] [BCP: If
   we think we can really do this, we should say so!]
   We will add a discussion of how to extend the model to a callee-saves
   registers convention, which demonstrates a concrete use for the observational
   properties.
   [BCP: Doesn't the current draft also demonstrate a use for the observational
   properties?][LEO: I think the current motivation is efficiency in the
   paper - this would tie things together beautifully IMO - and we can say
   we left it out due to space/complexity concerns but that in retrospect
   putting it in paints a more complete picture.]

# Detailed Comments

## Reviewer A

We will extend the paper with a more detailed discussion of our roadmap for
verification and testing and the issues that we expect to arise. Here is a
rough outline of how it would cover the concerns raised in the review.

> ...discussion on whether it is feasible/desirable/in-progress/etc. to prove enforcement mechanisms correct.

The formal security properties we define would absolutely be amenable to a
correctness proof. Such a proof would be considerable work to carry out for
a full ISA like RISC-V, but we see no fundamental barriers.  We chose to
concentrate on testing because it is better aligned with our immediate goal
of evaluating real enforcement mechanisms for real machine architectures.

> * The testing for the lazy tagging/clearing found mistakes but the "potential fix [is] itself a prime candidate for future testing" [line 868]
>
> * Any validation for the lazier observability definition (this is listed as future work.)^M
>
> * Any validation for the coroutine work.

We are working to implement testing of observable properties and to apply
this to the putatively fixed version of the lazy tagging/clearing
micro-policy.  At the moment, testing of observational integrity is
implemented; observational confidentiality testing is not, but -- since the
lazy policy enforces normal, stepwise confidentiality -- this is actually
sufficient to test it. [APT: Do we have the results of these tests?][BCP: +1
-- if we could actually say something about results it would be fantastic!]
But we did not have this ready before the deadline. [BCP: IIRC, we have not
been forbidden from mentioning new results that we would include in the
final paper if accepted, and IMO there is little risk of annoying the
reviewers if we mention them in response to direct criticisms or questions.]

Our other short-term plan is to implement testing of a second enforcement
mechanism -- a Cheri implementation of stack safety -- to demonstrate that
our properties are not strictly tied to tag-based enforcement. We are
currently working on QuickChick generators for Cheri programs, which
have a different calling convention (a more complicated one, which is easier
to get wrong!).  [BCP: We should probably add something like: "But this
effort falls outside the scope of the current paper" to make clear that we
are not promising it.][LEO: Agreed.]

Validation of the argument-passing and coroutine models are longer-term
projects.  The argument-passing model has existing enforcement mechanisms and serves
an important role in common stack use cases. Coroutines will require the
development of an enforcement mechanism (e.g., one based on tags) to
validate.

> There is one topic beyond my evaluation above worth considering:
> callee-save registers.  I fear these may be fairly tricky to support in
> your set-up.  Upon function entry, callee-save registers hold data private
> to the caller that may be passed arbitrarily deeper into the call stack,
> then saved into arbitrary stack locations, but then must be restored
> before return.  Have you or the closely related prior work on enforcement
> mechanisms considered this complexity?  The invariants are clear enough
> informally, but the issue seems to add substantial difficulty to tracking
> that a function faithfully implements the calling convention.

Callee-save registers are compatible with our approach, using a version of
the sharing model with its context initialization and updates modified to
apply appropriate domains to registers.  Indeed, they actually provide
another interesting use case for the "observational" variants of our
properties. Focusing on integrity: callee-save registers may be overwritten
(violating stepwise integrity) but should always be restored before a
return. This requirement corresponds to observational integrity with the
callee-save registers sealed. (Recall that observational integrity compares
sealed components at the start and end of a callee's execution, so the
interim changes are not violations.)

Confidentiality for callee-saves is similar. A callee-save register should
be secret, but in observational confidentiality, if it is copied to the
stack and then restored before return, the property will allow the original
register to be read normally after return.  But the property will not allow
it to be leaked in any other way.

We had considered adding this complexity and chosen to avoid it, because it
is an extra layer of detail to apply domains to registers.  [BCP: Don't
understand this.  Maybe just drop it and say we will add this discussion to
the paper?  Or do we even want to say that we think we can extend the model
and our testing framework to callee-saves before the camera-ready?... My
sense is that this is too much work, but either way we should say (again)
what we plan to do.][LEO: The point I guess is that now we're only applying
domains on stack addresses, while this would require domains over arbitrary
components (including registers). I don't think it's particularly hard to
do, just an extra layer of complexity.]

It is worth noting that the main prior work in this area by Skorstengaard et
al. relies [BCP: fundamentally?] on a calling convention that clears all
non-argument registers before calls and all non-return registers before
returns.

> Another minor question: The difference between [nested] call-by-reference
> and passing address-of-local was interesting, but I'm not sure how much it
> makes sense to argue the latter is "beyond the scope of stack safety per
> se" [line 939] without arguing the same of the former.  Perhaps the
> argument can be made that address-of-local can be put in the heap while a
> by-reference parameter cannot and since you don't guarantee heap safety,
> you shouldn't try to do anything useful with address-of-local?

Yes, this was exactly our thinking.  We know what constitutes legal access
to stack-allocated arguments, but for explicit pointers this is much less
clear, and depends on the intent of the programmer. We believe an
address-of-local should be treated similarly to the address of a heap
object, but with a different lifetime. For instance, if a heap safety model
treats heap pointers like capabilities (possession implies access rights),
we would treat stack pointers the same.  Similarly, if the heap model
permits pointer forging (restricted to within compartments, say) we would
expect to be able to forge pointers to address-taken locals in the same
circumstances.

In the longer term we would like to extend our model with a heap, in the
style of Azevedo de Amorim et al.'s "The Meaning of Memory Safety," POST 2018,
which is phrased in similar terms to our model and should be compatible. In this
setting the interplay between heap-derived and stack-derived pointers (with
similar behaviors but different lifespans) will be much more interesting.

## Reviewer B

> Q1. How does this work improve upon Skorstengaard et al? Neither the
> introduction nor related work section give a satisfying answer to this.

We improve upon Skorstengaard et. al. in the following ways.

1. We capture a desireable security characteristic of dynamically nested
   calls: that EVERY caller should be protected from its callee.

   By contrast, Skorstengaard et. al. statically divide the world into
   trusted functions, which feature additional dynamic constraints on their
   behavior and for which their properties hold, and adversary functions,
   which may violate the dynamic "reasonableness" constraints.

   For example, suppose we have a single function that recursively traverses
   a linked list, loading data into local memory. What if it has a bug, and
   certain data cause it to violate the reasonableness condition?  In
   Skorstengaard's model, it must be an adversary, and activations lower in
   the stack are not guaranteed protection. In our model, only the badly
   behaved activation is an attacker, and its caller(s) are guaranteed
   protection.  [BCP: Not clear enough -- Indeed, I think the example might
   be too subtle.] [LEO: "We will expand on such an example in the revised
   version"?]
   [RB: This part also read confusingly to me. What needs to be made clear, I
   think, is that in the world of StkTokens one needs to establish a boundary
   separating trusted and untrusted components, but the reasonability conditions
   on which trusted components rely is dynamic -- it might be approximated
   statically, but we could shoot ourselves in the foot in a way the model can
   do nothing about.]

2. Skorstengaard's approach to proving safety via fully abstract overlay
   semantics relies on the abstract machine being architecturally similar to
   the concrete one (beyond the specific call and return semantics that
   distinguish them). This makes it less portable: each architecture it
   applies to wants its own abstract machine. Our properties should apply
   directly to a wide range of architectures.

   We also differ from Skorstengaard et. al. in our focus. We use the
   language of formal security properties to apply established intuitions
   and formal techniques of non-interference.

> Q2. In L117-121 you state certain assumptions about the language
> semantics. It is unclear to me if these assumptions restrict the languages
> to which your stack safety definition apply. For example, does a language
> with a heap allow you to break stack safety? What about a language with
> delimited continuations that manipulate the stack?

Our stack safety model applies regardless of how a language uses non-stack,
non-code memory, so it works for languages with a heap.  It also applies to
any layout of memory (that is known statically).

Delimited continuations are not supported by our base model, so a language
that has them would violate stack safety. We do extend the base model with
argument passing on the stack to demonstrate how it can accommodate a
language feature that shares stack data between callers and callees, but a
similar extension to delimited continuations would be more complex.

This distinction -- between features that could be added without changing
the properties and ones that would require enhanced properties -- is
important, and we will clarify in section 2 which features fall into which
category.  [BCP: Can we say anything here about what that categorization
would look like?]

> Q3. Why don't you assume well-bracketed control flow like Skorstengaard et
> al (L289-291)? What are the implications of that?

We want our properties to be applicable even to low-level code that may not
keep function footprints isolated from one another. [BCP: Not clear what
footprints have to do with well-bracketing...] For example, consider a
program that mixes C code with hand-written assembly: the assembly may make
calls and returns, which should be protected by stack safety, as well as
arbitrary jumps, which should not. [LEO: I also don't fully follow this
answer]

## Reviewer C

> - It is a bit difficult to assess the merits of this work. Yes, the
>   stack safety property is important for security, but what new results
>   or new capabilities does the proposed definition bring in?

First, we contend that a formal definition of stack safety is valuable in
its own right, as a way of shifting the discussion away from specific
examples of bad behavior that must be prevented and toward general
mechanisms that ensure good behavior.  A formal definition gives us the
ability to reason clearly about what is gained from applying a given
enforcement mechanism to a system. Since many enforcement mechanisms are
quite costly in speed, dollars, and/or silicon, it is important to
understand precisely what they buy us.

More immediately, we can use a formal definition like this to test proposed
enforecement mechanisms for violations of the policy.  In our case study, we
identify a previously unknown bug in Roessler and Dehon's proposed "lazy
tagging" micro-policy, and we use randomized testing to increase confidence
that their "depth isolation" micro-policy correctly implements stack safety.

>   The paper does not talk about data flow
>   across heap and stack, which is an important element for many
>   real-world memory corruption attacks.

Agreed!  We plan to combine our stack model with a heap model in the style
of Azevedo de Amorim et al. as future work.  Both models are phrased in the
conceptual terminology of language-based security, so we have reason to
believe that they will fit together cleanly.

> - The paper is titled "stack safety is a security property". I don't
>   see why this is surprising, or what's the novelty here. Memory safety
>   is almost always connected with security properties.

In hindsight, our choice of title was confusing: We did not just mean that
stack safety impacts security (which is obvious), but that it can usefully
be formulated using (a refinement of) the same formal terminology and
mathematical definitions -- confidentiality, integrity, noninterference,
etc. -- that have been used for decades to reason about security.

We'll think of a more helpful title.
[BCP: Any ideas?][LEO: s/is/as]
