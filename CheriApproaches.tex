\documentclass{article}

\usepackage{geometry}

\begin{document}

This document deals with questions of the division between machine state and policy state.
In existing models of our security properties, the state is divided into a machine state,
which is a mapping from addresses and registers to data, and a policy state, which may be
any arbitrary data. A machine state can step on its own, or in conjunction with a policy
state; when states step together the machine state component always steps as it would on
its own. A policy state may only cause the step to fail outright, never change the result.

We are faced with the task of deciding 1) which parts of an architecture should be treated
as machine, and which parts as policy; 2) what is to be done with the policy state in the
context of confidentiality properties; and 3) whether there are parts of the machine state
that ought to be treated differently in such properties.

We will discuss these ideas in terms of three enforcement mechanisms:

\begin{itemize}
\item HOPE
\item Cheri
\item A software-based mechanism such as SFI
\end{itemize}

\section{What if we eliminate Policy States?}

Let's start by considering what a system would look like that doesn't use policy state. The
simplest such model simply makes the machine transition function partial, with failure to step
indicating a fail-stop. Here the enforcement is built directly into the machine. This applies to
our three enforcement mechanisms as follows.

\paragraph*{HOPE} The machine contains both ordinary registers and memory, and tag registers and memory.
The transition function is parameterized by a tag rule table, and we must be careful to construct the model
such that tags only be read and updated as described by the table. Fail-stops should occur only on tag
rule failures.

\paragraph*{Cheri} The machine contains ordinary registers and memory, with some effort needed to model
the extra space that capabilities take up. (Either words need to be larger to fit capabilities, or we
need to model them being spread across multiple words.) It also contains the map of 1-bit tags marking
capabilities as valid. The ISA is extended with the Cheri operations and the transition function handles
the valid-capability tags appropriately. Here a fail-stop occurs whenever the Cheri architecture would
trap to a failstate, mostly when reading or writing through an invalid capability or outside of a
valid capability's authority.

\paragraph*{Software} Here the machine gets to be completely unchanged, and never failstops. Instead
we restrict the set of initial states to those whose code comes from the compiler with the appropriate
modifications, and it will simply never violate the policy - any errors will take it to some error
state where it silently diverges, which is perfectly allowed.

\paragraph*{Implications for confidentiality} If everything lives in the machine state, then
we need to think about what it means to vary it to create a confidentiality property. Take the HOPE
example: does a variant include states with different tags, such that either the primary
trace failstops and the variant does not, or the variant does and the primary does not? Similarly,
in Cheri, do we vary the valid-capability bit? What about bounds information?

We can pretty firmly say that we do not need to vary tags, including the capability bit. That's
because these can never be read, and therefore it is meaningless to talk about their confidentiality.
But the bounds information in Cheri presents a bigger problem. We will revisit it as we start moving
policy data out of the machine.

\section{Separate Policy States}

We have identified some kinds of data that can never be read and serve exclusively to inform
the enforcement mechanism. We can think of data as having two meanings, its ``application content'' and its
``security content.'' In HOPE, the distinction seems clear: tags have only security content, never application.
So we can justify separating out security-only data into a separate part of the state, from which it cannot
escape and therefore does not need to be varied to support confidentiality. Let's discuss how that
works in HOPE and Cheri (in software methods, of course, everything has application content.)

\paragraph*{HOPE} In HOPE, we put all tags in the policy state, along with any policy-specific machinery such as
counters that give us the fresh tags. The machine step function can now be total, with failure only
coming from the policy step function. But it turns out that some machine data still has security content.
Consider a load instruction: its tag rule must take into account the tag at the target address, which
means that the policy step function must be aware of the machine state.

This gives us the same question of what we do in confidentiality with variant states that fail-stop
when the original didn't.

\paragraph*{Cheri} In Cheri, the valid-capability bit has no application content, so these can live in
the policy state. But the application content of a capability is its bitwise value. We might argue
that actually the base and offset are application content, while permissions and bounds information
are security-only, but it is not feasible to separate the latter from the former. Even if we did, the
base and bounds would give us the same issues as HOPE pointers.

\paragraph*{Implications} The primary implication is that we no longer need to worry about what happens
if we vary tags, whether that's the full HOPE tag or the 1-bit Cheri tag. But that doesn't save us
from sometimes varying security content, because pointer values still have security content. In both systems,
if we read a valid pointer that is supposed to be secret and then dereference it, there is a variant run
in which the pointer is invalid and the variant fail-stops. This will always be the case no matter how we
separate machine and policy.

The advantages that we do get by separating them as much as possible are: it's easier to model the separate
state than if we built it into the machine architecture, which matters more for HOPE but is a small concern for
Cheri. And depending on how we handle these variant fail-stops, it may be more efficient to test if fewer of
them occur.

\section{Handling Variations in Security Content}

Either way the question becomes: should the variant trace be one with a policy active, or no? Let's
look at a concrete example.

\begin{verbatim}
main() {
  int[2] x = {0,0};
  int* y = &x+secret();
  f(&x);
}

f() {
  int** z = guess_y_addr();
  print(z**);
}
\end{verbatim}

Here {\tt main} has an array {\tt x} and saves a pointer to one of its elements, but which one is secret.
Then it passes the address to  {\tt f}, so that {\tt f} can access {\tt x} legally according to sharing.
{\tt x} has a tag that marks it permissible for anyone to access it, but {\tt f} has actually accessed {\tt x}
via reading the hidden information in {\tt y}. Suppose that our policy contains an error such that the access
of {\tt y} is successful - then {\tt f} always ends up printing 0 regardless, so we haven't violated
confidentiality. But we would if we printed {\tt y} outright or if the values in {\tt x[0]} and
{\tt x[1]} differed.

Consider the variant states that we can have. {\tt x} does not vary, but {\tt y} can point to {\tt x[0]},
{\tt x[1]}, or a location beyond {\tt x} entirely. In the first two cases, our output is 0,
so confidentiality is maintained. What do we do with that case? We can:

\begin{enumerate}
\item Recognize that the variant should fail-stop, and treat that as a violation
\item Recognize that the variant should fail-stop, and ignore this variant
\item Do not check for a variant fail-stop, and therefore likely get a violation
\end{enumerate}

I argue for option 2, because either some other variation that doesn't create an illegal pointer
will be a violation, or the particular trace has not leaked any information. In this case,
the error will be detected if we ever run the comparable case where {\tt x = {0,1}}, but if the compiler
somehow only produced traces where this issue is invisible, we need not consider it. Still, option 1
could be fine, since our policies are meant to prevent {\tt y} from being read in the first place.

Option 3 is clearly bad because if the contents of {\tt y} are used in some other way, its behavior
could be radically different from the primary trace. Whether it fails or not is virtually unrelated to
the initial potential violation. This seems very bad.

Considering the same situation in Cheri, we also have the possibility to get additional tag failures
by varying not just the address pointed to, but the permissions bits on a capability. But the fundamental
question remains the same: what to do with fail-stop variants.

\section{Cheri Implementation}

In order to implement Cheri we'll need to make a couple of changes. First of all, we need to extend the model
with capability instructions and preferably add some capability-sized registers. It will be tedious aligning
capabilities properly in memory; could we instead take a shortcut by just making words capability-sized, and
only reading half of them for non-capabilities? We need at the very least cap-load, cap-store, arithmetic,
and the instructions to derive capabilities from the ambient capabilities (esp. stack capability). Currently
looking into just how much we can strip out and still have it work.

The policy state will be the mapping from addresses/registers to their capability bits. Capability instructions
will maintain the mapping as appropriate. Certain operations will fail-stop based on violating that mapping.

\end{document}
