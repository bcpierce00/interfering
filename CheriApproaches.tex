\documentclass{article}

\usepackage{geometry}

\begin{document}

This document deals with questions of the division between machine state and policy state.
In existing models of our security properties, the state is divided into a machine state,
which is a mapping from addresses and registers to data, and a policy state, which may be
any arbitrary data. A machine state can step on its own, or in conjunction with a policy
state; when states step together the machine state component always steps as it would on
its own. A policy state may only cause the step to fail outright, never change the result.

We are faced with the task of deciding 1) which parts of an architecture should be treated
as machine, and which parts as policy; 2) what is to be done with the policy state in the
context of confidentiality properties; and 3) whether there are parts of the machine state
that ought to be treated differently in such properties.

We will discuss these ideas in terms of three enforcement mechanisms:

\begin{itemize}
\item HOPE
\item Cheri
\item A software-based mechanism such as SFI
\end{itemize}

\section{What if we eliminate Policy States?}

Let's start by considering what a system would look like that doesn't use policy state. The
simplest such model simply makes the machine transition function partial, with failure to step
indicating a fail-stop. Here the enforcement is built directly into the machine. This applies to
our three enforcement mechanisms as follows.

\paragraph*{HOPE} The machine contains both ordinary registers and memory, and tag registers and memory.
The transition function is parameterized by a tag rule table, and we must be careful to construct the model
such that tags only be read and updated as described by the table. Fail-stops should occur only on tag
rule failures.

\paragraph*{Cheri} The machine contains ordinary registers and memory, with some effort needed to model
the extra space that capabilities take up. (Either words need to be larger to fit capabilities, or we
need to model them being spread across multiple words.) It also contains the map of 1-bit tags marking
capabilities as valid. The ISA is extended with the Cheri operations and the transition function handles
the valid-capability tags appropriately. Here a fail-stop occurs whenever the Cheri architecture would
trap to a failstate, mostly when reading or writing through an invalid capability or outside of a
valid capability's authority.

\paragraph*{Software} Here the machine gets to be completely unchanged, and never failstops. Instead
we restrict the set of initial states to those whose code comes from the compiler with the appropriate
modifications, and it will simply never violate the policy - any errors will take it to some error
state where it silently diverges, which is perfectly allowed.

\paragraph*{Implications for confidentiality} If everything lives in the machine state, then
we need to think about what it means to vary it to create a confidentiality property. Take the HOPE
example: does a variant include states with different tags, such that either the primary
trace failstops and the variant does not, or the variant does and the primary does not? Similarly,
in Cheri, do we vary the valid-capability bit? What about bounds information?

We can pretty firmly say that we do not need to vary tags, including the capability bit. That's
because these can never be read, and therefore it is meaningless to talk about their confidentiality.
But the bounds information in Cheri presents a bigger problem. We will revisit it as we start moving
policy data out of the machine.

\section{Separate Policy States}

We have identified some kinds of data that can never be read and serve exclusively to inform
the enforcement mechanism. We can think of data as having two meanings, its ``application content'' and its
``security content.'' In HOPE, the distinction seems clear: tags have only security content, never application.
So we can justify separating out security-only data into a separate part of the state, from which it cannot
escape and therefore does not need to be varied to support confidentiality. Let's discuss how that
works in HOPE and Cheri (in software methods, of course, everything has application content.)

\paragraph*{HOPE} In HOPE, we put all tags in the policy state, along with any policy-specific machinery such as
counters that give us the fresh tags. The machine step function can now be total, with failure only
coming from the policy step function. But it turns out that some machine data still has security content.
Consider a load instruction: its tag rule must take into account the tag at the target address, which
means that the policy step function must be aware of the machine state.

This gives us the same question of what we do in confidentiality with variant states that fail-stop
when the original didn't.

\paragraph*{Cheri} In Cheri, the valid-capability bit has no application content, so these can live in
the policy state. But the application content of a capability is its bitwise value. We might argue
that actually the base and offset are application content, while permissions and bounds information
are security-only, but it is not feasible to separate the latter from the former. Even if we did, the
base and bounds would give us the same issues as HOPE pointers.

\paragraph*{Implications} The primary implication is that we no longer need to worry about what happens
if we vary tags, whether that's the full HOPE tag or the 1-bit Cheri tag. But that doesn't save us
from sometimes varying security content, because pointer values still have security content. In both systems,
if we read a valid pointer that is supposed to be secret and then dereference it, there is a variant run
in which the pointer is invalid and the variant fail-stops. This will always be the case no matter how we
separate machine and policy.

The advantages that we do get by separating them as much as possible are: it's easier to model the separate
state than if we built it into the machine architecture, which matters more for HOPE but is a small concern for
Cheri. And depending on how we handle these variant fail-stops, it may be more efficient to test if fewer of
them occur.

\section{Handling Variations in Security Content}

Lets consider a very simple machine with three addresses and an external feed of instructions
(instructions are not in memory.) An address can be marked either secret or public. Let's start with
the following configuration (top rows are addresses marked S or P, bottom are contents):

\begin{tabular}{| c | c | c |}
  \hline
  0(S) & 1(P) & 2(P) \\
  \hline
  0 & 0 & 0 \\
  \hline
\end{tabular}

We have a register \(r\), initialized to 0, and an output {\sc Out} that can be loaded to like a register.
We want to apply our confidentiality model by varying secret locations and determining if programs
differ in output between the original state and a variant. I'm using the simplified format from our
examples in the paper. Assume that loads use the address modulo three so that the step operation is
total. Consider the program:

\vspace{\abovedisplayskip}

\begin{tabular}{l l l}
  Line & Instr & Description \\
  \hline
  1 & \(r \leftarrow [0]\) & Load from address 0 \\
  2 & {\sc Out} \(\leftarrow [r]\) & Load from the resulting address and output it \\
  3 & \(r \leftarrow 0\) & Reset \(r\) to 0 \\
\end{tabular}

\vspace{\belowdisplayskip}

At the end of this program, 0 has been printed. In any variant when address 0 mods to a 1 or a 2, it
will also print 0. And since the final instruction clears \(r\), the final state is identical as well.
So we would not say that this program violates confidentiality of address 0, even though it was read.

Now suppose that we also make address 1 secret. The variation might vary both 0 and 1, so that the
program reads address 1 and outputs a non-zero result. Now, confidentiality is violated, because this
variation produces a different output. Suppose we consider some possible security properties to
prevent this from occurring. The property we come up with attaches to the load instruction and,
if the source register contains an address that is marked secret, fail-stops the machine. But we forget
to implement a similar rule for loading through immediate values, oops! So the load on line 1 never failstops.
Let's look at that second start state and the same program:

\begin{tabular}{| c | c | c |}
  \hline
  0(S) & 1(S) & 2(P) \\
  \hline
  0 & 0 & 0 \\
  \hline
\end{tabular}

Now the primary execution will load from address 0, then attempt to do so again and fail-stop. The variant
might instead try to read from a different location, but we are termination insensitive, so even if it reads
from 2 (successfully) the property holds. But what about this start state?

\begin{tabular}{| c | c | c |}
  \hline
  0(S) & 1(S) & 2(P) \\
  \hline
  2 & 0 & 0 \\
  \hline
\end{tabular}

Here the primary execution loads from 2 and prints 0. But a variant in which address 0 holds 0 or 1 will
load from those addresses, which would violate the policy and cause a failstop. So the question is, how do
we handle those variants? We can:

\begin{enumerate}
\item Recognize that the variant should fail-stop, and since the primary execution does not,
  treat that as a violation.
\item Recognize that the variant should fail-stop, and since we are termination insensitive,
  treat that as acceptable and look for another variant that actually produces different output.
\item Do not check whether the variant fail-stops. So when we vary address 0 to 1 and address 1 to 1,
  the program prints 1. Thus the property is violated.
\end{enumerate}

Options 1 and 2, in testing, will let us stop short and either move on to a different test or
declare a failure. Option 1 seems at odds with the notion of termination-insensitivity; so does option 3
in its own way, with the added downside that it's hard to predict whether a given case might fail. Option
2 is similar to only doing variants that maintain the legality of pointers. I've been leaning toward option
2, and I tend not to like option 3 because our variant run can show behavior that is infeasible in the
target machine.

This small example illustrates a scenario that can come up in HOPE and Cheri, when pointers and capabilities
being varied introduces fail-stop behavior in the variant trace when none was present in the primary. This
is an edge case, of course, because in any such scenario the program could instead print the pointer and thus
violate the property immediately. But we do need to decide how to approach it. We could imagine a policy that
prevents printing the pointer directly (via taint-tracking, say) but does not prevent dereferencing it.

\section{Cheri Implementation}

In order to implement Cheri we'll need to make a couple of changes. First of all, we need to extend the model
with capability instructions and preferably add some capability-sized registers. It will be tedious aligning
capabilities properly in memory; could we instead take a shortcut by just making words capability-sized, and
only reading half of them for non-capabilities? We need at the very least cap-load, cap-store, arithmetic,
and the instructions to derive capabilities from the ambient capabilities (esp. stack capability). Currently
looking into just how much we can strip out and still have it work.

The policy state will be the mapping from addresses/registers to their capability bits. Capability instructions
will maintain the mapping as appropriate. Certain operations will fail-stop based on violating that mapping.

\end{document}
