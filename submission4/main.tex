%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[10pt,conference]{ieeetran}%\settopmatter{printfolios=true,printccs=false,printacmref=false}

\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{amsmath,amsthm,amssymb}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\input{macros}

\begin{document}

%% Title information
\title{Formalizing Stack Safety as a Security Property}

%\author{
%  \IEEEauthorblockN{
%    Sean Noble Anderson
%  }
%  \IEEEauthorblockA{
%    Portland State University\\
%    ander28@pdx.edu
%  }
%  \and
%  \IEEEauthorblockN{
%    Leonidas Lampropoulos,
%  }
%  \IEEEauthorblockA{
%    University of Maryland, College Park\\
%    leonidas@umd.edu
%  }
%  \and
%  \IEEEauthorblockN{
%    Roberto Blanco,
%  }
%  \IEEEauthorblockA{
%    Max Planck Institute for Security and Privacy\\
%    roberto.blanco@mpi-sp.org
%  }
%  \and
%  \IEEEauthorblockN{
%    Benjamin C. Pierce,
%  }
%  \IEEEauthorblockA{
%    University of Pennsylvania\\
%    bcpierce@cis.upenn.edu
%  }
%  \and
%  \IEEEauthorblockN{
%    Andrew Tolmach
%  }
%  \IEEEauthorblockA{
%    Portland State University\\
%    tolmach@pdx.edu
%  }
%}



%% Keywords
%% comma separated list
\ifcameraready
\keywords{Stack Safety, Micro-Policies}  %% \keywords are mandatory in final camera-ready submission
\fi

\maketitle

\begin{abstract}

What does ``stack safety'' mean, exactly? The phrase is associated with a
variety of compiler,
run-time, and hardware mechanisms for protecting stack
memory, but these mechanisms typically lack precise specifications,
relying instead on informal descriptions and examples of the bad
behaviors that they prevent.

We propose a generic, formal characterization
of stack safety based on concepts from language-based security: a
combination of an integrity property (``the private
state in each caller's stack frame is held invariant by the callee''),
and a confidentiality property (``the callee's behavior is insensitive to the
caller's private state''), which can optionally be extended with a control
flow property.

We use these properties to validate the stack-safety {\em micro-policies}
proposed by Roessler and DeHon%~\cite{DBLP:conf/sp/RoesslerD18}.
Specifically, we check (with
property-based random testing) that their ``eager''
micro-policy, which catches violations as early as possible, enforces a
simple ``stepwise'' variant of our properties, and that
(a repaired version of) their more performant
``lazy'' micro-policy enforces a slightly weaker and more extensional
observational property. Meanwhile our testing successfully detects violations
in several broken variants, including Roessler and DeHon's original lazy policy.

\end{abstract}

\newcommand{\paragraphx}[1]{\emph{#1.}}

\section{Introduction}

The call stack is a perennial target for low-level attacks, leading to a
range of dire consequences, from leakage or corruption of private stack data
to control-flow hijacking. To prevent or detect such attacks, a profusion of
software and hardware protections have been proposed,
%
including stack canaries~\cite{Cowan+98},
bounds checking~\cite{NagarakatteZMZ09,NagarakatteZMZ10,DeviettiBMZ08},
split stacks~\cite{Kuznetsov+14},
shadow stacks~\cite{Dang+15,Shanbhogue+19},
capabilities~\cite{Woodruff+14,Chisnall+15,SkorstengaardLocal,SkorstengaardSTKJFP,Georges+21},
and hardware tagging~\cite{DBLP:conf/sp/RoesslerD18}. \ifaftersubmission\apt{Mostly from
  nick; there could be more}\bcp{Yes, going back to MIT days---we should
  include several more of these, if only to give readers the impression that
this is a well-studied mechanism (so formalizing its protections is
useful).}
\fi

The protections offered by such mechanisms are commonly described in terms
of concrete examples of attacks that they can prevent---corruption of return
addresses, buffer overflows, use of uninitialized variables, etc.---leaving
a more abstract characterization to the reader's intuition.  But these
mechanisms can be quite intricate, and the behaviors they aim to prevent are
subtle and varied.  It can be hard to guess, based only on informal
intuitions, whether a given mechanism actually blocks all potential
attacks---or, conversely, whether it is overly conservative and disallows
system behaviors that are actually safe.
To settle such questions with confidence,
we need a precise, generic, and formal specification for stack
safety, as a basis both for comparing the security claims of different
enforcement techniques and for validating that these claims
are met by particular implementations.

We propose such a characterization using the tools of language-based
security~\cite{sabelfeld2003language}. The informal claim that
``stack safety protects a caller
from its callee'' amounts to saying that it guarantees the {\em integrity} and
{\em confidentiality} of the caller’s local state until it regains control.

A key technical novelty in these definitions,
compared to standard formulations of confidentiality and integrity from the
security literature, is that they
are ``nested'': {\em each} caller is guaranteed protection from its
immediate callees (which, in turn, need protection from their immediate
callees, etc.).
Confidentiality is especially interesting. It is based on a traditional
notion of noninterference, but whereas ordinary noninterference
is an end-to-end hyper-property on whole program runs, stack
confidentiality is a nested form of noninterference applied to
subtraces of the whole program trace delimited by call instructions
and corresponding returns, requiring that the callee’s behavior is
invariant under hypothetical scrambling of the caller’s stack frame.

Our threat model is very strong, allowing the attacker (i.e., the
callee) to execute arbitrary code, including attempting to smash
the stack to disrupt the program’s control flow. Our stack safety
properties demand that, even in the presence of such attackers, confidentiality
and integrity still apply to data in suspended stack frames
until the callee returns.

We can also, optionally, include a notion of {\em well-bracketed control
flow (WBCF)} as in Skorstengaard et al. \cite{SkorstengaardSTKJFP}---a global requirement that
callees must always return to their immediate caller, if they return
at all. Skostengaard et al. define stack safety as the conjunction of WBCF with
{\em local state encapsulation (LSE)}.
Informally, LSE says that the contents of
a caller's stack frame are not read or written while its callees (and their callees, etc.) are
executing.
Skorstengaard et al. formalize these properties by defining an idealized
machine in which they hold {\em by construction}. Our confidentiality and
integrity properties are together stronger than LSE, guaranteeing protection even
in the presence of control-flow violations, and are essentially orthogonal to WBCF.

For confidentiality and integrity, we consider both {\em stepwise}
and {\em observational} variants.  The simpler stepwise
variants formalize the intuition that a caller's local data is {\em never}
read or modified during a call. The observational variants
allow a callee to read from and write to their caller's stack frame, as
long as nothing that they read affects their observable behavior and nothing
they write affects the observable behavior of the caller after they return.
The observational properties are more extensional, and represent a baseline
that any reasonable protection mechanism ought to enforce,
even if it does not prevent every single dangerous read or write.

To demonstrate the utility of our formal characterization, we use these
properties to validate and improve an existing enforcement mechanism, the
{\em stack-safety micro-policies} of Roessler and DeHon~\cite{DBLP:conf/sp/RoesslerD18}, re-implemented
in the Coq proof assistant on top of a RISC-V specification.  We
use QuickChick~\cite{Denes:VSL2014,Pierce:SF4}, a property-based testing
tool for Coq, to generate random programs and check
that Roessler and DeHon's micro-policies correctly abort the ones that
attempt to violate one of our properties. Furthermore, we
%
check that the testing framework is able to generate counterexamples
that violate our properties but are \emph{not} halted by incorrect
enforcement variants---both variants that we accidentally created
during our re-implementation of the micro-policy and ones that we
intentionally crafted to be broken in order to increase our confidence
in testing and the enforcement mechanism itself.

We find that Roessler and DeHon's {\em Depth Isolation} micro-policy, in
which memory cells within each stack frame are tagged with the depth of
the function activation that owns the frame and access to those locations is
then permitted only when an activation at that depth is currently executing, validates our
stepwise properties. On the other hand, our testing reveals that \emph{Lazy Tagging and Clearing}
violates the temporal aspect of confidentiality in
corner cases where data can leak across repeated calls to the same callee,
and also violates integrity if the leak happens to use the caller's frame. We
propose a variant of {\em Lazy Tagging and Clearing} that testably enforces
confidentiality, albeit at some performance cost.
%
\ifaftersubmission
\bcp{Did Nick and Andre know about this deficiency?  Did they mention
  it in their paper?  (If neither, we should make a bigger deal out of the
  fact that we discovered it.)\apt{Their paper is a little vague on this subject.
    They refer to ``temporal security properties'' as something to do with dangling
    pointers, but they don't define it.
    Then they say that Depth Isolation has weaker temporal security
    guarantees than Static Authorities (tag=function name), but they don't explain why
    (and I don't see why). They don't say anything explicit about the temporal
    security properties of Lazy Tagging and Clearing, but they consider it to enforce
    a completely different (and generally weaker) policy anyway (``data flow
    integrity'' vs. ``memory safety'').}}\bcp{Sigh.  OK, I propose that we
  leave this issue to deal with later (in consultation with them, which we
  don't have time to do a good job of today).  At any rate, by my reading we
are not saying anything incorrect at the moment.}
\fi

For ease of exposition, our development initially assumes a single simple
stack with no sharing between callers and callees: all parameters and return
values are passed in registers.  Later, we show how to refine the properties
to allow passing of scalar stack data, granting a callee access to the
caller's data. Throughout, we note how we expect elements of the formalism
to apply to enforcement mechanisms beyond micro-policies.

Lastly, we define integrity and confidentiality properties for a coroutine
system with a static layout, in which each coroutine's stack is constrained
to a fixed region of memory.  Though simplistic, this extension is a step
toward full-blown multithreading and demonstrates that our approach is flexible
enough to handle more sophisticated styles of control flow.

In the rest of the paper, we begin with an informal overview of our key ideas via
examples (\cref{sec:running-example}), followed by a description of our key
assumptions about the machine environment and threat model (\cref{sec:setup}).
We then offer the following contributions:

\begin{itemize}
\item We adapt concepts of integrity and confidentiality from language-based
security, combine these with an existing notion of well-bracketed
control flow to formalize a {\em stepwise stack-safety}
property, and which captures the intuitive concept of
strict stack safety enforced over each step of execution~(\cref{sec:prelim,sec:lse}).
\item We use property-based random testing to check that this stepwise
property is actually enforced by the {\em Depth Isolation} policy
of Roessler and DeHon\cite{DBLP:conf/sp/RoesslerD18}; in the process, we extend the generation by
execution techniques of Hri\c{t}cu et al.\cite{TestingNI:ICFP} to handle nested
properties (\cref{sec:enforcement}).
\item We formalize weaker but more extensional \emph{observational} variants of
  confidentiality and integrity. Both are parameterized over a notion of external
  observation, and are violated only if the accessing of secrets or overwriting of
  data later causes a visible change in the system behavior (\cref{sec:lazy}).
\item We show that the definition can be
extended to argument passing on the stack, callee-saves registers, and a simple coroutine system (\cref{sec:ext}).
\end{itemize}
\Cref{sec:relwork,sec:future} discuss related and future work.

\section{Key Ideas by Example}
\label{sec:running-example}
\colorlet{lgray}{gray!40}
\colorlet{lred}{red!40}
\colorlet{lblue}{blue!20}

\newcommand{\mainsealc}{cyan}
\newcommand{\fsealc}{green}
\newcommand{\unsealc}{lgray}
\newcommand{\emptyoutc}{white} % or gray for consistency with unusedc ?
\newcommand{\fulloutc}{white}
\newcommand{\badc}{lred}
\newcommand{\goodc}{lblue}
\newcommand{\retptrc}{black}
\newcommand{\sealdesc}[1]{Seal(#1)}
\newcommand{\unsealdesc}{Unseal}
\newcommand{\retptrdesc}{RetPtr}
\newcommand{\passdesc}[2]{Pass(#1,#2)}

\begin{figure*}

\begin{subfigure}[t]{.2\textwidth}
{\small
\begin{verbatim}
int main() {
  int x = 42;
  return f()+x;
}



int f() {
  int y, z;
  z = *(&y-2);
  *(&y-2) = 0;
  return 5;
}
\end{verbatim}
}
\end{subfigure}
\begin{subfigure}[t]{.5\textwidth}
{\small
\begin{verbatim}
1 main: add $1,%sp      ; allocate frame
2       mov $42,-1(%sp) ; initialize local
3       call f
4       add -1(%sp),%ra ; set return value
5       sub $1,%sp      ; deallocate frame
6       ret

10 f:   add $2,%sp      ; allocate frame
11      mov -4(%sp),-1(%sp) ; violation!
12      mov $0,-4(%sp)      ; violation!
13      mov $5, %ra     ; set return value
14      sub $1,%sp      ; deallocate frame
15      ret
\end{verbatim}
}
\end{subfigure}
\begin{subfigure}[t]{.25\textwidth}
\begin{center}
\begin{tabular}{l l}
{\tt 2} &
\memoryaddrs{8em}
\memory{3}{\unsealc}[\unsealdesc]
~$\cdots$
\vspace{.5em}
\\
{\tt 3} &
\memoryaddrs{8em}
\memory{3}{\unsealc}
~$\cdots$
    \MemoryLabel{-15em}{0.75em}{42}
    \vspace{.5em}
\\
{\tt 12} &
\memoryaddrs{16em}
\memory{1}{\mainsealc}[\sealdesc{0}]%
\memory{1}{\retptrc}[\retptrdesc]%
\memory{1}{\unsealc}[\unsealdesc]
~$\cdots$
\MemoryLabel{-15em}{0.75em}{42}
\vspace{.5em}
\\
{\tt 13} &
\memoryaddrs{16em}
\memory{1}{\mainsealc}
\memory{1}{\retptrc}
\memory{1}{\unsealc}
~$\cdots$
\MemoryLabel{-15em}{0.75em}{\bf 0}
\vspace{.5em}
\end{tabular}
\end{center}
\vspace{-4ex}
\end{subfigure}
\caption{An integrity violation
\ifaftersubmission\bcp{I wonder if we
    could make the figures easier to read by putting very light, differently
  colored backgrounds under the different parts}\fi}
\label{fig:int1}
\end{figure*}

This section explains our formal stack safety properties through a series
of examples, each presented both in C syntax and in corresponding assembly code for a
simple two-address machine (see Figure~\ref{fig:int1}).
The address of each instruction is shown to its left.
The assembly code reflects a simple compilation model in which
local variables are stored in the stack frame.
For the moment, arguments and return values are passed in registers.
The stack grows upward in
memory and {\tt \%sp} points to the first unused word above the top of the stack.
The {\tt call} and {\tt ret} instructions push and pop the return address from the stack,
implicitly adjusting the stack pointer.
At the right of each example, we show snapshots of the layout of stack memory just before
selected instructions (labeled by their addresses) are executed; each box represents a memory word
(the machine is word addressed), and addresses increase to the right.
We refer to registers and addresses collectively as {\em state elements} or just elements.
  %% \bcp{Most of the
  %% figure is kind of self-explanatory with this help, but the rightmost part
  %% is a little opaque: what do 2, 3, 11, 12 mean?  What is SP?  What are the
  %% numbers in the boxes?  What are these brackets under the boxes, ...  One
  %% simple thing we could do to help might be to label the right-hand column
  %% something like ``Snapshots,'' or at least explain early on in the text
  %% that this is what they are.}

Labels under the boxes indicate an assignment of the address to a
{\em domain}, which is a particular set of intended access
rights. Unless otherwise marked, each address retains its domain as
sequential instructions execute. %, as hinted by their colors.
%\bcp{where do we see this happening?  Is it important?}.
Domains are not part of the machine state; rather, they are part
of the {\em context} of a state that describes the security restrictions
that the enforcement mechanism must adhere to.
(We will introduce some other parts of the context as needed.)
Such a domain
can be \(\unsealed\) (in the stack and accessible to writes), \(\sealed{\depth}\)
(in the stack and reserved for the caller at depth \(\depth\)), or \(\outside\)
(outside the stack entirely.)
% These are abbreviated \(U\) and \(S(\dots)\)\bcp{Nope} in the figures.
Global variables and code, which are not shown in the figures, would
also be labeled \(\outside\). Return pointers, labeled ``RetPtr,''
are shaded black and ignored for simplicity for now --- they will
be treated properly later.

Figure~\ref{fig:int1} shows a program with a simple integrity violation. It consists of a {\tt main}
function that performs a call to a function {\tt f}, which reads and then overwrites {\tt main}'s
variable {\tt x}. (Of course, this is illegal C, but it is characteristic of what buggy or malicious code might do.)
In the initial memory layout the entire stack is {\em unsealed},
meaning that it is eligible to be written to. At the call from {\tt main} to
{\tt f}, {\tt main}'s locals are {\em sealed} with {\tt main}'s depth,
in this case 0. (Note that this does not include the return address, which is saved
by the call instruction.)
Sealing is the fundamental integrity contract between the caller and callee:
{\tt main} expects that {\tt x} will be unchanged when it gets control back.
This leads to a simple, intuitive statement of {\em stepwise integrity}:
if a element is sealed before a step, it will be unchanged afterward.
% Stepwise
% refers to the fact that the property must hold on every step.
 %Later we will
%loosen this condition in the interest of extensionality---the caller only
%cares about changes it can see after the return, not changes during execution.
In this case, after instruction 12, {\tt f} has violated integrity by writing to {\tt x},
so the final return value produced by {\tt main} is wrong.

\begin{figure*}
\centering
\begin{tabular}{l l | l}
  {\tt 2} &
  \multicolumn{2}{c}{
    \memoryaddrs{8em}
    \memory{4}{\unsealc}
    ~$\cdots$
%    \MemoryLabel{-18em}{0.75em}{0}
%    \MemoryLabel{-14em}{0.75em}{0}
%    \MemoryLabel{-10em}{0.75em}{0}
%    \MemoryLabel{-7em}{0.75em}{0}
    \vspace{.5em}
  } \\
  {\tt 11} &
  \memoryaddrs{21em}
  \memory{1}{\unsealc}
  \memory{1}{\retptrc}
  \memory{2}{\unsealc}
  ~$\cdots$
  \MemoryLabel{-19em}{0.75em}{42}
%  \MemoryLabel{-10em}{0.75em}{0}
%  \MemoryLabel{-6em}{0.75em}{0}
  &
  \memoryaddrs{21em}
  \memory{1}{\unsealc}
  \memory{1}{\retptrc}
  \memory{2}{\unsealc}
  ~$\cdots$
  \MemoryLabel{-19em}{0.75em}{\(v_0\)}
  \MemoryLabel{-10em}{0.75em}{\(v_1\)}
  \MemoryLabel{-6em}{0.75em}{\(v_2\)}
  \\
  {\tt 12} &
  \memoryaddrs{21em}
  \memory{1}{\unsealc}
  \memory{1}{\retptrc}
  \memory{2}{\unsealc}
  ~$\cdots$
  \MemoryLabel{-19em}{0.75em}{42}
  \MemoryLabel{-10em}{0.75em}{5}
 % \MemoryLabel{-6em}{0.75em}{0}
  &
  \memoryaddrs{21em}
  \memory{1}{\unsealc}
  \memory{1}{\retptrc}
  \memory{2}{\unsealc}
  ~$\cdots$
  \MemoryLabel{-19em}{0.75em}{\(v_0\)}
  \MemoryLabel{-10em}{0.75em}{5}
  \MemoryLabel{-6em}{0.75em}{\(v_2\)}
  \\
  {\tt 13} &
  \memoryaddrs{21em}
  \memory{1}{\unsealc}
  \memory{1}{\retptrc}
  \memory{1}{\unsealc}
  \memory{1}{\badc}
  ~$\cdots$
  \MemoryLabel{-19em}{0.75em}{42}
  \MemoryLabel{-10em}{0.75em}{5}
  \MemoryLabel{-6em}{0.75em}{42}
  \vspace{.5em}
  &
  \memoryaddrs{21em}
  \memory{1}{\unsealc}
  \memory{1}{\retptrc}
  \memory{1}{\unsealc}
  \memory{1}{\badc}
  ~$\cdots$
  \MemoryLabel{-19em}{0.75em}{\(v_0\)}
  \MemoryLabel{-10em}{0.75em}{5}
  \MemoryLabel{-6em}{0.75em}{\(v_0\)}
  \vspace{.5em}
\end{tabular}

\vspace{\abovedisplayskip}

\caption{A confidentiality violation\ifspace\apt{Could save space by not
    repeating C or assemly code for {\tt main}.}\fi}
\label{fig:conf1}
\end{figure*}

But before violating integrity, {\tt f} violates confidentiality by
reading {\tt x}.
Confidentiality states intuitively that a callee is insensitive to
the context of its call (except for its arguments and any global
variables).
We state this as a form of {\em noninterference}~\cite{Goguen1982SecurityPA}.
Noninterference describes knowledge: its standard form states that for state elements
containing secret values, we can substitute any values whatsoever for the secrets
without changing the effect of our computation on non-secret values.
% \bcp{That's too loose.  Even for standard NI, high inputs
% are allowed to change high results.  And for us it's even more subtle, since
% a given address can switch from high to low when a function returns.}
If there exists some value for which we see different results, then
in fact we can learn something about the initial state by observing those results.
To adapt this to the stack, the notion of ``secret'' must be dynamic with function
calls and returns.

In Figure~\ref{fig:conf1} we see how noninterference applies to this scenario.
At instruction 10, we
create an imaginary {\em variant}
state with arbitrary values\ifaftersubmission\bcp{IMO, it would be easier to
  understand if we chose concrete values for the examples}\sna{FWIW I agree in
  theory, but it looks bad every time I try it.\fi~(\(v_0\), etc.),
in place of the actual values ($42$, ...) that should
be hidden from {\tt f}; we show the evolving stack memory of the variant in a second, parallel column.
At instruction 11, we note that the callee's variable, {\tt z}, has
changed to 42 in the primary trace, but
in the variant trace it instead might have any value \(v_0\). If \(v_0 \neq 42\) then the variant
has behaved differently than the primary, violating confidentiality.

We call this form of confidentiality {\em stepwise confidentiality}. Informally,
for any state at the entry to a function, and for any variant over the values in the stack,
the primary state and the variant will step in lockstep until they
return. To step in lockstep
means that if both states step---that is, neither the primary nor the variant failstops---any
state element that changes in the original will change in the same way in the variant.


\begin{figure}
%\begin{center}
\begin{subfigure}[t]{.32\columnwidth}
  {\small
\begin{verbatim}
int main() {
  int x;
  x = f();
  return g();
}
\end{verbatim}
  }
\end{subfigure}
\begin{subfigure}[t]{.32\columnwidth}
  {\small
\begin{verbatim}
int f() {
  int y = 5;
  return y;
}
\end{verbatim}
  }
\end{subfigure}
\begin{subfigure}[t]{.32\columnwidth}
  {\small
\begin{verbatim}
int g() {
  int z;
  return z;
}
\end{verbatim}
  }
\end{subfigure}
%\begin{subfigure}[t]{.68\textwidth}
%  {\small
%\begin{verbatim}
%1 main:  add $1,%sp      ; allocate frame
%2        call f
%3        mov %ra,-1(%sp) ; store x
%4        call g
%5        sub $1,%sp      ; deallocate frame
%6        ret
%
%10 f:    add $1,%sp      ; allocate frame
%11       mov $5,-1(%sp)  ; initialize y
%12       mov -1(%sp),%ra ; set return value
%13       sub $1,%sp      ; deallocate frame
%14       ret
%
%20 g:    add $1,%sp      ; allocate frame
%21       mov -1(%sp),%ra ; violation!
%22       sub $1,%sp      ; deallocate frame
%23       ret
%}
%\end{verbatim}
%}
%\end{subfigure}
%\end{center}
%\begin{subfigure}{.65\textwidth}
%\begin{center}
%\begin{tabular}{l r | l}
%  {\tt 2} &
%  \multicolumn{2}{c}{
%    \memoryaddrs{8em}
%    \memory{3}{\unsealc}
%    ~$\cdots$
%    \vspace{.5em}
%  } \\
%  {\tt 11} &
%  \memoryaddrs{16em}
%  \memory{1}{\unsealc}
%  \memory{1}{\retptrc}
%  \memory{1}{\unsealc}
%  ~$\cdots$
%  &
%  \memoryaddrs{16em}
%  \memory{1}{\unsealc}
%  \memory{1}{\retptrc}
%  \memory{1}{\unsealc}
%  ~$\cdots$
%  \MemoryLabel{-15em}{0.75em}{\(v_1\)}
%  \MemoryLabel{-6em}{0.75em}{\(v_2\)}
%  \\
%  {\tt 12} &
%  \memoryaddrs{16em}
%  \memory{1}{\unsealc}
%  \memory{1}{\retptrc}
%  \memory{1}{\unsealc}
%  ~$\cdots$
%  \MemoryLabel{-6em}{0.75em}{5}
%  &
%  \memoryaddrs{16em}
%  \memory{1}{\unsealc}
%  \memory{1}{\retptrc}
%  \memory{1}{\unsealc}
%  ~$\cdots$
%  \MemoryLabel{-15em}{0.75em}{\(v_1\)}
%  \MemoryLabel{-6em}{0.75em}{\(5\)}
%  \\
%  {\tt 4} &
%  \multicolumn{2}{c}{
%    \memoryaddrs{8em}
%    \memory{1}{\unsealc}
%    \memory{1}{\retptrc}
%    \memory{1}{\unsealc}
%    ~$\cdots$
%    \MemoryLabel{-14em}{0.75em}{5}
%    \MemoryLabel{-6em}{0.75em}{5}
%    \vspace{.5em}
%  }
%  \\
%  {\tt 22} &
%  \memoryaddrs{16em}
%  \memory{1}{\unsealc}
%  \memory{1}{\retptrc}
%  \memory{1}{\unsealc}
%  ~$\cdots$
%  \MemoryLabel{-15em}{0.75em}{5}
%  \MemoryLabel{-6em}{0.75em}{\bf 5}
%  &
%  \memoryaddrs{16em}
%  \memory{1}{\unsealc}
%  \memory{1}{\retptrc}
%  \memory{1}{\unsealc}
%  ~$\cdots$
%  \MemoryLabel{-15em}{0.75em}{\(v_3\)}
%  \MemoryLabel{-6em}{0.75em}{\(v_4\)}
%  \MemoryLabel{-2em}{0.75em}{90}
%  \\
%\end{tabular}
%\end{center}
%
%\vspace{\abovedisplayskip}
%
%\end{subfigure}
\caption{Another confidentiality violation}
\label{fig:conf2}
\end{figure}

It may be unclear in Figure~\ref{fig:conf1} why we vary the initial values of {\tt y}
and {\tt z} as well as that of {\tt x}. This is to detect some violations of so-called
{\em temporal stack safety}. Suppose, in a
In Figure~\ref{fig:conf2}, {\tt f} leaves behind a value in {\tt y}
that later becomes the value of {\tt main}'s variable {\tt x}. Then {\tt g} is able to access
{\tt y} and hence {\tt x} without even directly reading the stack pointer. In terms of noninterference,
in the primary trace, {\tt z} will have the value 5, but in the variant it can have
an arbitrary value. We regard this as a violation of confidentiality as well.

\paragraph*{Control-Flow Attacks}
\begin{figure*}
  \centering
\hspace*{-6em}
  \begin{subfigure}[t]{.2\textwidth}
{\footnotesize
\begin{verbatim}
int *stash = 0;
int main() {
  int x = 1;
  f();
  x = -x;
  f();
  return x;
}


void f() {
  int y;
  if (!stash) {
    stash = *(&y-1);
  } else {
    *(&y-1) = stash;
    stash = 0;
  }
  return;
}
\end{verbatim}
}
\end{subfigure}
  \begin{subfigure}[t]{.4\textwidth}
{\footnotesize
\begin{verbatim}
   stash: .word 0
1  main:  add $1,%sp     ; alloc frame
2         mov $1,-1(%sp) ; init x
3         call f
4         neg -1(%sp)    ; x = -x
5         call f
6         mov -1(%sp),%ra ; set ret val
7         sub $1,%sp     ; dealloc frame
6         ret

10 f:     add $1,%sp     ; alloc frame
11        cmp stash, $0  ; stash = 0?
12        breq #15       ; branch if so
13        mov -2(%sp),stash ; set stash
14        jmp #17
15        mov stash,-2(%sp) ; get stash
16        mov $0,stash
17        sub $1,%sp     ; dealloc frame
18        ret
\end{verbatim}
}
  \end{subfigure}
%
  \begin{subfigure}[t]{.2\textwidth}
    \begin{center}
    \begin{tabular}{l l l}
      {\tt 3} &
      \memoryaddrs{8em}
      \memory{3}{\unsealc}
      ~$\cdots$
      \MemoryLabel{-15em}{0.75em}{1} \\
      {\tt 18} &
      \memoryaddrs{12em}
      \memory{1}{\mainsealc}[\sealdesc{0}]%
      \memory{1}{\unsealc}[\retptrdesc]%
      \memory{1}{\unsealc}%
      ~$\cdots$
      \MemoryLabel{-15em}{0.75em}{1}
      \MemoryLabel{-11em}{0.75em}{\#4}
      \vspace{.5em} &
      \hspace*{-1.5em}
      \memory[1.2em]{1}{\mainsealc}[Target]%
      \MemoryLabel{-2.2em}{0.75em}{\#4}
      \\
      {\tt 4} &
      \memoryaddrs{8em}
      \memory{3}{\unsealc}
      ~$\cdots$
      \MemoryLabel{-15em}{0.75em}{1} \\
      {\tt 11} &
      \memoryaddrs{16em}
      \memory{1}{\mainsealc}
      \memory{2}{\unsealc}%
      ~$\cdots$
      \MemoryLabel{-15em}{0.75em}{-1}
      \MemoryLabel{-11em}{0.75em}{\#6} &
      \hspace*{-1em}
      \memory[1.2em]{1}{\mainsealc}
      \MemoryLabel{-1.2em}{0.75em}{\#6}
      \\
      {\tt 18} &
      \memoryaddrs{12em}
      \memory{1}{\mainsealc}
      \memory{1}{\badc}
      \memory{1}{\unsealc}%
      ~$\cdots$
      \MemoryLabel{-15em}{0.75em}{-1}
      \MemoryLabel{-11em}{0.75em}{\#4} &
      \hspace*{-1em}
      \memory[1.2em]{1}{\mainsealc}
      \MemoryLabel{-1.2em}{0.75em}{\#6}
      \\
      {\tt 4} &
      \memoryaddrs{8em}
      \memory{1}{\mainsealc}
      \memory{2}{\unsealc}
      ~$\cdots$
      \MemoryLabel{-15em}{0.75em}{-1} &
      \hspace*{-1em}
      \memory[1.2em]{1}{\mainsealc}
      \MemoryLabel{-1.2em}{0.75em}{\#6}
      \\
      {\tt 5} &
      \memoryaddrs{8em}
      \memory{1}{\mainsealc}
      \memory{2}{\unsealc}
      ~$\cdots$
      \MemoryLabel{-15em}{0.75em}{\bf 1} &
      \hspace*{-1em}
      \memory[1.2em]{1}{\mainsealc}
      \MemoryLabel{-1.2em}{0.75em}{\#6} \\
    \end{tabular}
    \end{center}
    \vspace{\abovedisplayskip}
  \end{subfigure}
  \caption{A control-flow attack.}
  \label{fig:controlflow}
\end{figure*}

%From the classic stack smashing attack to return oriented programming,
One of the most pernicious ways to attack the stack is by hijacking control flow.
Our stack safety properties do not assume that control flow follows a typical structure
of matching sets of calls and returns nested within one another.
Rather, they aim to capture what it means to protect data even in the presence of control-flow attacks.
Consider Figure~\ref{fig:controlflow}.
(Now we treat return addresses properly, but write them as line numbers, in the
form $\#n$.)
Function {\tt f} is called twice, at instructions 3 and 5; it should therefore return to instructions
4 and 6, respectively. But the first time, before returning, it stashes its
return pointer away, and the second time it returns to instruction 4 instead of 6; then it ends
up being called a third time, at which point it finally returns to instruction 6.

Reasoning about {\tt main}, we expect that {\tt x} is negated once, so that {\tt main} returns
$-1$. But because of {\tt f}'s interference, {\tt x} is negated twice, and {\tt main} returns 1.
This has the appearance of an integrity violation, so how do we capture it in our
integrity property?

The key intuition is that, to be considered as having returned to {\tt main}, {\tt f} needs
to do more than just execute a return-labeled instruction: it must actually reach the
appropriate return target in {\tt main}.
To capture this intuition, we add a new piece of context to our diagram:
a stack of return targets.  Now a callee is
only considered to have returned when it reaches a state that matches the caller's target.
A return target is associated with a set of sealed locations that will become unsealed
when it is reached, represented here by coloring both the target and its sealed data with the
same color (blue).

In the example, on its first return, {\tt f} reaches its return target, because the
\(\PCname\) is 4 after its return. But {\tt f}'s second return is to the wrong instruction
(4 rather than 6) because the stack pointer has been overwritten (shown in light red).
Thus {\tt x} is still sealed and {\tt f}'s attempt to overwrite it at instruction 4
violates the integrity property.

\paragraph{Well-bracketed control flow.} Together,
integrity and confidentiality protect a caller's data until its callee
returns to it. However, it is possible that an intermediate caller is not
returned {\em to}, but rather returned {\em past}, to some ancestor caller!
For example, function $A$ calls function $B$, which in turn calls $C$, which
returns directly to $A$ by resetting the stack pointer to $A$'s stack frame
and branching to the address after the call from $A$ to $B$.  Strictly
speaking, this is not an information-flow violation, since neither $A$'s nor
$B$'s stack frames are improperly read or written by $C$.  But it is still
arguably unsafe in general.  For example, suppose that $B$'s continuation
after the call to $C$ takes $C$'s result, doubles it, and returns this to
$A$.  If $A$'s correct behavior after the call to $B$ returns depends on the
result it receives being a even number---i.e., $A$ is trusting that $B$'s
continuation will execute after $C$ returns, perhaps because $A$ and $B$ are
written by the same person while $C$ is an untrusted library---then $C$ can
cause it to behave incorrectly, possibly even insecurely, by returning an
odd result directly to $A$.
%
Thus, a formal definition of safe use of the stack should include the
condition that calls and returns should be correctly nested---e.g., $C$ should
only return to $B$.  This is what Skorstengaard et al.\cite{SkorstengaardSTKJFP}
call \emph{well-bracketed control flow (WBCF)}.

\section{Threat Model, Machines, and Enforcement }
\label{sec:setup}
\label{sec:threat}

Before introducing our formal model of stack safety, we describe our assumptions:
how broadly we can abstract over machines, how we represent enforcement, and
our threat model.

\paragraph*{Machine model}
Our properties are defined in terms of an abstract machine model that makes very few
assumptions about the concrete machine that instantiates it. Each formal property
may be instantiated with any machine that meets the following criteria, and it
will be a meaningful definition of stack safety for that machine. It must at least be a
register machine with a program counter (\(\PCname\)), and there must be a well-defined
mechanism for determining the bounds of a stack frame, and for recognizing when a call
has returned. In this paper we discuss those machines with a stack pointer (\(\rsp\)),
in which the current stack frame is everything below the stack pointer and above the
previous frame, and a call from instruction \(\addr_\PCname\) with stack pointer \(\addr_\rsp\)
is said to have returned when the pc is at \(\addr_\PCname + 4\) and the stack pointer
is again at \(\addr_\rsp\). But, other configurations, such as those involving frame pointers,
are equally feasible. A machine may use its non-stack memory in any way, including
as a heap, as long as the stack has static bounds.

Our core property assumes that all register values passed to the callee are public,
and that all data in a stack frame is private.
Some calling convention choices, such as callee-saves registers and argument
passing on the stack, are not supported directly by this property; we introduce
secondary properties that use the same underlying formalism to handle these cases,
as well as a simple coroutine model, in Section~\ref{sec:ext}.

\paragraph*{What is a ``call''?}  One significant challenge in formulating our
properties arises from the fact that we want to define stack safety at the
machine-code level for a variety of ISAs, including RISCy
\ifaftersubmission\sna{RISCy?}\leo{RISC-like maybe?}\sna{Apparently riscy is a thing.}\fi ones.  In
particular, there may be no single ``call'' instruction that does all the
required manipulation of the \(\PCname\) and stack pointer. Instead, there
might be just a simple branch instruction that stores the old \(\PCname\) in
a register, with the rest of the call sequence performed by other
instructions either before or after the jump.  Similarly, there may be no
``return'' instruction, but rather a ``return sequence'' involving an
indirect branch at some point.  Thus, the same instruction opcode may be
used in some places as part of a call or return sequence and in other places
for other purposes.

Since our stack-safety properties are all about protecting ``callers'' from
their ``callees,'' we need some clear-cut way to recognize when the program
makes or returns from a call.  Accordingly, we assume we are given a machine
language program {\em annotated} with the locations of instructions
representing calls.  We declare that a call has occurred when the machine
has just executed an instruction marked as a call.
%
These call annotations would typically come from a compiler together with
the machine code, but we do not assume anything about their provenance.
Annotations connect the enforcement mechanism to the property: we don't
protect unmarked calls, because a mechanism's correct functioning might
depend on knowing where calls are.

Returns, on the other hand, need not be annotated: we can tell when a callee
has returned control to the caller when...we see control return to the
caller! We don't require the callee's cooperation at all.
For example, under a standard calling convention, we can see that a
return has occurred when the state of the machine reaches a state where
the stack pointer has the same value as it did at the point of some earlier
call and the $\PCname$ points to the instruction following that call.  We
abstract away from the details of specific calling conventions by assuming
that we are given some way of telling when a given machine state is a
{\em return target} with respect to some set of pending calls.

\paragraph*{Enforcement Model}

We model the base machine's behavior as a step function over machine states,
and a machine
enhanced with an enforcement mechanism, or {\em policy} for short, as a
partial step function over machine states extended with some
auxiliary state, refining the base machine. When the policy-enhanced machine
does not step from a given state, this is a {\em failstop}, halting the program before it can perform an
action that would violate the security property;
our properties are therefore naturally \emph{termination insensitive.}
This model will be made more precise in \cref{sec:prelim}.

Dividing policy state from machine state helps us reason about
enforcement mechanisms that keep a significant amount of data separate from the
primary execution data to inform security. Tag-based systems, in which a hardware
monitor tracks metadata tags associated with a software-defined ``micro-policy,'' are
the motivating application. The tags, and any extra policy state, are separated from
and untouchable by application code.

That said, our model is meant to apply generically to any enforcement mechanism,
including those that do not take advantage of this separation.
Some mechanisms, like hardware capability systems, might exhibit failstop behavior,
but have no protected policy state---this is represented by a trivial policy
that failstops when the hardware faults. Others might never even failstop, such as
code rewriting techniques that prevent stack safety violations directly, in which
case their policy state does nothing at all.

An enforcement model may additionally
apply a ``well-formedness'' criterion on initial states, ensuring that
they are set up properly for the enforcement mechanism in question.
When validating Roessler and DeHon's \cite{DBLP:conf/sp/RoesslerD18}'s micro-policies,
well-behaved calls and returns are implemented by fixed sequences of instructions
which the tag policy will force to be executed from start to finish,
termed {\em blessed sequences}. Well-formedness requires that all annotated
instructions will be situated at the appropriate instruction of a {\em blessed sequence}.
This is all we need for the policy to protect itself: it can then failstop if it would
execute the blessed sequence out of order.

\paragraph*{Threat Model}

We adopt a strong threat model in which both caller and callee may execute
arbitrary machine code, subject to whatever well-formedness conditions the
enforcement mechanism demands. But hardware and timing attacks are out of scope, as
are attacks on the heap---though we believe that the work of
Azevedo de Amorim et al.\cite{DBLP:conf/post/AmorimHP18} can be combined smoothly with ours
to protect both stack and heap.

\paragraph*{Limitations}

Our model is flexible enough to support many realistic uses of the stack.
We intentionall say little or nothing about other structures
such as the heap.  (Heap safety has already been studied, in isolation,
by Azevedo de Amorim et al., and we expect that their correctness condition and ours can be
combined cleanly to characterize correct protection of stack + heap.)

Features that we do not currently support:

\begin{itemize}
\item Address-taken locals. A satisfactory
  treatment of these seems to require integration with a more general
  model of memory safety that covers the heap and static globals too,
  such as the aforementioned model of Azevedo de Amorim et al.

\item Exceptions. We can see a way to extend the model to include them:
  we would model a "setjump" operation by inserting a
  special target in the return target stack. We would weaken
  well-bracketedness to allow reaching such a target from any
  depth. Since integrity and confidentiality are distinct from
  well-bracketedness and already permit the popping of multiple
  functions from the stack, they can simply treat the exception's
  target as another return target.

\item Tail calls. To implement these, we would need to distinguish them
  from normal calls and slightly adjust the mechanics of the return stack.

\item Dynamic code generation. This would be challenging to
  integrate into our framework, because we rely on code annotations.
  But we can easily envision supporting limited cases in which
  the generated code never contains a call or other annotated instruction,
  or in which existing code is copied along with its annotations.

\item Concurrency. We can handle a limited form of coroutines, as described in
  8.3. Handling full-blown preemptive concurrency would require significant
  changes in our underlying machine model.
\end{itemize}

\section{Machines and Traces}
\label{sec:prelim}

We now define our machine and enforcement model precisely.

The building blocks of the machine are {\em values} and {\em addresses}.
Both are drawn from some set of {\em words} \(\WORDS\), ranged over by \(\word\) and
\(\addr\), respectively.
%
Our machine states are composed of {\em elements} \(\component\),
which are either addresses or register names (\(\reg\)) drawn from some set
\(\REGS\), which is assumed to include two special-purpose registers: the
program counter {\PCname} and the stack pointer \(\SP\).
$\component \in \COMPONENTS ::= \WORDS + \REGS$.
A {\em machine state} is a map from elements to values.
$\mach \in \MACHS ::= \COMPONENTS \rightarrow \WORDS$.

We have a total step function between machine states, written \(\mach \stepsto \mach'\).

We now formalize the model of enforcement that we introduced in Section~\ref{sec:threat}.
A {\em policy} consists of a set of policy
states \(\pol \in \POLS\) and a policy step function \((\mach, \pol) \polstep \pol' \in
\MACHS \times \POLS \rightharpoonup \POLS\). This step function is partial;
it is undefined on input configurations that correspond to a policy fault. The policy
can see the machine state, but cannot modify it. The policy also provides a
well-formedness predicate, \(\WF \subseteq \MACHS \times \POLS\), describing
initial states that are properly configured.
%
%A concrete policy based on \citet{DBLP:conf/sp/RoesslerD18} will be described in
%\Cref{sec:enforcement}.---APT: We just said this.

We lift the policy step function to operate on such pairs
by combining it with the regular step function for machine states.

\judgmenttwo{\(\mach \stepsto \mach'\)}{\((\mach, \pol)
               \polstep \pol'\)}
            {\(\mpstate{\mach}{\pol} \stepstopol
               \mpstate{\mach'}{\pol'}\)}

\noindent
Note that the base machine has a total step function, while the policy-enhanced machine
refines it to a partial function. The extra policy state never changes behavior,
but it can cause
premature termination, representing failstop behavior.

\paragraph*{Contexts}

Separate from the machine state, we keep track of additional context
information representing the history of the run. This has no influence on execution, it merely
describes information relevant to the particular property. Different information is needed
for different versions of the model, so the definitions are parameterized
over an arbitrary set of context states, \(\CONTEXTS\), annotations \(\ANNS\),
an initial context state \(\context_0 \in \CONTEXTS\), and a context step function
\(\mach, \context \constep \context' \in \MACHS \times \CONTEXTS
\rightarrow \CONTEXTS\). We also assume the existence of a \emph{code map},
\(\codemap \in \WORDS \rightharpoonup \ANNS\)
that relates each code address to its annotation, if any.
We lift contexts into an MP trace in much the same way as we lifted policy states to get
a triple state \(\mpcstatename \in \MPCS = \MACHS \times \POLS \times
\CONTEXTS\).

\judgmenttwo{\(\mpstate{\mach}{\pol} \stepstopol \mpstate{\mach'}{\pol'}\)}
              {\(\mach, \context \constep \context'\)}
              {\(\mpcstate{\mach}{\pol}{\context} \stepstocon
                \mpcstate{\mach'}{\pol'}{\context'}\)}

\paragraph*{Machine Traces}
\label{sec:traces}

A {\em machine trace} is a nonempty, finite or infinite sequence of elements
of MPC-states, ranged over by \(\MPCT\) and \(\NPCT\).
We use ``\(\notfinished{}{}\)'' to represent ``cons'' for traces (ordinary lists will use
``::'').

The ``trace-of'' operator, written \(\mpcstatename \hookrightarrow \MPCT\),
coinductively relates an initial state with the trace of states
produced by repeated application of \(\stepstocon\)

\begin{center}
\begin{minipage}{.4\textwidth}
\judgmenttwo{\(\mpcstatename \stepstocon \mpcstatename'\)}
            {\(\mpcstatename' \hookrightarrow \MPCT\)}
            {\(\mpcstatename \hookrightarrow \notfinished{\mpcstatename'}{\MPCT}\)}%
\end{minipage}
\begin{minipage}{.4\textwidth}
\judgment%[Default]
         {\(\not\exists \mpcstatename'. \mpcstatename \stepstocon \mpcstatename'\)}
         {\(\mpcstatename \hookrightarrow \mpcstatename\)}
\end{minipage}
\end{center}
%

We project out the machine state of an MPC-state with \(\pi_\mach\), the
policy state with \(\pi_\pol\), and the context with \(\pi_\context\).
We take the first element of a trace with \(\head(\MPCT)\), which is a total
function since traces are non-empty, and the final element (if one exists) with
\(\last(\MPCT)\), which is partial.

\paragraph*{Until}
The operation \(\PUT ~ f ~ \MPCT\) takes a trace \(\MPCT\)
and a predicate on states \(f \subseteq \MPCS\) and gives the prefix of
\(\MPCT\) ending with the first element on which \(f\) holds.

\begin{center}
  \begin{minipage}{.3\textwidth}
    \judgment{\(f ~ \mpcstatename\)}
             {\(\PUT ~ f ~ (\notfinished{\mpcstatename}{\MPCT}) = \mpcstatename\)}
  \end{minipage}
%
  \begin{minipage}{.3\textwidth}
    \judgment{}
             {\(\PUT ~ f ~ \mpcstatename = \mpcstatename\)}
%
  \end{minipage}
  \begin{minipage}{.3\textwidth}
    \judgmenttwo{\(\neg f ~ \mpcstatename\)}{\(\PUT ~ f ~ \MPCT = \MPCT'\)}
                {\(\PUT ~ f ~ (\notfinished{\mpcstatename}{\MPCT}) = \notfinished{\mpcstatename}{\MPCT'}\)}
  \end{minipage}
\end{center}
%
If the resulting trace is a strict prefix of the parameter, then the
predicate must hold on its final element. If the predicate never holds, then
\(\PUT\) is the identity function.

We will frequently take a prefix of the trace from an initial state up
through the first state where some condition holds on the machine state.
This can easily be implemented using \(\PUT\), and we provide special notation
for convenience.
%
If \(f\) is a predicate on machine states, we define \(\mpcstatename
\hookrightarrow \MPCT | f\) (read ``\(\MPCT\) is the prefix of
running \(\mpcstatename\) up to \(f\)''):
%
\begin{center}
\judgmenttwo{\(\mpcstatename \hookrightarrow \MPCT'\)}
            {\(\PUT ~ f ~ \MPCT' = \MPCT\)}
            {\(\mpcstatename \hookrightarrow \MPCT | f\)}
\end{center}

\paragraph*{Context Segments}

In particular, we wish to formulate properties around consecutive subtraces
in which the context obeys a given predicate. This will commonly be used to extract
individual calls from a trace by taking subtraces in which the stack is
at or above a given depth. If \(f\) is still a predicate on states, then
we define \(\mpcstatename \hookrightarrow \MPCT \langle f \rangle\), pronounced
``\(\mpcstatename\) segmented by \(f\) yields a sub-trace \(\MPCT\).''
\ifspace{\bcp{Throughout, we could save space and improve beauty by removing some of the
vertical space between inference rules.}\fi

\begin{center}
  \judgmenttwo[]
              {\(f ~ \mpcstatename\)}
              {\(\mpcstatename \hookrightarrow \MPCT | \neg f\)}
              {\(\mpcstatename \hookrightarrow \MPCT \langle f \rangle\)}
  \judgmentthree[]
                {\(f ~ \mpcstatename\)}
                {\(\mpcstatename \hookrightarrow \MPCT | \neg f\)}
                {\(\last(\MPCT) \hookrightarrow \MPCT' \langle f \rangle\)}
                {\(\mpcstatename \hookrightarrow \MPCT' \langle f \rangle\)}
  \judgmentthree[]
                {\(\neg f ~ \mpcstatename\)}
                {\(\mpcstatename \hookrightarrow \MPCT | f\)}
                {\(\last(\MPCT) \hookrightarrow \MPCT' \langle f \rangle\)}
                {\(\mpcstatename \hookrightarrow \MPCT' \langle f \rangle\)}
\end{center}

\paragraph*{Reachability}

We often want to quantify over all traces from any initial state so that our
properties apply to the system as a whole. We say that a state \(\mpcstatename'\)
is {\em reachable} if for some initial state \(\mpcstatename = \mach,\pol,\context_0\)
where \((\mach,\pol) \in \WF\), \(\mpcstatename \hookrightarrow \MPCT\)
and \(\MPCT\) contains \(\mpcstatename'\). A {\it reachable segment} \(\MPCT \langle f \rangle\) is a subtrace
such that from some similarly well-formed initial state \(\mpcstatename\),
\(\mpcstatename \hookrightarrow \MPCT \langle f \rangle\).

\section{Stack Safety, Formally}
\label{sec:lse}

We are finally ready for our definition of stack safety. We begin
by describing how we model knowledge about the program structure,
then dive into the formal definitions of integrity, confidentiality, and
well-bracketed control flow, which together constitute stack safety.

We will focus on a simple stack model, with a single stack
that doesn't share between caller and callee: arguments and results are passed
in registers. The code map just marks the locations of calls.
\[\codemap \in \CODEMAPS ::= \WORDS \rightharpoonup \callmap\]
To accommodate different machine architectures and different calling
conventions, we parameterize over the structure of the stack, particularly
the means by
which a caller identifies the data that should be protected during a call. We term
this the {\em sealing convention},
%\(\sealcon ~ (\mach \in \MACHS) ~ (\component \in \COMPONENTS)\),
\(\sealcon \subseteq (\MACHS \times \COMPONENTS)\),
a relation between machine states and the addresses that should be sealed.
If a state's \(\PCname\) is annotated as a call, the sealing convention tells us
which addresses must be protected until the return. Similarly, we abstract over what
it means to return with a {\em return convention},
%\(\retcon ~ (\mach \in \MACHS) ~ (\mach' \in \MACHS)\),
\(\retcon \subseteq (\MACHS \times \MACHS)\),
which relates call states to the states that can be considered valid returns to that call.
The usual return convention is that \(\mach\) and \(\mach'\) agree on the stack pointer,
and \(\mach'\) has its program counter advanced by one instruction from \(\mach\).

Each state element is assigned to a {\em domain}, which may be {\em outside}
of the stack entirely, {\em unsealed} and therefore accessible, or {\em sealed}
at a particular depth. Each caller registers a {\em target}
condition, \(\target \subseteq \MACHS\), which is a predicate on machine states that means it
has been returned to.
A context is a pair of a ``domain map'' from elements to domains, and a
``return target list,'' which is a stack of targets, one for each caller awaiting
return.
%
\[\stackDom \in \STKDOMS ::= \outside + \unsealed + \sealed{\depth}\]
\[(\domMap,\rts) = \context \in \CONTEXTS ::= (\COMPONENTS \rightarrow \STKDOMS)
  \times (\listT (\target)) \]
%
The initial context \(\context_0 = \domMap_0, []\), where \(\domMap_0\) maps
the stack to \(\unsealed\) and all other addresses and all registers to \(\outside\).


The rules for \(\stepsto_C\) are given inductively, and apply in the listed order.
A call annotation tells us to push the return target onto the return stack and
seal all elements with the depth of the previous return stack.
(Recall that the code map \(\codemap\) is a partial function, and we can use its domain
as a predicate on addresses.) If we aren't making a call,
we identify a return by looking ahead and checking if we're about to step to a state
that matches the topmost return target ({\sc ReturnFound}), and unsealing the caller's frame if so.
If a target is reached anywhere in the return stack, {\sc ReturnRec}
unseals each frame down to the level that was returned to.
If none of these situations hold, the context remains unchanged.

\judgmenttwobrlong[ Call]
              {\(\codemap ~ (\mach ~ \PCname)\)}
%              {\(\components = \sealcon ~ \mach\)}
              {\(\components = \{\component | \sealcon ~ \mach ~ \component\}\)}
              {\(\domMap' = \domMap[\components \mapsto \sealed{|\rts|}]\)}
                {\(\mach,(\domMap,\rts) \stepsto_C \domMap',(\retcon ~ \mach)::\rts\)}

\vspace*{-1ex}
\judgmenttwo[ ReturnFound]
              {\(\mach \stepsto \mach' \in \target\)}
              {\(\components = \{\component | \domMap ~ \component = \sealed{|\rts|}\}\)}
              {\(\mach,(\domMap,\target::\rts) \stepsto_C \domMap[\components \mapsto \unsealed],\rts\)}

\vspace*{-1ex}
\judgmentbr[ ReturnRec]
            {\(\mach,(\domMap,\rts) \stepsto_C \domMap',\rts'\)}
            {\(\components = \{\component | \domMap ~ \component = \sealed{|\rts|}\}\)}
            {\(\mach,(\domMap,\underscore::\rts) \stepsto_C \domMap'[\components \mapsto \unsealed],\rts'\)}
\vspace*{-2.5ex}
\judgment[ Default]
         {}
         {\(\underscore,\context \stepsto_C \context\)}

\noindent
When we build machine traces with this step function, we always know how deep in the
call stack we are and which elements are sealed.

We now state our properties.
The first is {\em stepwise stack integrity}, where ``stepwise'' means that the property is
quantified over each step of execution from any initial state. The criterion for integrity
is simple: sealed elements do not change.

\definition
The \emph{protected set} of a context, \(\prot(\domMap,\_)\), is the
set of elements \(\component\) such that \(\domMap ~ \component = \sealed{\depth}\)
for some depth \(\depth\).

\definition
A system enjoys \textit{\textbf{stepwise stack integrity}} if, for any reachable state
\(\mach,\pol,\context\) such that \(\mach,\pol,\context \stepstocon \mpcstatename'\),
and any element \(\component \in \prot(\context)\),
\(\pi_\mach(\mpcstatename') ~ \component = \mach ~ \component\).

Next we consider {\em stepwise stack confidentiality}. Recall that our properties are
nested: we will quantify over subtraces that represent whole calls. For each
subtrace, we quantify over {\em variants} of its initial state. Then we require
that the original, {\em primary} traces move in {\em lockstep} with the variant.

\definition The \emph{call set} \(\MPCT^*\) of a machine is
\[\begin{aligned}
\bigcup_{\depth \in \mathbb{Z}} \{\MPCT, \neg f_\depth | \MPCT\langle f_\depth \rangle
\text{ is a reachable segment}\} \hspace{1em} \\
\text{where } f_\depth ~ (\mach,\pol,(\domMap,\rts)) \triangleq |\rts| \geq \depth \\
\end{aligned}\]

This is the set of all possible calls that can be reached from any well-formed initial state.

We term \(\neg f_\depth\) the {\em break condition} \(\brk\), a predicate on
states that holds on \(\MPCT\)'s final state, {\em unless it terminated prematurely due to a failstop}.

\definition Machine states \(\mach\) and \(\nach\) are {\em \(\components\)-variants},
written \(\mach \approx_\components \nach\), if, for
all \(\component \not \in \components\), \(\mach ~ \component = \nach ~ \component\).

\definition The \emph{difference} of two machine states \(\mach\) and \(\mach'\), written \(\Delta(\mach,\mach')\),
is the set of elements \(\component\)
such that \(\mach ~ \component \not = \mach' ~ \component\).

\definition Two pairs of states \((\mach,\mach')\) and \((\nach,\nach')\)
 {\em change together}, written \((\mach,\mach') \diamond (\nach,\nach')\), if, for all elements \(\component\) in
\(\Delta(\mach,\mach') \cup \Delta(\nach,\nach')\),
\(\mach' ~ \component = \nach' ~ \component\).

\definition A pair of traces \(\machT\) and \(\nachT\) are {\em in lockstep},
written \(\machT \doteq \nachT\),
if their adjacent pairs of states change together.  We define this as a coinductive relation:

\judgment{}
         {\(\mpcstatename \doteq \npcstatename\)}
\judgmenttwo{\(\mach, \pi_\mach(\head(\machT)) \diamond \nach, \pi_\mach(\head(\nachT))\)}
            {\(\machT \doteq \nachT\)}
            {\(\notfinished{(\mach,\underscore,\underscore)}{\machT} \doteq \notfinished{(\nach,\underscore,\underscore)}{\nachT}\)}

\definition
The \emph{secret set} of a context, written \(\secret(\domMap,\rts)\), is the
set of elements \(\component\) such that \(\domMap ~ \component \not = \outside\).

\definition
A system enjoys \textbf{\textit{stepwise stack confidentiality}} if,
for any \(\MPCT,\brk \in \MPCT^*\) with \(\head(\MPCT) = \mach,\pol,\context\),
any \(\nach\) such that \(\mach \approx_{\mathit{secret}(\context)} \nach\), and any trace
%\(\NPCT\) such that \(\nach,\pol,\domMap \hookrightarrow \NPCT | \brk\),
\(\NPCT\) such that \(\nach,\pol,\context \hookrightarrow \NPCT | \brk\),
\(\MPCT \doteq \NPCT\) holds.

In other words, stepwise stack confidentiality states that if, at the start of the call,
we vary all stack locations that are supposed to be secret from the callee
(which in our simple setting is the entirety of the stack),
the resulting trace remains in lockstep with the original trace
until either both return together or one failstops. This implies that
if the callee reads a secret location, it must failstop.
%
Note that \(\MPCT\) may contain nested calls; these must also respect the secrecy
of the elements in \(\components\), and in addition their subtraces are also in
\(\MPCT^*\), and therefore confidentiality must hold on them separately. \(\NPCT\)
will contain these calls and returns as well, so its return stack pushes and pops
in lockstep until it breaks at the final return.

Finally, we formalize a version of WBCF, which captures the same informal idea
as that of Skorstengaard et al.\cite{SkorstengaardSTKJFP} using our context machinery.
\definition
A system enjoys \textit{\textbf{well-bracketed control flow}} when, for every reachable state
\(\mpcstatename\) where \(\pi_\context(\mpcstatename) = (\underscore,\rts)\), and
\(\mpcstatename \stepsto \mpcstatename'\) where \(\pi_\context(\mpcstatename') = (\underscore,\rts')\),
if \(|\rts'| < |\rts|\), then \(|\rts'| = |\rts|-1\).

\section{Case Study: Micro-Policies}
\label{sec:enforcement}

In this section we explore how an existing enforcement mechanism called {\em
  Depth Isolation}~\cite{DBLP:conf/sp/RoesslerD18} implements
the formal stack-safety property described in the previous
section. We validate this claim
using a property-based random testing framework.

\subsection{A Conservative Stack-Safety Enforcement Mechanism}
%
The enforcement policy of Roessler and DeHon \cite{DBLP:conf/sp/RoesslerD18} relies
on a programmable, tag-based reference monitor that runs alongside the
program,
allowing fine-grained manipulation of metadata tags to encode so-called
\emph{micro-policies}~\cite{pump_oakland2015}.
Every value in
memory and registers (including the $\PCname$)
is enriched with an abstract metadata tag, which can represent
arbitrary information about the value. A micro-policy is then defined as a
set of tags and a
collection of software-defined rules.
At each step of the machine, the relevant rule is applied to the tags on
the instruction's inputs ($\PCname$, registers, memory) and on the
instruction opcode itself, producing
one of two outcomes: either the instruction is permitted to execute (and
generates tags for the result of the operation and the new $\PCname$), or
the machine fail-stops with a policy violation.
Existing work \cite{TestingNI:ICFP,pump_oakland2015, DBLP:conf/sp/RoesslerD18}
%\bcp{additional citations: the noninterference paper, Nick and Andre's papers, ...}
has shown that a wide range of
micro-policies can be defined using this scheme.

Efficient execution of these micro-policies relies on hardware acceleration,
such as the PUMP architecture~\cite{pump:asplos2015}.
The hardware incorporates a rule cache
to allow quick retrieval of rule outputs for mapped inputs. If the cache misses,
the hardware traps to a software handler (running in a privileged context or
on a co-processor) to compute the rule result. To obtain adequate performance,
it is important to design micro-policies so that they hit in the cache as
much as possible. Thus, practical policies need to maintain a small working
set of distinct tags.
%% %
%% \rb{Maybe go into more detail, examples later\ldots or try to segue into stack
%% policies}

%\paragraph{A Conservative Tag Policy}
%\label{sec:conservative}

The micro-policy we present here to illustrate enforcement of stack
safety as defined in \cref{sec:lse} is a small variation
on the {\em Depth Isolation} policy presented by
Roessler and DeHon\cite{DBLP:conf/sp/RoesslerD18}. In their policies,  the stack memory is tagged
with ownership information associated to each stack frame (and to each
separate object inside that frame, a more finely grained access
control that we do not need to consider here), and tags registers containing
stack pointers with access permission information. The policy also
uses tags on instructions to identify the code
sequences that have permission to manage the stack, say during calls and returns.
%\leo{If we have the simple exposition so far, no need to mention the following sentence:}
%In the following, for ease of exposition, we will assume that no
%arguments are passed on the stack.
%% \rb{Conceivably on alloc
%%   operations, etc., which we have not yet mentioned.}

The Depth Isolation micro-policy maintains tags of the form $\tagStackDepth{n}$ for
each stack location belonging to the stack frame at activation depth
$n$, or the tag $\tagNoDepth$ for stack locations that are currently
unused (but could potentially be used in the future).
%
The $\PCname$ is tagged similarly as $\tagPCDepth{n}$.
%
Initially, the entire stack is considered unused (and therefore tagged
$\tagNoDepth$), and the {\PCname} has tag $\tagPCDepth{0}$.
%
During normal execution, the micro-policy rules only permit load and
store operations when the target memory is tagged {\em with the same
  depth} as the current {\PCname} tag, and store operations also when the
target memory is $\tagNoDepth$.

Interesting changes to the tags occur where the program switches from
a caller to a callee or vice-versa:

\begin{itemize}

\item From caller to callee: when the machine executes a call,
  %, when the machine executes an instruction marked as a call in
  % the call map.
  the current
  $\tagPCDepth{n}$ tag is incremented to $\tagPCDepth{(n + 1)}$, and the function
  entry sequence initializes  all locations of the new function frame with
  tag $\tagStackDepth{(n + 1)}$.

\item From callee back to caller: the callee clears its frame, and at
  the actual return instruction,
  the $\PCname$ tag is decremented.

\end{itemize}

This discipline suffices to enforce stack safety.
To implement it,  we define blessed instruction sequences
intended to appear at the entry and exit of each function,
which manipulate tags as just described in addition to performing the
usual calling convention tasks of saving/restoring the return address to/from
the stack and adjusting the stack pointer. With the aid of an additional tag on
the $\rsp$ register, these sequences also serve to enforce
well-bracketed control flow.
The micro-policy guarantees atomic execution of these sequences
using a combination of tags on the instructions
and an additional tag on the $\PCname$.

There remains the question of how to ensure that the sequences are
invoked at the right places from the perspective of the stack-safety
property. For a program to enjoy stack safety
(with respect to a particular call map), all we require is that
the entry sequence immediately follows any instruction marked as a call
in the call map. This is achieved by giving these instructions (another) special tag,
and it is easy to check statically that this has been done correctly.
If the code fails to initiate an exit
sequence at a point where the stack-safety property expects a return,
the micro-policy will incorrectly behave as if execution
is continuing in the callee, but since the callee never has stronger access
rights than the caller, this is harmless.

\subsection{Validation through Random Testing}
\label{sec:testing}

There are several ways to evaluate whether an enforcement mechanism enforces
stack safety properties. Ideally such validation would be done through formal proof over
the semantics of the enforcement-augmented machine.
However, while there are no fundamental barriers to producing such a proof,
it would be considerable work to carry out for a full ISA like RISC-V and
complex enforcement mechanism like the Depth Isolation micro-policy.
We therefore choose to validate the micro-policy of the previous section by
systematically \emph{testing} that it satisfies our properties.
This focus on testing is better aligned with our immediate
goal of evaluating real enforcement mechanisms for real machine architectures.
Formal proof remains as possible future work.

We validate the micro-policy of the previous section by
systematically testing that it satisfies eager stack integrity and
confidentiality. We use a Coq specification of the RISC-V
architecture\bcp{change from footnote to citation :-)}\footnote{Available at
  \url{https://github.com/mit-plv/riscv-coq}.}
%\leo{translated from Haskell via hs-2-coq?\apt{not worth saying since the MIT people did it}}
and extend it with a
runtime monitor implementing the stack-safety
micro-policy. We
  chose the Coq proof assistant as the setting for our implementation
  to ensure that our coinductive trace
  definitions are well-formed, and reason about them, and to leverage the power of the
  QuickChick property-based testing framework~\cite{Pierce:SF4}.

To use QuickChick, we build random test-case generators that produce
% \begin{enumerate}
% \item
(1) an initial RISC-V machine state, including most notably
  the program to be executed;
  % \item
(2)
  an initial policy state, tagging instructions corresponding to
  blessed call or return sequences appropriately, while marking
  all potential stack locations as $\tagNoDepth$; and
% \item
(3)
 a code map identifying the locations of calls.
% \end{enumerate}

That is, our generators need to produce not only a low-level program
that exhibits interesting control-flow patterns, but also the policy
meta-information and code annotations that would normally be produced
by the compiler.

%\paragraph*{Generators}
%
%To write such generators we build on the work of
%Hri\c{t}cu et al. \cite{TestingNI:ICFP, DBLP:journals/jfp/HritcuLSADHPV16}, which
%introduced {\em generation by execution} to produce progams that lead
%machines towards interesting behaviors. Generation by
%execution receives as an input a partially instantiated machine state
%and attempts to generate an instruction (or a sequence of instructions
%such as a blessed sequence) that makes sense locally (e.g., jumps go
%to a potentially valid code location and loads read from a
%potentially valid stack location). Then we step the machine and repeat
%the process until we generate or execute some target number of
%instructions, or reach a point where the machine cannot step
%any more.
%
%We extend this technique to keep track of the control flow behavior of
%the program being generated: each time a call or return sequence is
%generated, we ensure that the appropriate policy tags and code
%annotations are set for the entry or return points.% At the same time,
%%we allow the generation to sometimes relax those constraints,
%%introducing potentially ill-formed flows: this causes our programs
%%to failstop when executed in conjunction with the policy monitor,
%%but also allows for revealing errors in our setup.\apt{??}
%
%In addition, we need to further extend this technique to handle the nested
%nature of our confidentiality property: rather than just generating two
%initial machines that are variants of one another and letting them
%execute to test for noninterference, we generate a new variant
%{\em every time a call is made} and check confidentiality for the
%subtrace produced from that variant state until its corresponding
%return. As a result, a ``single'' confidentiality test compactly
%checks the confidentiality of multiple nested calls.

\paragraph*{Findings}

To ensure the effectiveness of testing against our formal properties, we
use {\em mutation testing}~\cite{JiaH11}. In mutation testing, we inject errors
(mutations) in a program that should cause the property of interest (here,
stack safety) to fail, and ensure that the testing framework can find
them. The bugs we use for our evaluation are either artificially generated
by us (deliberately weakening the micro-policy in ways that we expect
should break its guarantees), or actual bugs that we discovered through
testing our implementation. We elaborate on some such bugs below.

\begin{table}[]
\centering
\begin{tabular}{c|c|c|c}
  Bug & Property Violated & MTTF (s) & Tests \\
  \hline
      {\em LOAD\_NO\_CHECK}  & Confidentiality & 24.2 & 13.3 \\
      {\em STORE\_NO\_CHECK} & Integrity & 26.9 & 26 \\
      {\em HEADER\_NO\_INIT} & Integrity & 69.5 & 76.3 \\
\end{tabular}
\vspace*{1em}
\caption{MTTF for finding bugs in erroneous eager policy enforcement mechanisms}
\vspace*{-2em}
\label{tab:bug-table}
\end{table}

The mean-time-to-failure (MTTF) and average number of tests for various bugs can be found in
Table~\ref{tab:bug-table}, along with the average number of tests
it took to find the failure. Experiments were run in a desktop
machine equipped with i7-4790K CPU @ 4.0GHz with 32GB RAM.
% \leo{Something like: There is really no baseline to compare this
  %against, but include it here for the future/reasons?}
%
The artificially injected bugs weaken the tag propagation
and checking mechanism.
%
For example, when loading from a stack location, the correct
micro-policy needs to enforce that the tag on the location being read
is $\tagStackDepth{n}$ for some number $n$ and that the tag of the
current $\PCname$ is $\tagPCDepth{n}$ for the same depth $n$. We can relax
that restriction by not checking the depth equality (row {\em
  LOAD\_NO\_CHECK}).
%
Similarly, when storing to a stack location, the correct micro-policy
needs to ensure that the tag on the memory location is either
$\tagNoDepth$ or has again the same depth as the current $\PCname$
tag. Relaxing that constraint causes violations to the integrity
property (row {\em STORE\_NO\_CHECK}).

Naturally, testing also revealed a number of errors in our
implementation of the enforcement mechanism (the original was written in C++
and targeted ARM machine code;
%\bcp{right?}\leo{yeah}
we re-implemented it in Coq targeting RISC-V).  These errors range
from trivial typos to ones that require an intriguingly complex setup
to appear.  The most interesting bug (included in the table as row
{\em HEADER\_NO\_INIT}) was that, on our first try, the blessed call
sequence %/policy combination\apt{??}
did not initialize all locations for the
newly allocated stack frame correctly, but left some of them as
$\tagNoDepth$. This allowed for a potential integrity violation, but
only if a rather complicated sequence of events occured.
The smallest counterexample requires calling a function {\tt f},
which fails to initialize some of its frame during the blessed sequence,
but writes into an uninitialized location $l$ later, treating \(l\) as outside
the stack. Then {\tt f} calls a further function {\tt g} (which should have
the effect of sealing $l$ for integrity purposes). {\tt g} attempts to write to $l$,
which is allowed because the enforcement mechanism still has
$l$ tagged as $\tagNoDepth$, but violates the integrity property on {\tt f}'s data.
%\sna{I believe what went wrong was that we were off-by-one in {\tt main}'s initialization,
%  and the write from {\tt f} was already a violation.}

\section{Observable Stack Safety}
\label{sec:lazy}

The conservative policy described in the previous section, while
testably enforcing stack safety, is rather slow in
some important practical cases. Roessler and DeHon\cite{DBLP:conf/sp/RoesslerD18} observe
that most of the performance overhead incurred
stems from the need to set stack activation tags as a frame is created
and reset them as it is destructed;  this
is particularly costly for frames that contain large uninitialized arrays.
To mitigate those costs, they eliminate the costly frame initialization pass.

Under the most optimized version of the micro-policy, {\em Lazy Tagging and Clearing},
it does not initialize stack frames on entry \emph{or} clear them on exit,
and it permits all writes to the stack, even when the $\PCname$ tag
does not match the memory tag; the \(\PCname\) tag is always propagated
to the written location. Reads from the stack \emph{do} require $\PCname$
tag and memory tag to match. Thus, even if a callee illicitly writes to
a private location in its caller, the caller will eventually detect this
if it ever tries to read from that location.

This \emph{lazy policy} admits more a efficient implementations, but
they deliberately allow temporary violations of stack integrity.
The natural question then is: how do we characterize the
protections provided by these policies once stepwise stack safety is broken?
How does a harmful violation that must be caught later differ from a
harmless one?

Beyond this one enforcement mechanism, some code features may involve
moving data, overwriting its original location,
and ultimately restoring it before the change becomes visible; for example, the
``callee-saves'' registers in some calling conventions will be stashed and restored.
These examples call for an abstract mechanism to characterize behaviors that are externally
\emph{observable}.

So we extend our model with a notion of observations. We abstract over an
observation type \(\obs \in \OBSS\), containing at minimum the silent observation
\(\tau\). Our machine step function now takes a state and returns a state and an observation,
which is carried over into the policy and context step functions:

\paragraph*{Observations-Of}

This operator, written \(\obsof\), takes a machine trace and
gives the trace of observations of each step in
the trace. It uses a coinductive helper \(\mathit{obsfor}\) that relates an
initial observation, a machine-trace, and an observation trace; the helper is
then invoked with an initial \(\tau\).

  \judgmentthree{\(\mpcstatename \stepstocon[\obs'] \mpcstatename'\)}
                {\(\mpcstatename' \hookrightarrow \MPCT\)}
                {\(\mathit{obsfor} ~ \obs' ~ \MPCT = \obsT\)}
                {\(\mathit{obsfor} ~ \obs ~ \notfinished{\mpcstatename}{\MPCT} = \notfinished{\obs}{\obsT}\)}

\begin{minipage}[b]{.4\columnwidth}
  \judgment{}
           {\(\mathit{obsfor} ~ \obs ~ \mpcstatename = \obs\)}
\end{minipage}
\begin{minipage}[b]{.4\columnwidth}
\judgment{\(\mathit{obsfor} ~ \tau ~ \MPCT = \obsT\)}
         {\(\obsof(\MPCT) = \obsT\)}
\end{minipage}

\paragraph*{Observational Similarity}

We say that two observation traces $\obsT_1$ and $\obsT_2$ are {\em similar}
from the perspective of an external observer, written \(\obsT_1 \eqsim
\obsT_2\), if the sequence of non-silent observations is the same. That is, we
compare up to deletion of \(\tau\) observations, coinductively:

\begin{minipage}{.4\columnwidth}
  \judgment{}{\(\obsT \eqsim \obsT\)}
\end{minipage}
\begin{minipage}{.4\columnwidth}
  \judgment{\(\obsT_1 \eqsim \obsT_2\)}
           {\(\notfinished{\tau}{\obsT_1} \eqsim \obsT_2\)}
\end{minipage}

\begin{minipage}{.4\columnwidth}
  \judgment{\(\obsT_1 \eqsim \obsT_2\)}
           {\(\obsT_1 \eqsim \notfinished{\tau}{\obsT_2}\)}
\end{minipage}
\begin{minipage}{.4\columnwidth}
  \judgment{\(\obsT_1 \eqsim \obsT_2\)}
           {\(\notfinished{\obs}{\obsT_1} \eqsim \notfinished{\obs}{\obsT_2}\)}
\end{minipage}


Note that an infinite silent trace is a
prefix of (and similar to) any other trace. While this might seem
surprising at first, it makes sense in a timing-insensitive context:
an external observer looking at two machine runs cannot (computably)
distinguish between a machine that steps forever and a machine that
steps for a long time before producing some output.

\paragraph*{Observational Stack Safety}

We now sketch observational versions of both integrity and confidentiality.
Integrity is already straightforward, simply weakening the condition that must hold
after the return---instead of preventing dangerous writes from being read, we
prevent them from being leaked.

\definition
\textbf{\em Observational integrity} means that for any \(\MPCT,\brk \in \MPCT^*\)
where \(\head(\MPCT) = \mach,\pol,\context\) and \(\last(\MPCT) = \mach',\pol',\context'\),
the following holds. Let \(\components\) be the set of protected elements that changed during
the call, \(\components = \prot(\context) \cap \Delta(\mach, \mach')\),
and let \((\mach',\pol',\context') \hookrightarrow \MPCT'\).
Then for any \(\nach\) such that
\(\mach' \approx_{\components'} \nach\), and its induced trace
\((\nach,\pol',\context') \hookrightarrow \NPCT\), \(\obsof(\MPCT') \simeq \obsof(\NPCT)\).

\medskip

Confidentiality is more sophisticated. We must capture the intuition that
secrets do not escape during a call {\em and} are not leaked during a return.
This require us to be able to quantify over elements that fail to preserve
the change-together relation \(\diamond\).

\definition Let \(\mach,\mach'\) and \(\nach,\nach'\)
be pairs of states. Their {\em unsafe set}, written
\(\bar{\Diamond}(\mach,\mach',\nach,\nach')\), is the set of all elements
\(\component \in \Delta(\mach,\mach') \cup \Delta(\nach,\nach')\) where
\(\mach' ~ \component \not = \nach' ~ \component\).

\definition
A system enjoys \textbf{\em observational confidentiality} if for all
\(\MPCT,\brk \in \MPCT^*\), with \(\head(\MPCT) = \mach,\pol,\context\) and
\(\components = \secret(\context)\), the following holds.
%
For any \(\nach\) such that \(\mach \approx_\components \nach\) and
\(\nach \hookrightarrow \NPCT | \brk(\MPCT)\),
\(\MPCT\) and \(\NPCT\) respect three conditions:

\begin{itemize}
\item They are observationally equivalent, \(\obsof(\MPCT) = \obsof(\NPCT)\),
  meaning that no secrets leak during the call
\item \(\brk ~ (\last(\MPCT)) \leftrightarrow \brk ~
(\last(\NPCT))\), i.e. if one call returns, so does the other
\item Assuming both calls return, let \(\last(\MPCT) = \mach',\pol',\context'\)
  and \(\pi_\mach(\last(\NPCT)) = \nach'\),
  let \(\components' = \components \cap \bar{\Diamond}(\mach,\mach',\nach,\nach')\),
  and let \(\nach''\) be a state such that \(\mach' \approx_\components \nach''\).
  Then if \(\mach',\pol',\context' \hookrightarrow \MPCT'\) and
  \(\nach',\pol',\context' \hookrightarrow \NPCT'\), it must be
  that \(\obsof(\MPCT') \simeq \obsof(\NPCT')\)
\end{itemize}

This last condition is the most interesting: we identify the elements that
contain leaked information on either side of the first pair of variant traces.
This becomes the basis for the second variation, as all of these values
must be protected from leaking for the remainder of the program.

These two properties give us
{\em Observable Stack Safety}. This is a weaker property
than the stepwise one, and also much more extensional.
We can think of the stepwise properties as instantiating
the observation model with a view of the entire state, and
thus as one end of a spectrum that can become arbitrarily permissive.
Therefore, if we had to choose a single property to represent stack safety,
it would be the observational formalization.

\subsection{Connection to Policies}

Observable properties allow us to defer enforcement until a property
violation would become visible. Now we can identify when lazy policies
miss such violations, which are again susceptible to testing;
Table~\ref{tab:lazy-bug-table} summarizes the results of our evaluation.
The Lazy Tagging and Clearing
micro-policy from Roessler and DeHon \cite{DBLP:conf/sp/RoesslerD18} in fact
allows violations of observable stack safety!
Our implementation of this policy, {\em PER\_DEPTH\_TAG}, has an error that we find
in testing. If, at depth \(d\), a callee \(A\) writes into its caller's
frame, then returns, and later another callee \(B\) at depth \(d\) reads the same
address and prints it, \(A\) has violated integrity in a way that later becomes visible,
and \(B\) has likewise violated confidentiality!

Lazy Tagging and Clearing can be repaired if, instead of tagging each function
activation with its depth in the stack, we generate a fresh activation
identifier on each call, which prevents a program from exploiting stale
tags from previous activations.
(A related mechanism was explored in the
Static Authorities policy of Roessler and DeHon \cite{DBLP:conf/sp/RoesslerD18}, which
associates a unique \emph{static} identifier to each function, which is shared
by all activations---but that policy allows leaks between
instances of the same function.)

We test {\em Lazy Per-activation Tagging and Clearing}, in which
each activation is tagged uniquely, and find that it obeys stepwise
confidentiality and observational integrity. To round out our mutations testing
we also check an equivalent to {\em LOAD\_NO\_CHECK} and a version where
stores succeed but fail to propagate the PC tag, {\em STORE\_NO\_UPDATE}.
It turns out that {\em PER\_DEPTH\_TAG} is a comparatively subtle bug,
taking twice as long to catch as the next longest.

\begin{table}[]
\centering
\begin{tabular}{c|c|c|c}
        Bug & Property Violated & MTTF (s) & Tests \\
  \hline
        {\em PER\_DEPTH\_TAG} & Obs. Integrity & 189.7 & 8342.5  \\
        {\em LOAD\_NO\_CHECK}  & Obs. Integrity & 23.5 & 12.0 \\
        {\em LOAD\_NO\_CHECK}  & Confidentiality & 19.2 & 695.5 \\
        {\em STORE\_NO\_UPDATE} & Obs. Integrity & 70 & 80.6  \\
        {\em STORE\_NO\_UPDATE} & Confidentiality & 4.9 & 88.5 \\
\end{tabular}
\vspace*{1em}
\caption{MTTF for finding bugs in erroneous lazy policy enforcement mechanisms}
\vspace*{-2em}
\label{tab:lazy-bug-table}
\end{table}


Our abstract properties have allowed us to identify an enforcement mechanism as
not really stack safe, and to validate a possible fix.
Unfortunately, Lazy Per-activation Tagging and Clearing
puts severe pressure on the tag cache, so it may not be usable in practice.
However, we conjecture that no lazy scheme can be fully stack safe
without using unique per-activation identifiers.

\subsection{Callee-saves Registers}
\label{sec:callee}

Another application of observational properties is characterizing a ``callee-saves''
calling convention.
Intuitively, a caller expects a callee-saves register to be unchanged on
return, but it
may change during the call, as long as it is restored. We similarly expect a callee-saves
register to be secret from the callee, except when it is copied to the stack. Both scenarios
reflect observational rather than stepwise stack safety.

We begin by adding information to Call annotations defining which registers will be {\em saved}
and which are {\em unsaved}. The stack pointer and the register containing the return address
should never be saved. We then extend the set of domains with these values, for the first time applying
(non-{\em outside}) domains to registers as well as addresses.
%
\[\begin{split}
\codemap \in \CODEMAPS ::= & \WORDS \rightharpoonup \callmap(S)\\
\mbox{\rm{where}} ~ & S \in \REGS \rightarrow (\unsaved + \saved) \\
\end{split}\]

\[\begin{split}
\stackDom \in \STKDOMS ::= & \outside + \unsealed + \sealed{\depth} \\
& + \unsaved + \saved
\end{split}\]
%
\judgmenttwobrlong[ Call]
                  {\(\codemap ~ (\mach ~ \PCname) = \callmap(S)\)}
                  {\(\components = \{\component | \sealcon ~ \mach ~ \component\}\)}
                  {\(\domMap' = \domMap[\components \mapsto \sealed{|\rts|}][\reg \mapsto S(\reg) ~ | ~ r \in \REGS]\)}
                  {\(\mach,(\domMap,\rts) \stepsto_C \domMap',(\retcon ~ \mach)::\rts\)}
The remaining rules are the same as in the simple model.

\definition Let the protected set of a context, \(\prot_S(\domMap,\rts)\),
be the set of elements \(\component\) such that either \(\domMap ~ \component = \sealed{\underscore}\)
or \(\domMap ~ \component = \saved\).

\definition Let the secret set of a context, written \(\secret_S(\domMap,\rts)\),
be the set of elements \(\component\) such that
\(\domMap ~ \component = \sealed{\underscore}\), \(\domMap ~ \component = \unsealed\), or
\(\domMap ~ \component = \saved\).

\definition
%
\textbf{\em Observational stack integrity} with callee-saves registers substitutes the above
\(\CONTEXTS\) type and update function, and \(\prot_S\), for its equivalent in the simple model.
%
\textbf{\em Observational stack confidentiality} additionally substitutes \(\secret_S\).

\section{Extensions}
\label{sec:ext}

We have seen how our properties apply to an extremely simple
subroutine model.
What about more realistic uses of the stack? We now demonstrate the
flexibility of our core concepts by extending
them to a system that models the passing of
parameters on the stack (Section~\ref{sec:passing}), to callee-saves
registers  (\ref{sec:callee}), and to a very simple coroutine model
(\ref{sec:coroutines}).

\subsection{Parameters Passed on the Stack}
\label{sec:passing}

\newcommand{\mainpassc}{magenta}

\begin{figure*}
  \centering
  \begin{subfigure}[t]{.2\textwidth}
{\small
\begin{verbatim}
int *stash = 0;
int main() {
  int x, y;
  f(x);
  x = 0;
  f(y);
  return x;
}





void f(int &a) {
  if(!stash)
    stash = &a;
  *stash = 5;
  return;
}
\end{verbatim}
}
  \end{subfigure}
  \begin{subfigure}[t]{.47\textwidth}
{\small
\begin{verbatim}
   stash: .word 0
1  main:  add $2,%sp      ; alloc frame
2         mov %sp,%ra
3         add -2,%ra      ; ra = &x
4         call f          ; SHARE: %sp-2
5         mov $0,-2(%sp)  ; x = 0
6         mov %sp,%ra
7         add -1,%ra      ; ra = &y
8         call f          ; SHARE: %sp-1
9         mov -2(%sp),%ra ; set return
10        sub $2,%sp      ; dealloc frame
11        ret

20 f:     cmp stash, $0   ; stash = 0?
21        breq #13        ; branch if so
22        mov %ra,stash   ; stash = &a
23        jmp #15
24        mov $5, (stash) ; *stash = 5
25        ret
}
\end{verbatim}
}
  \end{subfigure}
  \begin{subfigure}[t]{.27\textwidth}
    \begin{center}
    \begin{tabular}{l l}
      {\tt 20} &
      \memoryaddrs[(1)]{17em}
      \memory{1}{\mainpassc}[{\makebox[0pt]{\passdesc{0}{1}}}]%
      \memory{1}{\mainsealc}[{\makebox[0pt]{\sealdesc{0}}}]%
      \memory{1}{\retptrc}
%      \memory{1}{\unsealc}
      ~$\cdots$ \\
      {\tt 25} &
      \memoryaddrs[(1)]{17em}
      \memory{1}{\mainpassc}
      \memory{1}{\mainsealc}
      \memory{1}{\retptrc}
%      \memory{1}{\unsealc}
      ~$\cdots$
      \MemoryLabel{-18em}{0.75em}{5}
      \\
      {\tt 8} &
      \memoryaddrs[(0)]{12em}
      \memory{3}{\unsealc}
      ~$\cdots$
      \MemoryLabel{-18em}{0.75em}{0}
      \\
      {\tt 20} &
      \memoryaddrs[(1)]{17em}
      \memory{1}{\mainsealc}[{\makebox[0pt]{\sealdesc{0}}}]%
      \memory{1}{\mainpassc}[{\makebox[0pt]{\passdesc{0}{1}}}]%
      \memory{1}{\retptrc}
%      \memory{1}{\unsealc}
      ~$\cdots$
      \MemoryLabel{-18em}{0.75em}{0}
      \\
      {\tt 25} &
      \memoryaddrs[(1)]{17em}
      \memory{1}{\mainsealc}
      \memory{1}{\mainpassc}
      \memory{1}{\retptrc}
%      \memory{1}{\unsealc}
      ~$\cdots$
      \MemoryLabel{-18em}{0.75em}{\bf 5}
\end{tabular}
\end{center}
\end{subfigure}
\caption{A violation with pass-by-reference}
\label{fig:passing}
\end{figure*}

To this point we have ignored function arguments, by assuming that they are placed
in registers (which are implicitly shared by all functions).
We now show how to implement two kinds of protected
sharing of stack contents: passing by value on the stack, and passing by reference. We first explore
some examples and then extend our formalization.

Example~\ref{fig:passingsimple} shows a sample trace of a program that passes
variables by reference. In this example, written in C++ notation,
{\tt f} takes a single argument by reference (the diagram displays it in magenta). The function
{\tt main} calls {\tt f}, passing a reference to {\tt x}, then clears {\tt x} and calls
{\tt f} again, passing a reference to {\tt y}.
We would expect that the first call to {\tt f} can modify
{\tt x}, but not the second. Unfortunately {\tt f} has hidden away our reference and modifies
{\tt x} in the second call. (Incidentally, this is perfectly compilable C++,
although its behavior is officially undefined.)

To avoid cluttering the picture at the assembly level, we revert to assuming that the
argument {\tt a} is passed in a register, namely {\tt \%ra}.
The question is how the local variables {\tt x} and {\tt y} themselves
should be labelled in order for the property to correctly classify an integrity violation.
Our notion of domains is extended to include \(\passed{\depth,\depth'}\),
recording two depths for reasons explained below.
At the initial call, the address of {\tt x} is marked as passed, and {\tt f} is free to write to it. Then upon
return, {\tt main}'s frame is unsealed. At the second call it is the address of {\tt y} that is marked as passed,
and when {\tt f} instead tries to write to {\tt x}, it violates integrity.
%For that matter
%a future call with no arguments passed by reference would also violate integrity if it wrote
%to either variable.

When passing by reference, it is possible to repeatedly pass the same reference further
and further down the stack. Note, however, that this sharing of the reference must be over
an unbroken chain of calls. So it suffices for the domain to track two depths for each passed
cell: the original owner, and the highest depth it has been passed to. The policy considers
it to be accessible anywhere between the two.

Our approach provides only limited support for handling fully first-class pointers into
stack frames, e.g., pointers obtained by taking the address of a local variable.
Unlike with pass-by-reference, there is no obvious way to model the intended
sharing behavior of such pointers in terms of stack frame activation patterns.
In general we expect such a pointer to behave similarly to other pointers in
the system, except that its lifespan is connected to that of the frame that contains
it. In order to give a satisfactory property, then, we would tie it to an existing (e.g.)
heap safety property.

The default otherwise would be to treat an address-taken variable in the
same way as a passed argument, with the additional property
that it remains accessible at \emph{all} stack depths above the caller.
This prevents most violations of temporal safety, although stale pointers
can still be used in certain corner cases. Callees would be permitted
to access the location without having been explicitly given a pointer
to it.
%\sna{This is trying to get toward what we were saying at OOPSLA: it's not
%  a technical obstacle, it's that the behavior is tied to things we don't model.}
\paragraph*{Formalization of variable passing.}
We add extra information to our call
annotations to reflect that they may now pass variables on the stack, and that the locations
of those variables may be dynamic (as in the case of pass-by-reference).
A call annotation now includes a predicate relating machine states to the elements
that should be passed, expressed as offsets from the stack pointer.
\[\codemap \in \CODEMAPS ::= \WORDS \rightharpoonup \callmap(P)~\mbox{\rm where}~P \subseteq \WORDS\]
We extend the set of domains to include passed elements,
which are labeled with the range of depths of the caller that has passed them.
\[\begin{split}
\stackDom \in \STKDOMS ::= & \outside + \unsealed\\
& + \sealed{\depth} + \passed{\depth,\depth'}
\end{split}\]
The definition of context looks the same, but is based on the revised definition of \(\STKDOMS\):
\[\context \in \CONTEXTS ::= (\domMap \in \COMPONENTS \rightarrow \STKDOMS)
\times (\rts \in \listT (\target)) \]
The initial context again maps all elements to \(\unsealed\).
We straightforwardly describe how the sealing convention and passing predicate combine to
update a domain map at a call from depth \(\depth\).

\judgmentthree[]
              {\(\domMap ~ \component = \unsealed\)}
              {\(\sealcon ~ \mach ~ \component\)}
              {\(\component - (\mach ~ \rsp) \not \in P\)}
              {\((\mathit{push} ~ \domMap ~ \sealcon ~ P ~ \mach ~ \depth) \component = \sealed{\depth}\)}
\judgmentthree[]
              {\(\domMap ~ \component = \unsealed\)}
              {\(\sealcon ~ \mach ~ \component\)}
              {\(\component - (\mach ~ \rsp) \in P\)}
              {\((\mathit{push} ~ \domMap ~ \sealcon ~ P ~ \mach ~ \depth) \component = \passed{\depth,\depth+1}\)}
\judgmentthree[]
              {\(\domMap ~ \component = \passed{\depth',\depth}\)}
              {\(\sealcon ~ \mach ~ \component\)}
              {\(\component - (\mach ~ \rsp) \in P\)}
              {\((\mathit{push} ~ \domMap ~ \sealcon ~ P ~ \mach ~ \depth) \component = \passed{\depth',\depth+1}\)}
\judgment[]
         {}
         {\((\mathit{push} ~ \domMap ~ \sealcon ~ P ~ \mach ~ \depth) \component = \domMap ~ \component\)}

         At the matching return we just unseal the elements at depth \(\depth\):

\judgment[]
         {\(\domMap ~ \component = \sealed{\depth}\)}
         {\((\mathit{pop} ~ \domMap ~ \depth) \component = \domMap ~ \component\)}
\judgment[]
         {\(\domMap ~ \component = \passed{\depth-1,\depth}\)}
         {\((\mathit{pop} ~ \domMap ~ \depth) \component = \domMap ~ \component\)}
\judgmenttwo[]
           {\(\domMap ~ \component = \passed{\depth',\depth}\)}
           {\(\depth' < \depth\)}
           {\((\mathit{pop} ~ \domMap ~ \depth) \component = \domMap ~ \component\)}
\judgment[]
         {}
         {\((\mathit{pop} ~ \domMap ~ \depth) \component = \domMap ~ \component\)}

Now we can inductively define the context update function, as before.

\judgmenttwo[ CallSeal]
            {\(\codemap ~ (\mach ~ \PCname) = \callmap(P)\)}
            {\(\domMap' = \mathit{push} ~ \domMap ~ \sealcon ~ P ~ \mach ~ |\rts|\)}
            {\(\mach,(\domMap,\rts) \stepsto_C \domMap',(\retcon ~ \mach)::\rts\)}

\vspace*{-1ex}
\judgmenttwo[ ReturnFound]
            {\(\mach \stepsto \mach' \in \target\)}
            {\(\domMap' = \mathit{pop} ~ \domMap ~ |\rts|\)}
            {\(\mach,(\domMap,\target::\rts) \stepsto_C \domMap',\rts\)}

\vspace*{-1ex}
\judgmenttwo[ ReturnRec]
              {\(\mach,(\domMap,\rts) \stepsto_C \domMap',\rts'\)}
              {\(\domMap'' = \mathit{pop} ~ \domMap' ~ |\rts|\)}
              {\(\mach,(\domMap,\underscore::\rts) \stepsto_C \domMap'',\rts'\)}

\vspace*{-3ex}
\judgment[ Default]
         {}
         {\(\underscore,\context \stepsto_C \context\)}

\definition The \emph{protected set} of a context, \(\prot_P(\domMap,\rts)\),
is the set of elements \(\component\) such that either \(\domMap ~ \component = \sealed{\underscore}\)
or \(\domMap ~ \component = \passed{\depth,\depth'}\) and \(|\rts| < \depth\) or
\(|\rts| > \depth'\).

\definition The \emph{secret set} of a context, written \(\secret_P(\domMap,\rts)\),
is the set of elements \(\component\) such that
\(\domMap ~ \component = \sealed{\underscore}\), \(\domMap ~ \component = \unsealed\), or
\(\domMap ~ \component = \passed{\depth,\depth'}\)
where \(|\rts| < \depth\) or \(|\rts| > \depth'\).

\definition
For each of the \textbf{\em stepwise} and \textbf{\em observational} versions of
\textbf{\em stack integrity} in the simple model, the equivalent property in the
passing model substitutes the above \(\CONTEXTS\) type and update
function, and \(\prot_P\), for their equivalents in the simple model.

For both the \textbf{\em stepwise} and \textbf{\em observational} versions of \textbf{\em stack confidentiality} in
the original model, the passing model equivalents additionally substitute \(\secret_P\).


\subsection{Coroutines}
\label{sec:coroutines}

Our final extension to the model adds coroutines. We assume a very simple model with
a fixed number of coroutines, each with its own stack.
Stack identifiers are drawn from a set \(\STACKS\), and there is a static partial map
\(\stackof\) from addresses to stack ids.  Annotations and code maps are unchanged from
the subroutine model.
%\[\ann \in \ANNS ::= \callmap(P \subseteq \MACHS \times \COMPONENTS)\]
%\[\codemap \in \CODEMAPS ::= \addr \in \WORDS \rightharpoonup \ann \in \ANNS\]

The first major difference in this model is the domains. Stack domains are now nested inside
top-level domains, and associated with stack identifiers.
Our context now consists of a domain map, a map from stack identifiers to return target stacks,
an additional map of targets for yields, and a stack identifier of the active stack.
A yield target map \(\yts\) is a map from stack identifiers to targets.
In a standard system an initial yield target map will map each stack identifier to the
set of all states with their stack pointer at the stack base, and include any restrictions
on entry points. Just as a return target tells us that we have really returned, a yield
target tells us that we have really yielded. When yielding from state \(\mach\),
\(\ycon ~ \mach \in \MACHS\) gives us the yield target for coming back to the yielding
coroutine.
%
\[\topDom \in \TOPDOMS ::= \outside + \instack{\stackid}{\stackDom}\]
\[\begin{split}
\context \in \CONTEXTS ::= &
 (\domMap \in \COMPONENTS \rightarrow \TOPDOMS) \times \\
& (\rtm \in \STACKS \rightarrow \listT(\target)) \times \\
& (\yts \in \STACKS \rightarrow \target) \times \\
& \stackid \in \STACKS
\end{split}\]

The initial domain map maps each stack address in stack \(\stackid\) to
\(\instack{\stackid}{\unsealed}\), the initial return map maps all stack identifiers to empty
return stacks, the initial yield targets are defined above, and the initial stack id matches the initial
coroutine. Together these form the initial context.

In our context update rules, calls and returns work the same as in the subroutine models,
with domain updates restricted to the top-level domain corresponding to the active stack,
and likewise using the return target stacks. We will omit these rules and focus on the new yield rule.

\judgmenttwobr[ Yld]
             {\(\mach \stepsto \mach'\)}
             {\(\stackid' = \stackof ~ (\mach'~ \rsp) \not = \stackid\)}
             {\(\yts ~ \stackid'\)}
             {\(\yts' = \yts[\stackid \mapsto \ycon ~ \mach]\)}
             {\(\mach,(\domMap,\rts,\yts,\stackid) \stepsto_C \domMap,\rts,\yts',\stackid'\)}

This calls for some explanation. First, we determine which coroutine we are yielding to by
checking which stack the stack pointer of the next state is pointing to. Then we can only yield
if the next state is a valid yield target for that stack, and we update the yield target for
the current stack, ensuring that when the system yields back we expect the current coroutine
to continue from where it left off. So, it is possible for a coroutine to claim to yield
but not actually change the active stack, with similar effects to when a callee fails
to return properly. Now we can define both stack safety and coroutine safety under this model.

Stack integrity and confidentiality apply in the coroutine model, based on straightforward
projections of each stack's domains, etc. and the machinery of the passing model. We will give
the coroutine-specific properties.

\definition The \emph{yield set} \(\MPCT^\wedge\) of a system is
\[\begin{aligned}
\bigcup_{\stackid \in \STACKS} \hspace{-.5em} \{\MPCT, \neg f_\stackid | \MPCT\langle f_\stackid \rangle
\text{ is a reachable segment}\} \hspace{1em} \\
\text{where } f_\stackid ~ (\underscore,\underscore,(\underscore,\underscore,\underscore,\stackid')) \triangleq \stackid \not = \stackid' \\
\end{aligned}\]

\noindent
Here, we are capturing the entire span that the system spends {\em away} from a given
coroutine.

\definition
The \emph{protected set} of a context, \(\prot_Y(\domMap,\rtm,\yts,\stackid)\),
is the set of elements \(\component\) such that
\(\domMap ~ \component = \instack{\stackid'}{\underscore}\) where \(\stackid \not = \stackid`\).

\definition
The \emph{secret set} of a context, \(\secret_Y(\domMap,\rtm,\yts,\stackid)\),
is the set of elements \(\component\) such that
\(\domMap ~ \component = \instack{\stackid'}{\underscore}\) where \(\stackid \not = \stackid`\).

\definition
We define \textbf{\em stepwise coroutine integrity} in the same way as stepwise stack integrity,
substituting the above \(\CONTEXTS\) type, initial context and update
function, and \(\prot_Y\) for their equivalents. Likewise
\textbf{\em observational coroutine integrity} is defined
in terms of their simple equivalents using \(\MPCT^\wedge\) in place of \(\MPCT^*\).

\definition
We define \textbf{\em stepwise coroutine confidentiality} in the same way as stepwise stack
integrity, substituting the above definitions. Likewise
\textbf{\em observational coroutine confidentiality} is defined in terms of observational
stack confidentiality.

\section{Related Work}
\label{sec:relwork}

\paragraphx{Formal Stack Safety on Capability Machines}
%
To our knowledge, the only line of work to date that has attempted
a positive and formal characterization of stack safety
is that of Skorstengaard et al. \cite{SkorstengaardSTKJFP}. Their
StkTokens system enforces stack safety on hardware equipped with
memory capabilities, similar to those used in the Cheri system~\cite{Woodruff+14,Chisnall+15}, but
with additional support for linear capabilities.
They define Stack safety as the conjunction of local state encapsulation (LSE) and
well-bracketed control flow (WBCF).
Informally, LSE means that the current activiation can only access its own frame,
and WBCF means that the topmost frame can only return to
the immediately adjacent frame below. Formally, these properties are defined
with reference to a capability machine with a built-in call stack and call and return
instructions; this machine is proven fully abstract with respect to a more
concrete capability machine, an approach termed ``fully abstract overlay semantics.''
We improve upon Skorstengaard et al. \cite{SkorstengaardSTKJFP} in two significant ways:
\begin{enumerate}[label=(\roman*)]
\item Our definition captures the intuition that {\em
  every} caller should be protected from its callees.  By contrast,
  Skorstengaard et al. \cite{SkorstengaardSTKJFP} describe a class of ``unreasonable'' elements
  that are not protected, because they are capable of dynamic behavior that can compromise
  their own security. Consider a function that, when called with the wrong
  inputs, behaves unreasonably. Skorstengaard et al. \cite{SkorstengaardSTKJFP} would not consider this a
  {\em reasonable element} (as defined in their section 4.3.3), as a reasonable
  element is always reasonable. In our setting, individual
  well-behaved activations of the buggy function would be protected.

\item Skorstengaard et al. \cite{SkorstengaardSTKJFP}'s fully
  abstract overlay
  semantics rely on the definition of a ``stack-safe-by-construction''
  abstract machine that is closely tied to the underlying machine architecture.
  While the fundamental approach can no doubt be ported to other architectures and enforcement
  schemes, each such port will require a new abstract machine definition whose
  safety-by-construction property must be checked afresh.
  Since we abstract over most of the machine
  state as well as the sealing and return conventions, our properties apply directly
  to a range of architectures, code features, and enforcement mechanisms.
  Moreover, we have implemented extensions such as passing arguments on the stack,
  describing callee-saves registers, and coroutines by making simple modifications
  to our base domain model.

\end{enumerate}

Skorstengaard et al. \cite{SkorstengaardSTKJFP} propose a useful list of five criteria for judging
candidate stack safety properties.
%% : they should be (1) intuitive; (2)
%% useful for reasoning; (3) reusable in secure compiler chains; (4)
%% arguably ``complete'' with respect to informal notions of stack
%% safety; and (5) potentially scalable to richer settings such as
%% dynamic code generation or multithreading.
%
(1) {\em Intuitiveness}. Our property definitions are at least as
intuitive as theirs, while being phrased in interestingly different terms.
We use the language of formal security
properties to apply well-established concepts and formal techniques
of non-interference, and we define our properties in terms of
traces of memory and register states, rather than in terms of an
ad-hoc abstract machine.
Which approach is ``better'' is probably a matter of taste, but ours
has at least the merit of explicitly relating stack safety to existing
notions of security.
%
(2) {\em Usefulness} of the safety criterion
for carrying out formal proofs (about individual programs). We agree that this is an important consideration;
demonstrating it for our proposal remains future work, in which we
plan to apply our properties to justifying a low-level program logic.
%
(3) {\em Reusability} in secure compilation chains.
StkTokens
is specifically set up to address this,
while it is not a goal of
our work.
%
(4) {\em Comprehensiveness} in capturing programmers' informal
understanding of stack safety. We believe that our support
for dynamically changing notion of adversaries, as outlined in point (i) above,
captures a better definition of safety than LSE; moreover, our observational
properties capture an even richer and more extensional notion of stack safety
that can be applied to a broader range of enforcement mechanisms and code features.
%
(5) {\em Broad applicability} to richer settings. We have demonstrated that our approach extends to
coroutines, a first step towards multithreading. Dynamic code generation is
more challenging, but StkTokens does not yet handle this either.

Finally, we would propose one more criterion: reusability in evaluating multiple machines and
enforcement mechanisms. They have used their approach to give strong validation
to one machine/enforcement mechanism, a linear-capability machine,
via formal proof. We have used ours to obtain a weaker, testing-based validation of
two different mechanisms on a single machine, and will target a capability machine
next as future work.

\paragraphx{Protecting the Stack with Micro-Policies}
%
Roessler and DeHon \cite{DBLP:conf/sp/RoesslerD18}
study the protection of stack data through three families of
micro-policies that tag stack objects with a pair of frame and object identifiers
used to validate accesses: {\em Return Address Protection} (which
prevents an adversary from overwriting designated return addresses), {\em Static
Authorities} (which only allows the code of a function to access the stack frames
of its own dynamic instances), and {\em Depth Isolation}
(\cref{sec:enforcement}). All these policies exploit various kinds of spatial and
temporal locality of stack memory and local call graphs, as well as information
generated by the compilation toolchain, to strike various balances between
precision and cacheability, evaluated through benchmarks that demonstrate
limited performance overhead. In addition to the baseline ``eager'' policies,
they propose a number of lazy optimizations, notably {\em Lazy Tagging} and
{\em Lazy
Clearing} (\cref{sec:lazy}).

We evaluate {\em Depth Isolation}, {\em Lazy Tagging}, and {\em Lazy
  Clearing} against our properties, finding that {\em Depth Isolation} does
indeed enforce stepwise stack safety and therefore observable stack
safety. We also find that neither lazy micro-policy actually enforces
stack safety, and we proposed a fix.

\paragraphx{Heap Safety as a Security Property}
%
Heap safety, like stack safety, may be framed as a security property using
the language of
noninterference~\cite{DBLP:conf/post/AmorimHP18}. Their paper was a significant inspiration
for the present work, and we believe that the two safety conditions should
combine smoothly.

\section{Future Work}
\label{sec:future}

From here, we see two natural ways to extend the work. First, we should thoroughly evaluate
other enforcement mechanisms, especially Cheri-based capability
systems. Second, we can further demonstrate
the functionality of our definitions by showing that they can be used to prove
the correctness of a programming logic with strengthened rules around calls and returns.

\paragraphx{Stack Safety in the Cheri Ecosystem}
%
There are several proposals around the use of Cheri capabilities to enforce stack safety,
including mechanisms that use the standard Cheri hardware (which includes local
capabilities) \cite{SkorstengaardLocal},
and others that propose entirely new types of capabilities, such as linear
\cite{SkorstengaardSTK}, uninitialized \cite{Georges+21}, lifetime
\cite{Tsampas+19}, and monotonic \cite{GeorgesComplete} capabilities.
Of these, uninitialized capabilities seem particularly promising---they naturally enforce
write-before-read behavior and therefore will enable confidentiality without the need
to clear large swaths of the stack. We plan to implement a model of the stack safety
system described in Georges et al. \cite{Georges+21} and test it against our properties using
QuickChick.

\paragraphx{A Program Logic for Stacks}
%
Stack integrity suggests a reasoning principle in which knowledge about a
caller's local data can be carried across a call site. We aim to develop
this idea into a low-level separation logic with a ``call rule'' that
preserves propositions whose domains are sealed across a call, while
allowing those propositions proven about the behavior of the callee to apply
to the accessible stack.
%
It is easy to imagine that such a rule could be proven sound in a system
with lockstep stack safety. More challenging would be to ask what kind of
proof rule would be appropriate for a system that obeys only our
observational properties.

%% Acknowledgments
%\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
%  This material is based upon work supported by the
%  \grantsponsor{GS100000001}{National Science
%    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
%  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
%  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
%  conclusions or recommendations expressed in this material are those
%  of the author and do not necessarily reflect the views of the
%  National Science Foundation.
%\end{acks}


%% Bibliography
\bibliographystyle{ieeetran}
\bibliography{bcp.bib,local.bib}


%% Appendix
%\appendix
%\section{Appendix}
%Text of appendix \ldots

\end{document}
