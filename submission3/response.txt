> Review #416A
> Overall merit

> B. Weak Accept
> Reviewer expertise

> X. Expert
> Paper summary

> This submission formalizes the general notion of stack safety (roughly speaking, every caller should be protected from its callees during program execution) using well-known notions of security (integrity, confidentiality and non interference), and defines several security policies for protecting the stack. The formalization is validated on existing (and less general) micro-policies for stack safety (depth isolation, lazy tagging and lazy clearing) using property-based random testing. This evaluation of former policies detected some security violations in former and less precise works.

> First, this submission introduces the main required security policies, in terms of traces of memory, register states and stepwise stack-safety: stepwise integrity (an execution step does not modify the memory slots that are reserved for a caller at a given depth), confidentiality (a callee is insensitive to the context of its call), stepwise confidentiality, temporal stack safety, and well-bracketed control-flow (calls and returns should be correctly nested). Then, the submission describes the requirements on the machine model (presence of a program counter, used to distinguish between the different stack-frames, and a mechanism for recognizing the return from a call) and the threat model. The machine model is abstract enough to represent different architectures.

> Next, the submission details in a progressive way the formalization of machine behaviors and stack safety using semantic rules. The first formalization of the execution stack is simple, with a single stack and no sharing between callers and callees. Then the model is enriched with function parameters passed on the stack (by value or by reference), with callee-saves registers and with coroutines. Moreover, the first model is implemented in Coq and this implementation reuses an existing RISCV specification. The QuickChick tool is used to test the stepwise property and validate an existing enforcement mechanism (called depth isolation) of the literature. Furthermore, as the previous policy is conservative and rather slow to be practical, more permissive variants of confidentiality and integrity properties are formalized, resulting in an observational property that is again validated by testing.
> Strengths

>    well-written submission, well-explained ideas

>    general formalization that addresses a real challenge and that is validated by testing

> Weaknesses

>    lack of discussion about the limitations of the work

>    medium delta with respect to previous works

> Comments for author

> This submission is well-written, with well-explained ideas. Examples of C and assembly programs are used throughout the submission to illustrate the various dÃ©finitions. The formalization is provided as a supplementary material together with the test cases. The techniques and results of the submission are interesting and general enough to be reused in different settings.

> I am in favor of accepting this paper; however there are a few questions that I would like to be addressed.

*** Questions Begin ***

> Why did you choose this RISCV specification?
> Why didn't you choose to reuse an ARM specification (as there are some of them written in Coq in the literature)?
> Would it be easy to adapt your work to another ISA specification?

We chose RISCV for its simplicity, and because it has been used as the
base ISA for much of the existing work (by others) to design
hardware that supports tag-based micro-policies.

To clarify a possible misunderstanding: the Coq specification of RISCV
that we use was developed by others (see footnote p. 14) and we were
able to adapt it to our testing framework with relatively little
effort.

Our stack safety theory itself is not dependent on the details of the
architecture, as in fact the properties are defined in terms of a
generic interface over machine and enforcement policy; [see ... in the
Coq development]

Performing testing on another architecture such as ARM would require
modifying the testing framework by example generator for the new ISA,
and translating the micropolicy rules to apply to that architecture
and its calling conventions.  This would take some work, but should be
straightforward.

We are currently working on extending the work to a model of a Cheri-style
hardware capability machine, Cerise, and have not encountered major
obstacles.

> How realistic is the RISCV specification? In other words, are there any RISCV vulnerabilities that are not taken into account in your model?

We use the RISCV specification to demonstrate that our properties are testable in
a realistic setting. We do not exercise the entire RISCV specification, and the validity
of the model is not dependent on the absence of vulnerabilities in the RISCV implementation.
That said, the RISCV specification we use is complete for user mode integer instructions
(IV32IM). 

> More generally, what are the limitations of the presented work? For example, in the model, there seems to be no distinction between values and addresses; is it a limitation?

Currently, discussion of our model's limitations is scattered
throughout the paper.  We will expand and organize it into an explicit
section, as follows.

Our goal is to specifically characterize stack safety.  So we are
particularly concerned with limitations that prevent the model from
applying to realistic uses of the stack, and not with other structures
such as the heap, which we intentionally make no guarantees about.

Features that we do not currently support:

- Address-taken locals. As we discuss at line 954ff, a satisfactory
  treatment of these seems to require integration with a more general
  model of memory safety that covers the heap and static globals too.

- Exceptions. We can see a way to extend the model to include them:
  essentially, we would model a "setjump" operation by inserting a
  special target in the return target stack. We would weaken
  well-bracketedness to allow reaching such a target from any
  depth. Since integrity and confidentiality are distinct from
  well-bracketedness and already permit the popping of multiple
  functions from the stack, they can simply treat the exception's
  target as another return target.

- Tail calls. Again, we can see how we might extend the model for them
  Since a tail call is both a call and a return in a single step, our
  normal handling of returns doesn't work -- it would interpret the
  tail call as a call to and immediate return from a new function
  activation. We would need to distinguish tail calls from normal
  calls and essentially process the call and the return in the reverse
  order.

- Dynamic code generation. This would be rather challenging to
  integrate into our framework, because we rely on annotations in the
  code.
[APT: Right? Can we imagine how this might be supported in future?]

- Concurrency. We can handle a limited form of coroutines, as
  described in 8.3. But handling true concurrency would require
  significant changes in our underlying machine model. 

As for the distinction between values and addresses, conventional ISAs
do not make this distinction.  Ongoing work on the Cerise capability
machine formalization has required some modification to distinguish
values from addresses, as they are not the same in a capability
machine, but it has little effect on the model itself. Further,
distinguishing between values and addresses is a higher-level
abstraction that can "hide" potential bugs resulting from implicit
conversions between them, so it may even be preferable to model them
as the same when possible.

> Another example is the outside qualifier that characterizes only a whole component. Wouldn't you need a finer-grain access control policy (and a qualifier for partially outside components)?

There may be some confusion arising from our use of the term
"components."  In our model (see line 398), components are already
fine-grained: individual registers and memory addresses. We recognize
that this is a poor choice of term given the common usage of component
to refer to a larger module in a compartmentalization context, and
will change the term to [SNA: still looking for a word. Atom?
APT: "state element" ?]  Since components/atoms are so fine-grained, there
is no need for finer access control.

> Could you comment on the Coq formalization that is provided as a supplementary material? Was it straightforward to write a Coq program from a C++ program? Moreover, I looked at the Coq development and found some admitted lemmas in it.

See below.

> Other comments

> The supplementary material is not mentioned in the submission. Links to the Coq formalization would have been useful (e.g., for definition 7.4 that I did not fully understand in the submission, as K' is defined but not used, and so is n'').

The supplementary material should indeed be mentioned in the submission.
The Coq formalization provided contains two parts: the formalization of our properties,
which was a conceptual aid in their development and may be useful to readers' intuitions,
and the testing framework, which is used to validate our properties by showing that
computable versions of them are testable.

Admitted lemmas are the beginnings of an effort to formalize [details]

In the case of definition 7.4, this is a typo. The K in the third bullet should be K', and the
last instance of n' should be n''.

Map of the supplementary material:
Core contains the abstract machine and policy models, as well as the RISCV instantiations with different policies.
Properties contains Coq definitions corresponding to the different Properties:
- Trace.v and ObsTrace.v define the trace model and observation model
- TraceProperties.v defines arbitrary stack properties given a call trace and context type
- SubroutineSimple.v defines the basic stack safety properties
- SubroutineShare.v defines the version enhanced with argument passing on the stack
- Coroutine.v defines the coroutine version
- Lazy.v defines the lazy properties
- CalleeSave.v defines stack safety with callee-save registers
Testing contains the test system, with generators for different machines and the final test run
via extraction in TestProperties.v

> The first example programs (Fig. 1 to 4) are C programs. The programs in Fig. 5 and 6 are qualified as C++ programs, but they could be C programs and they are close to the first programs. Moreover, the C syntax for passing parameters by reference is surprising. I would have written f(&x)(line 934) and void f(int *a)(line 944).

[BCP: We should check our C / C++ syntax.]
[APT: I think the reviewer is confused. C doesn't really have call-by-reference: (explicitly) passing a pointer
is _not_ the same thing as (implicitly) passing a reference, as the latter cannot be used in a first-class way
in the callee: that's the whole distinction we're trying to make starting at line 954 of the text.
Evidently we need to clarify this.]

>    (83) when THAT an
>    (83) actiVation
>    (210) We CAN this form
>    (310, 886,895,947) The return instruction is confusing as the return type of fis void.
>    (357) when THE state
>    (389) are ARE
>    (568) two many closing parentheses (twice)
>    (626) we need REQUIRE
>    (626) followS
>    (652) calls. That
>    (796) I was expecting m' in (m,p',ctx').
>    (1005) lack of space between the last two rules
>    (1118) conjunctIon

> Questions for the response period

> See my former questions related to 1) the Coq formalization, 2) the choice of a RISCV model and 3) the limitations of the approach

====================================================================================================================================

> Review #416B
> Overall merit

> C. Weak Reject
> Reviewer expertise

> Y. Knowledgeable
> Paper summary

> This paper presents a semantics for formalising safety properties of stack safety enforcement systems. The paper uses a map to say which parts of the stack can currently be accessed and which can't, similar to the semantics of separation logic. It then connects this to a notion of call and return, that can be configured to enable different machine's implementations of functions.

> The paper uses a systematic testing approach with QuickChick to show that a hardware enforcement mechanism actually provides stack safety, and find bugs that are injected into the approach. It is great that you found the bug in lazy approach, however, it is fairly obvious type of security issue where uninitialised data leads to something escaping.

> The paper discusses extension, where parameter passing can use the stack, and passing references to structures.

> The paper is primarily a semantics paper, though that seems fairly straightforward. The more interesting aspect of the paper is the more elaborate examples in Section 6 and 7, and the more elaborate extensions in 8. But I had not followed the earlier aspects well enough to appreciate those.

> Overall, I didn't find the paper particularly compelling in its current form. It seems complex for what it achieves earlier on, and doesn't have clear enough exposition for the later parts.
> Strengths

>    Checks properties of stack safety using capabilities
>    Interesting topic

> Weaknesses

>    Exposition doesn't connect the different aspects of the paper well.

>    Seems overly complex in comparison to other relational reasoning papers.

> Comments for author

> I found the paper did not connect the section well. Section 4 presents a lot of details for a framework, which is then used in Section 5. Seem very disconnected? For instance, Line 501: âC\leftarrow_CâCâ this has a different type to the semantics in the previous section. How does it relate? Generally, there are a lot of things that are similar to the previous section, but you are not actually connecting them. Is this because they are different or just missing exposition.

Many of the content that seems disconnected takes the form of a parameterizable relation and its various
instatiations in different versions of the property. \rightarrow_C parameterized by the type ctx, which is section 5
is instantiated as (K -> SD)x(list(target)). In later sections it will be instantiated by other types.
Then for any \rightarrow_C, we can extend \rightharpoonup to form \rightharpoonup_C.

We can do more to call out which parts of the formalization are parameterized and when they are being
instantiated, so that the connections are more clear.

> Line 320: defition

[BCP: We should just fix these sorts of things and then not mention them in
the response.]

> Line 329: I was really interested in address taken at this point, and whether the model could handle it. I really think the informal aspects of the extensions, should be pulled forward, so these questions are answered earlier

This is a good point, and we will examine ways to introduce that information sooner. However, we are
hesitant to spend too much time on variants before introducing the basic formalism, because it can
be a lot to keep track of.

[BCP: This is a good expositional idea.]
[APT: Right, so we should acknowledge it politely -- but we did have reasons for ordering
things the way we did....]
[SNA: That was roughly the reason, as I recall? I may take a stab tomorrow at sketching what
moving them up would look like.]

> Line 349: How does this related to control flow integrity/guard, and Intel's CET?

> Line 448: "If the predicate always holds" never holds?

> Line 510: "isRet" is a relation, but you are using as a function.

> Line 515: ReturnRec: This seems like it would allow you to access outer frames as long as you didn't return?

> Line 642: wrok

====================================================================================================================================

> Review #416C
> Overall merit

> B. Weak Accept
> Reviewer expertise

> Z. No familiarity
> Strengths

> The work presents a compelling model for stack security, framed in terms of existing notions of integrity and confidentiality.

> Models are sufficiently abstract and general to be transportable to a variety of mechanisms and machines.

> Notions of observable stack safety capture a more idealized notion that can reflect realistic violations, rather than "false positives" due to the limitations of particular mechanisms. This is my favorite contribution of this work.

> Some evidence that the approach can be tailored to complex control mechanisms, by showing how it applies to a simple fixed coroutine model.
> Weaknesses

> Validation is performed using random testing rather than formal proof. However, testing proved sufficient to uncover shortcomings in prior lazy models (which could then be fixed), and mutation testing was used to ensure that the testing approach would catch errors.
> Comments for author

> line 13: variant of our properties and /does so/ correctly, and

> line 94: what about tail calls?

> line 118: please briefly summarize what "stepwise" means here. Doing so should not need the full formalism, just a notion of steps. Simply hoisting the discussion from line 521 would likely suffice.

> line 123: "we extend the generation ..." I'm not sure what that means.

> line 210: We /call/ this form...

> line 293: What about exceptions?

> line 563: all possible calls that /can/ be reached
