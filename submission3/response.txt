We first address for the most important high-level points, then go back to
fill in detailed responses to all points made in the reviews.

_[BCP: Fill this part in!!]_

___________________________________________________________________

_[BCP: This could all use some more attention to markdown formatting so that
the output looks readable.]_

_[BCP: Still some comments below marked BCP/LEO...]_

# Reviewer A

> Paper summary

> This submission formalizes the general notion of stack safety (roughly
  speaking, every caller should be protected from its callees during program
  execution) using well-known notions of security (integrity,
  confidentiality and non interference), and defines several security
  policies for protecting the stack. The formalization is validated on
  existing (and less general) micro-policies for stack safety (depth
  isolation, lazy tagging and lazy clearing) using property-based random
  testing. This evaluation of former policies detected some security
  violations in former and less precise works. 

> First, this submission introduces the main required security policies, in
  terms of traces of memory, register states and stepwise stack-safety:
  stepwise integrity (an execution step does not modify the memory slots
  that are reserved for a caller at a given depth), confidentiality (a
  callee is insensitive to the context of its call), stepwise
  confidentiality, temporal stack safety, and well-bracketed control-flow
  (calls and returns should be correctly nested). Then, the submission
  describes the requirements on the machine model (presence of a program
  counter, used to distinguish between the different stack-frames, and a
  mechanism for recognizing the return from a call) and the threat
  model. The machine model is abstract enough to represent different
  architectures.

> Next, the submission details in a progressive way the formalization of
  machine behaviors and stack safety using semantic rules. The first
  formalization of the execution stack is simple, with a single stack and no
  sharing between callers and callees. Then the model is enriched with
  function parameters passed on the stack (by value or by reference), with
  callee-saves registers and with coroutines. Moreover, the first model is
  implemented in Coq and this implementation reuses an existing RISCV
  specification. The QuickChick tool is used to test the stepwise property
  and validate an existing enforcement mechanism (called depth isolation) of
  the literature. Furthermore, as the previous policy is conservative and
  rather slow to be practical, more permissive variants of confidentiality
  and integrity properties are formalized, resulting in an observational
  property that is again validated by testing.

> Strengths

>    well-written submission, well-explained ideas

>    general formalization that addresses a real challenge and that is validated by testing

> Weaknesses

>    lack of discussion about the limitations of the work

>    medium delta with respect to previous works

> Comments for author

> This submission is well-written, with well-explained ideas. Examples of C and assembly programs are used throughout the submission to illustrate the various définitions. The formalization is provided as a supplementary material together with the test cases. The techniques and results of the submission are interesting and general enough to be reused in different settings.

> I am in favor of accepting this paper; however there are a few questions that I would like to be addressed.

*** Questions Begin ***

> Why did you choose this RISCV specification?
> Why didn't you choose to reuse an ARM specification (as there are some of
> them written in Coq in the literature)? 
> Would it be easy to adapt your work to another ISA specification?

We chose RISCV for its simplicity, and because it has been used as the base
ISA for much of the existing work (by others) on designing hardware that
supports tag-based micro-policies.

To clarify a possible misunderstanding: the Coq specification of RISCV that
we use was developed by others (see footnote p. 14); we were able to adapt
it to our testing framework with relatively little effort.

Our stack safety theory itself is not dependent on the details of the
architecture, since the properties are defined in terms of a generic
interface over machine and enforcement policy; see the `Properties`
directory in the Coq development as explained below for concrete
modelling details.

Porting the testing framework to another architecture such as ARM would
require adding a test case generator for the new ISA (including its specific
calling conventions) and translating the micropolicy rules to apply to that
architecture / calling conventions.  This would take some work, but it
should be straightforward.

For example, we are currently working on extending the work to a model of a
Cheri-style hardware capability machine, Cerise, and have not encountered
major obstacles.

> How realistic is the RISCV specification? In other words, are there any
  RISCV vulnerabilities that are not taken into account in your model? 

We use the RISCV specification to demonstrate that our properties are
testable in a realistic setting. We do not aim to exercise the entire RISCV
specification, and the validity of the model is not dependent on the absence
of vulnerabilities in the RISCV implementation. [BCP: It's not??] That said,
the RISCV specification we use is complete for user mode integer
instructions (RV32IM).

> More generally, what are the limitations of the presented work? For example, in the model, there seems to be no distinction between values and addresses; is it a limitation?

Currently, discussion of our model's limitations is scattered
throughout the paper.  We will expand and organize it into an explicit
section, along the following lines...

Our focus is on characterizing stack safety.  So we are particularly
concerned with limitations that prevent the model from applying to realistic
uses of the stack, as opposed to modeling other structures such as the heap,
which we intentionally say nothing about.  (Heap safety has already been
studied, in isolation, by Azevedo et al, and we expect that their
correctness condition and ours can be combined cleanly to characterize
correct protection of stack + heap.)

Features that we do not currently support:

- Address-taken locals. As we discuss at line 954, a satisfactory
  treatment of these seems to require integration with a more general
  model of memory safety that covers the heap and static globals too.
  [LEO: such as "The Meaning of Memory Safety" by Amorim et al.?]
  [BCP: Note that this is mentioned now, just above.]

- Exceptions. We can see a way to extend the model to include them:
  essentially, we would model a "setjump" operation by inserting a
  special target in the return target stack. We would weaken
  well-bracketedness to allow reaching such a target from any
  depth. Since integrity and confidentiality are distinct from
  well-bracketedness and already permit the popping of multiple
  functions from the stack, they can simply treat the exception's
  target as another return target.

- Tail calls. Again, we can see how we might extend the model for them
  Since a tail call is both a call and a return in a single step, our
  normal handling of returns doesn't work -- it would interpret the
  tail call as a call to and immediate return from a new function
  activation. We would need to distinguish tail calls from normal
  calls and essentially process the call and the return in the reverse
  order.

- Dynamic code generation. This would be rather challenging to
  integrate into our framework, because we rely on annotations in the
  code. We can easily envision supporting dynamic code generation
  where the generated code is guaranteed never to contain a call
  or other annotated instruction. We could also support annotated-code
  generation in which existing code is copied along with its annotations.

- Concurrency. We can handle a limited form of coroutines, as described in
  8.3. Handling full-blown preemptive concurrency would require significant
  changes in our underlying machine model.

As for the distinction between values and addresses, conventional ISAs do
not make this distinction.  Ongoing work on the Cerise capability machine
formalization has required some modifications to our model to distinguish
values from addresses, as they are _not_ the same in a capability machine,
but it has little global effect on the model itself. Indeed, distinguishing
between values and addresses is a higher-level abstraction that can "hide"
potential bugs resulting from implicit conversions between them, so we feel
it is preferable to model them as the same when possible.

> Another example is the outside qualifier that characterizes only a whole
  component. Wouldn't you need a finer-grain access control policy (and a
  qualifier for partially outside components)?

We don't entirely understand this question, but we wonder whether there may
be some confusion arising from our use of the term "components."  In our
model (see line 398), components are already fine-grained: individual
registers and memory addresses. We recognize that this is a poor choice of
term given the common usage of component to refer to a larger module in a
compartmentalization context, and we plan to change the term to "state
elements."  Since components/elements are so fine-grained, there is no need
for finer access control.

> Could you comment on the Coq formalization that is provided as a
  supplementary material? Was it straightforward to write a Coq program from
  a C++ program? Moreover, I looked at the Coq development and found some
  admitted lemmas in it. 

See below.

> Other comments

> The supplementary material is not mentioned in the submission. Links to the Coq formalization would have been useful (e.g., for definition 7.4 that I did not fully understand in the submission, as K' is defined but not used, and so is n'').

The supplementary material should indeed be mentioned in the submission.
The Coq formalization provided contains two parts: the formalization of our properties,
which was a conceptual aid in their development and may be useful to readers' intuitions,
and the testing framework, which is used to validate our properties by showing that
computable versions of them are testable.

Admitted lemmas are the beginnings of an effort to formalize [details] [BCP:
N.b.]

In the case of definition 7.4, this is a typo. The K in the third bullet should be K', and the
last instance of n' should be n''.

Map of the supplementary material:
Core contains the abstract machine and policy models, as well as the RISCV instantiations with different policies.
Properties contains Coq definitions corresponding to the different Properties:
- Trace.v and ObsTrace.v define the trace model and observation model
- TraceProperties.v defines arbitrary stack properties given a call trace and context type
- SubroutineSimple.v defines the basic stack safety properties
- SubroutineShare.v defines the version enhanced with argument passing on the stack
- Coroutine.v defines the coroutine version
- Lazy.v defines the lazy properties
- CalleeSave.v defines stack safety with callee-save registers
Testing contains the test system, with generators for different machines and the final test run
via extraction in TestProperties.v
[APT: Can we give pointers from each paper definition to corresponding Coq definition?]

> The first example programs (Fig. 1 to 4) are C programs. The programs in Fig. 5 and 6 are qualified as C++ programs, but they could be C programs and they are close to the first programs. Moreover, the C syntax for passing parameters by reference is surprising. I would have written f(&x)(line 934) and void f(int *a)(line 944).

Only Fig. 6 uses C++ features.  Although C programmers might indeed
try to simulate call-by-reference by passing a pointer as suggested
here, this is subtly different from a genuine by-reference argument in
C++, because the latter cannot be directly used in a first-class way
in the callee (without using the & operator, as e.g. at line 945).
Thus, legal access to the value of a by-reference argument is
restricted to the immediate callee (and any chain of sub-callees to
which the argument is handed down by reference), and we can capture
this access pattern in our policies.  On the other hand, pointer
arguments might escape into arbitrary sub-callees, and there is no
obvious way for policies in our style to specify when access through
these pointers should be permitted. We will improve the discussion at
line 954ff to clarify this point.

>    (310, 886,895,947) The return instruction is confusing as the return type of f is void.

[SNA: should we do jlr?]

> Questions for the response period

> See my former questions related to 1) the Coq formalization, 2) the choice of a RISCV model and 3) the limitations of the approach

___________________________________________________________________________
# Reviewer B

> Paper summary

> This paper presents a semantics for formalising safety properties of stack safety enforcement systems. The paper uses a map to say which parts of the stack can currently be accessed and which can't, similar to the semantics of separation logic. It then connects this to a notion of call and return, that can be configured to enable different machine's implementations of functions.

> The paper uses a systematic testing approach with QuickChick to show that a hardware enforcement mechanism actually provides stack safety, and find bugs that are injected into the approach. It is great that you found the bug in lazy approach, however, it is fairly obvious type of security issue where uninitialised data leads to something escaping.

> The paper discusses extension, where parameter passing can use the stack, and passing references to structures.

> The paper is primarily a semantics paper, though that seems fairly straightforward. The more interesting aspect of the paper is the more elaborate examples in Section 6 and 7, and the more elaborate extensions in 8. But I had not followed the earlier aspects well enough to appreciate those.

> Overall, I didn't find the paper particularly compelling in its current form. It seems complex for what it achieves earlier on, and doesn't have clear enough exposition for the later parts.
> Strengths

>    Checks properties of stack safety using capabilities
>    Interesting topic

> Weaknesses

>    Exposition doesn't connect the different aspects of the paper well.

>    Seems overly complex in comparison to other relational reasoning papers.

> Comments for author

> I found the paper did not connect the section well. Section 4 presents a lot of details for a framework, which is then used in Section 5. Seem very disconnected? For instance, Line 501: ←C\leftarrow_C←C​ this has a different type to the semantics in the previous section. How does it relate? Generally, there are a lot of things that are similar to the previous section, but you are not actually connecting them. Is this because they are different or just missing exposition.

Much of the content that may seem disconnected takes the form of a
parameterizable relation and its various instantiations in different
versions of the property. \rightarrow_C parameterized by the type ctx, which
is section 5 is instantiated as (K -> SD)x(list(target)). In later sections
it will be instantiated by other types.  Then for any \rightarrow_C, we can
extend \rightharpoonup to form \rightharpoonup_C.
[BCP: The formatting here makes it hard to read.  Can we improve it?]

We will do more to call out which parts of the formalization are
parameterized and when they are being instantiated, so that the connections
are more clear.

> Line 329: I was really interested in address taken at this point, and
  whether the model could handle it. I really think the informal aspects of
  the extensions, should be pulled forward, so these questions are answered
  earlier

This is a good point, and we will examine ways to introduce that information
sooner. But we are hesitant to go into too much detail on variants while
introducing the basic formalism, because it can be a lot to keep track of.

> Line 349: How does this related to control flow integrity/guard, and
  Intel's CET? 

[BCP: ???]

> Line 508: "isRet" is a relation, but you are using as a function.

> Line 515: ReturnRec: This seems like it would allow you to access outer
  frames as long as you didn't return? 

[BCP: ???]

___________________________________________________________________________
# Reviewer C

> Strengths

> The work presents a compelling model for stack security, framed in terms
  of existing notions of integrity and confidentiality.

> Models are sufficiently abstract and general to be transportable to a
  variety of mechanisms and machines.

> Notions of observable stack safety capture a more idealized notion that
  can reflect realistic violations, rather than "false positives" due to the
  limitations of particular mechanisms. This is my favorite contribution of
  this work.

> Some evidence that the approach can be tailored to complex control
  mechanisms, by showing how it applies to a simple fixed coroutine model.

> Weaknesses

> Validation is performed using random testing rather than formal
  proof. However, testing proved sufficient to uncover shortcomings in prior
  lazy models (which could then be fixed), and mutation testing was used to
  ensure that the testing approach would catch errors.

> Comments for author

> line 94: what about tail calls?

Tail calls are discussed above in our proposed "limitations" section.  They
are not currently supported, but we describe there how they might be.

> line 123: "we extend the generation ..." I'm not sure what that means.

Line 123 should read "... we extend the generation-by-execution
techniques...", referring to the method of randomly generating valid
low-level programs by lazily adding instructions while simulating execution.

> line 293: What about exceptions?

Exceptions are also discussed in our "limitations" section, along with a
description of what it would take to implement them.
