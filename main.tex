%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}

%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{POPL} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2021}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\input{macros}
\input{examples}

\begin{document}

%% Title information
\title{Stack Safety as a Security Property}         %% [Short Title] is optional;
                                        %% when present, will be used in
                                        %% header instead of Full Title.
%\titlenote{with title note}             %% \titlenote is optional;
%                                        %% can be repeated if necessary;
%                                        %% contents suppressed with 'anonymous'
%\subtitle{Subtitle}                     %% \subtitle is optional
%\subtitlenote{with subtitle note}       %% \subtitlenote is optional;
%                                        %% can be repeated if necessary;
%                                        %% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
%\author{First1 Last1}
%\authornote{with author1 note}          %% \authornote is optional;
%                                        %% can be repeated if necessary
%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
%\affiliation{
%  \position{Position1}
%  \department{Department1}              %% \department is recommended
%  \institution{Institution1}            %% \institution is required
%  \streetaddress{Street1 Address1}
%  \city{City1}
%  \state{State1}
%  \postcode{Post-Code1}
%  \country{Country1}                    %% \country is recommended
%}
%\email{first1.last1@inst1.edu}          %% \email is recommended
%
%%% Author with two affiliations and emails.
%\author{First2 Last2}
%\authornote{with author2 note}          %% \authornote is optional;
%                                        %% can be repeated if necessary
%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
%\affiliation{
%  \position{Position2a}
%  \department{Department2a}             %% \department is recommended
%  \institution{Institution2a}           %% \institution is required
%  \streetaddress{Street2a Address2a}
%  \city{City2a}
%  \state{State2a}
%  \postcode{Post-Code2a}
%  \country{Country2a}                   %% \country is recommended
%}
%\email{first2.last2@inst2a.com}         %% \email is recommended
%\affiliation{
%  \position{Position2b}
%  \department{Department2b}             %% \department is recommended
%  \institution{Institution2b}           %% \institution is required
%  \streetaddress{Street3b Address2b}
%  \city{City2b}
%  \state{State2b}
%  \postcode{Post-Code2b}
%  \country{Country2b}                   %% \country is recommended
%}
%\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
What is stack safety? Numerous mechanisms have been proposed to guard
against attacks that corrupt the call stacks of running programs,
\ifaftersubmission
and many
others rely on a protected stack as an assumption to provide higher level
guarantees,\bcp{this is a good point, but we don't pick it up anywhere in the
  paper, do we?}\leo{No, should we delete this? it still makes sense in flow}
\bcp{Let's delete for now; later, we can try to incorporate it in the body
  of the paper.}
\fi
but a clear and precise definition of stack safety is missing
from the literature.
%
We propose a formal definition phrased in the technical
terminology of language-based security---as a combination of a
confidentiality property (callees should not be able to read their caller's
stack frames) and an integrity property (callees should not corrupt their
caller's stack frames or control state).
  %
We discuss how these properties are enforced or approximated by
existing stack protection mechanisms and describe some useful
stronger and weaker variants.  \ifaftersubmission\bcp{should we mention stktokens here?}
\leo{Not sure. We almost never cite stuff in the abstract, do we?}\fi
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

%\ccsdesc[500]{Software and its engineering~General programming languages}
%\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{Stack Safety, Micropolicies}  %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle

\section{Introduction}

\newcommand*{\MemoryLabel}[3]{\raisebox{#2}{\makebox(0,0){\hspace{#1}#3}}}

%\begin{figure}
%  \begin{minipage}{\textwidth}
%    \begin{center}
%\MemoryLabel{10em}{1.5em}{40}
%\MemoryLabel{16em}{1.5em}{60}
%\MemoryLabel{22em}{1.5em}{80}
%$\cdots$
%\memory{4}{gray}%
%\memory{5}{green}[{\makebox[0pt]{Caller}}]%
%\memory{5}{yellow}[{\makebox[0pt]{Args}}]%
%\memory{8}{red}[{\makebox[0pt]{Callee}}]%
%\memory{4}{\unusedc}%
%~$\cdots$\\
%  \end{center}
%  \end{minipage}\\
%~\\
%~\\
%  \begin{minipage}{0.45\textwidth}
%    \begin{center}
%\begin{verbatim}
%jal ...
%lw r1 r0 40
%\end{verbatim}
%    \end{center}
%  \end{minipage}~
%  \begin{minipage}{0.45\textwidth}
%    \begin{center}
%\begin{verbatim}
%jal ...
%sw r0 r0 40
%\end{verbatim}
%    \end{center}
%  \end{minipage}
%  \caption{Examples of Unsafe Programs\bcp{The numbers don't line up with
%      the boxes; the program fragments need comments explaining what each
%      line does.}}
%  \label{fig:stackunsafety}
%\end{figure}
%
%\leo{I hate the writing here, but I wanted to make a start.}

%\bcp{We don't actually say very clearly anywhere that we are interested in
%  low-level enforcement mechanisms for machine-code programs (because this
%  is where stack attacks occur, and because at higher levels of abstraction
%  the stack is a built-in concept, not something that can be attacked even
%  in principle).  This could cause confusion.\apt{not so worried}}
%\leo{I agree. I've clarified the writing in the top of the running example
%  a bit to make sure though}

The call stack is a perennial target for attacks
based on memory safety vulnerabilities, with potential consequences
ranging from leakage or corruption of private stack data to
control-flow hijacking. To detect or prevent such attacks, a menagerie of
software and hardware techniques for stack safety have been proposed,
%
including stack canaries~\citep{Cowan+98},
bounds checking~\citep{NagarakatteZMZ09,NagarakatteZMZ10,DeviettiBMZ08},
split stacks~\citep{Kuznetsov+14},
shadow stacks~\citep{Dang+15,Shanbhogue+19},
capabilities~\citep{Woodruff+14,Chisnall+15,Skorstengaard+19,Skorstengaard+19b},
and hardware tagging~\citep{DBLP:conf/sp/RoesslerD18}. \ifaftersubmission\apt{Mostly from
  nick; there could be more}\leo{Do we want to hunt for more refs here?}
\bcp{Sure, but later!}
\fi

But what {\em is} this stack safety of which people speak? Precise formal
definitions are mostly lacking: rather, the notion
is commonly defined in a negative way, by enumerating the bad things that a
given enforcement mechanism
prevents, such as corruption of return addresses, buffer overflows, or
use of uninitialized variables.
%\bcp{Does use of unitialized variables lead to stack safety attacks?\apt{sure, via buffer overflow}}
%with the notion usually being
%defined negatively: through examples of stack-based exploits
%\rb{usually though not always; as noted below there are other
%  approaches}\bcp{Yes, we have to be very careful about this}.
%\leo{Examples at a high level}: such as -- does not overwrite return addresses, or ...
Indeed, we are only aware of one quite recent attempt to frame a
positive definition, by
\citet{Skorstengaard+19}, which defines stack safety as
the conjunction of two properties: {\em local state encapsulation} and {\em
  well-bracketed control flow}.
These properties are formalized by defining an abstract capability-based machine
that ``satisfies [stack safety] by construction.''
%
While this work represents an important step in the right direction, we believe
there is still room to craft a more abstract, more generic characterization
of stack safety that is independent of capabilities or any other specific
enforcement
technique.  In other words, we seek formal criteria that can be applied
to \emph{any} mechanism for protecting stack-based low-level programs to judge
whether or not it actually ``guarantees stack safety.''
%
Our key contribution is another important step towards this goal: a generic
presentation of local state encapsulation and well-bracketed
control\bcp{we need to either weaken the previous sentence or else add
  ``first steps toward'' in this sentence...}\leo{Weakened enough?}\bcp{Not
  sure: it still says ``generic,'' and it's not clear why we're saying it's
  a step rather than that we achieved the goal...} flow using the technical
framework of language-based security.

The intuition behind \citeauthor{Skorstengaard+19}'s {\em
  local state encapsulation} is that callers should be protected from
callees: a callee should not be able to access or overwrite private data
in the caller's stack frame.
%
We formalize this intuition in (1) a {\em stack confidentiality}
property, which promises that a callee's observable behavior is not affected
by memory outside its stack frame (e.g., a caller's private data or
uninitialized memory), plus (2) a {\em stack integrity} property,
which promises that, if a function call ever returns, the caller's stack
data at the point of return will be identical to what it was before the
call.

The intuition behind \citeauthor{Skorstengaard+19}'s {\em
  well-bracketed control flow} is the need to protect the call graph
itself: a callee should pass control back to the caller only by
transferring control to the instruction
following the call; it should not be allowed to jump back into the
caller's code at an arbitrary point, either directly (via a jump
instruction) or indirectly (by corrupting stack data and
returning). Well-bracketed control flow establishes safety between
functions: each instruction is uniquely owned by some function, and
all jumps between functions are either calls that enter at a marked
entry point or returns that re-enter just after their associated call
in the standard nested call structure.  \apt{clarify what we are
  contributing here. We are not trying to phrase this as a security
  property.}\leo{Better now? Should this be fixed two paragraphs above
  too?}\bcp{Hmmm this seems like a fundamental issue with the way we are
  framing the story...}

To phrase stack safety, and especially local state encapsulation, as a
security property requires an explicit attacker model: a clear
understanding of who is being protected and from what. Most existing
stack protection mechanisms envisage scenarios where a callee is
influenced by external inputs to corrupt the stack in some way. To
avoid getting into the details of exactly how this happens when
formalizing our properties, we use an even stronger model: when we
state the protections that a function can rely on when it makes a
call, we assume that the callee can execute arbitrary instructions
until it returns.

A key challenge in adapting the concepts of language-based security to this
setting is that integrity and confidentiality are ``nested'' properties: not
only does a given caller need to be protected from its callee, but the callee
also needs to be protected from {\em its} callees, and so on. That is, the notion
of ``attacker'' changes at many points throughout the execution of the program.
We address
this issue by introducing a dynamically changing notion of {\em accessibility} for
the different components of the machine state and adjusting the integrity
and confidentiality levels of different stack locations and registers at
every transition (call or return) between functions.

After formally defining stack safety, we show that the definition is
enforceable using an existing tag-based enforcement
mechanism~\citep{DBLP:conf/sp/RoesslerD18}. We first consider
\citeauthor{DBLP:conf/sp/RoesslerD18}'s
conservative Depth Isolation policy, which not only enforces our basic
stack safety property, but also an alternative lockstep property that
checks for integrity and confidentiality violations at every step of
an execution trace. The advantage of this property is that it ``fails
faster'' and os therefore more suitable for efficient testing. We prove (in
Coq) that this ``lockstep'' property implies our original definition of stack
safety.

The downside of the Depth Isolation policy is that it is rather
expensive to implement. In the same work,
\citeauthor{DBLP:conf/sp/RoesslerD18} propose a different mechanism
that is more efficient by virtue of being lazy in its enforcement.
Instead of enforcing the integrity and confidentiality of the stack at the
exact moment
when a callee returns, this policy signals violations when the
caller actually accesses data that the callee has written into its stack
frame\ifaftersubmission\bcp{We could also hint at the lazy confidentiality
  property inthe same way...}\fi.
The lazy policy does not enforce our original integrity and confidentiality
properties, and to our knowledge there is no formal statement of the properties that
it ought to enforce. We propose ``observable'' versions of integrity and
confidentiality property, which capture the desired behavior of a policy that
detects violations between when they occur and when they make a visible impact.
Unfortunately the existing Lazy Tagging and Clearing policy of
\citeauthor{DBLP:conf/sp/RoesslerD18} does not quite enforce these properties,
but would if enhanced (at some performance cost).
%\bcp{I worry that we are being a little
%  dishonest here: the stated advantage of the lazy policy is that it is more
%efficient, but our variant is {\em not} efficient!}

\sna{There's been some inconsistency in ``stack safety'' vs.
     ``stack-safety,'' I'm fixing on the former.}
\bcp{Be careful: When a compound phrase is used as an adjective to modify a
  following noun, it gets hyphenated; otherwise it does not.  This is
  correct grammar, not inconsistency!  :-)}

In summary, we offer the following contributions:
\begin{itemize}
\item
  % \leo{More? Extensional}\bcp{We might need to invent a word for this---''quasi-extensional''?}
  A novel {\em formal stack safety property} formalizing the
  intuitive concepts of strict local state encapsulation and well-bracketed
  control flow~(\cref{sec:lse-and-wbcf}) in terms of familiar security concepts.
  % These properties   rule out common examples of stack memory abuse.
  This property can be enforced by
  the Depth Isolation policy of \citet{DBLP:conf/sp/RoesslerD18}, which is
  based on hardware tagging~(\cref{sec:conservative}).
\item
  A {\em lockstep} variant of the stack safety property that is also
  enforced by the Depth Isolation policy
  but is more efficient to test, plus a proof (in Coq) that this variant is
  stronger than the original~(\cref{sec:lockstep}).
\item
  A {\em lazy} variant of the stack safety property that can be enforced if the
  Lazy Tagging and Clearing policy of \citet{DBLP:conf/sp/RoesslerD18} is enhanced
  with unique tags on each activation, plus a proof (in Coq) that this
  variant is weaker than the original~(\cref{sec:lazy}).
%  This policy does not enforce our strict
%  local state encapsulation property,
%  but a modified version of it using unique per-activation tags enforces
%  an (also provably) weaker lazy variant of the property, which still prohibits
%  the same intuitively stack unsafe behaviors.
%
% \apt{Awkward, but the truth I fear.} \bcp{I agree the phrasing is awkward,
%   but the point we can make is still strong: To make the property easier
%   to enforce, we can slightly weaken its guarantees; the weaker version is
%   a bit more complicated to state but still retains the pragmatic
%%   protections of the original.}\apt{To clarify: Nick's LT\&C policy uses
%   depth-based tags, which do not enforce even our lazy policy. So we need to
%   introduce a version of LT\&C that uses unique activation tags.}

  %\item As evidence that the property is not too strong\apt{But we add the lazy version because the strict version \emph{is} too strong, in some sense.}, we show that it is
%  realizible by
%  a previously proposed micropolicy enforcement
%  mechanism~(\Cref{sec:micropolicy}). \leo{And it says yes on a
%    substantial body of code}. We also present a variation of the
%  property + policy that is lazy, easier/more efficient to implement,
%  and provably weaker (\Cref{sec:lazy}).
%\item A provably stronger (inductive? step-by-step/stepwise) variant
%  of this property tuned for testing/verification.  We test the whole
%  thing with a cool framework. \bcp{Which section?}
\end{itemize}
\Cref{sec:relwork} discusses related work;
\cref{sec:future} sketches directions for future work.

We begin with a description of our threat model
(\cref{sec:threat}), a running example that we refer to throughout the paper
(\cref{sec:running-example}),  and some technical preliminaries
(\cref{sec:prelim}).

\section{Threat Model and Assumptions}
\label{sec:threat}

Stack safety is meant to protect a caller from a confused or malicious callee's
attempts to access private data or hijack its control flow. Our
attacker model reflects this intention by assuming that the attacker
can run arbitrary machine code to try to access or overwrite its caller's stack data
or disrupt its control state.  Hardware and timing attacks are out of
scope.
%\leo{Anything else to add here?}
%\leo{Maybe a good place to discuss calling conventions and that they
%  are essentially enforced by the policy or sth?}
%\rb{Intuition that the callee can do anything in principle, but the machine will
%halt if it does not follow the calling convention, etc.?}

\newcommand*{\rsp}{\textsc{sp}}

We assume we are given a machine language program, together with some auxiliary information
about its structure: the code footprint of each function and the locations of instructions
representing calls, returns, and function entry points.
Although this information would typically come from a compiler together with
the machine code, we do not
assume anything about their provenance.  We assume that the machine has a
program counter $\PCname$
and stack pointer $\rsp$\bcp{but not a frame pointer?!}; other details of the machine's ISA are unimportant.

To make our stack safety definitions precise, we make some straightforward
assumptions about
memory layout; our definitions could easily be changed to be parametric over
these assumptions, at the cost of some complexity in their statements.  Memory
consists of an instruction region and a stack that grows upwards. (For simplicity,
we do not consider the heap. Integrating a memory safety property for the
heap in the style of
\citet{DBLP:conf/post/AmorimHP18} is a natural extension that we discuss
in~\Cref{sec:relwork}.)  The stack has a conventional structure, with
contiguously allocated per-function frames.
The boundary between the frames of a caller and callee is indicated by the $\rsp$ register
at the time of the call.  The stack can be used to
pass arguments or return results in the usual way, by placing them
at the top of the caller's frame. Callers and callees can also communicate
via registers if they wish; indeed, our
definitions say nothing at all about registers (except $\PCname$ and
$\rsp$). \bcp{This implicitly amounts to choosing a caller-saves register
  convention, though, doesn't it?}

Our stack safety concepts depend critically on the notions of ``call'' and ``return,''
which are not fully explicit in machine code (the same instruction may be
used in some places as part of a call or return sequence and in other places
for other purposes).  We define a call to be
any instruction declared as such in the compiler-provided call structure.
If a call occurs at $\PCname = a$ and $\rsp = s$, then the \emph{corresponding
  return} has occurred when $\PCname = \nextPC(a)$ and $\rsp = s$. (Our definition
of well-bracketed control flow relates this definition of return to the program's
declared set of return points.)
Our property definitions make no other detailed assumptions about call or return sequences, although
some of the enforcement mechanisms we consider do.

Enforcement mechanisms are modeled as {\em policies}\bcp{this is a somewhat
  special use of the word ``policy'' that comes from the micropolicies
  world.  We should include a comment about this to avoid confusing
  readers.} that add some auxiliary
policy state to the ordinary machine state
%\bcp{This may be surprising to people who are not thinking about micropolicies.\apt{added para below}}
and a partial policy step function that refines the machine step
function by allowing or disallowing a step to be taken based on its
auxiliary state.  Enforcement works by halting the program before it
can perform an action that would violate the security property; our
properties are therefore naturally \emph{termination insensitive.}
This model will be made more precise in \cref{sec:prelim}.

We model ordinary program state and policy-enforcement state separately to make it
easier to use well-established concepts from language-based security.
In particular, confidentiality has an elegant extensional characterization in terms of
\emph{noninterference}: a program preserves the confidentiality of certain data if
\emph{varying} that data would not change the program's observable
behavior~\citep{6234468}
In applying this idea to a system that incorporates policy enforcement, only
ordinary program data should be varied, while any associated policy
state should be left alone; our model makes this distinction obvious.
%That is, we compare the actual execution of the program with a \emph{hypothetical}
%execution where data has been varied.
We will also introduce a notion of {\em observational integrity} that relies on the idea of
\emph{rolling back} program state; again, our model makes it easy to describe
rollback of ordinary program data while leaving policy state alone.

%% \leo{Policies of interest: null, micro, cherri, software-only}
%% \leo{TODO: Write down carefully}

This enforcement model directly describes
micropolicies~\citep{pump_oakland2015}, and we believe that it is
flexible enough to capture code-altering approaches (such as code rewriting
or capability-based techniques).

\newcommand{\TAGS}{\mathcal{T}}
\newcommand{\tagname}{t}
\newcommand{\uP}{{\mu P}}

\paragraph*{Micropolicies}
%
Micropolicies are a flexible tag-based, hardware-accelerated
reference monitoring mechanism; they been applied to stack safety
enforcement by \citet{DBLP:conf/sp/RoesslerD18}.
Here the policy state consists of metadata tags (e.g., identifying stack frames)
attached to each value in memory or registers, and the policy step
function\bcp{undefined!}\leo{``partial policy step'' is explained informally above}
checks that each machine operation obeys a set of rules on tags
(e.g., that the current $\PCname$ tag matches the tag on the stack
location being accessed), and halts the machine if not.  Distinguishing
ordinary machine state and policy state is very natural in this setting.
%% Here the machine state is extended with tags paired with all components of the
%% system, and a monitor checks for each operation that the tags on the operands
%% obey a set of rules. One could treat tags directly as part of the machine
%% state, and build the rules into the step function. But local state
%% encapsulation properties as we frame them are not intuitive in their
%% interaction with tags or other additional enforcement state, so it is helpful
%% to separate tags for clarity. This also distinguishes a hardware fail-stop from
%% a software fail state.
%% \rb{TODO Similarly to above, should we consider tags as part of the machine or part of the
%%   policy? }

\paragraph*{Capability machines}
%
%Other policies are implemented in hardware or built on hardware mechanisms.
Capability machines such as CHERI \citep{Woodruff+14} extend conventional
architectures to support efficient and fine-grained control over memory
accesses, which can be used to implement security policies, including
the stack protection policies of
\citet{Skorstengaard+19,Skorstengaard+19b}\bcp{I thought these policies used
  linear capabilities?}\leo{Only the second one AFAIK. What would you
  change to characterize it more accurately?}\rb{StkPointers uses linear
  capabilities, its predecessor users local capabilities (and unlike
  StkPointers could be implemented in CHERI)}.
Capabilities package up pointers
(ordinary data) with base and bounds information (policy data),
and they require rewriting source code (e.g., to use capabilities in place
of ordinary pointers), so separating ordinary machine state from policy
state is delicate; we conjecture it can be done with some effort.

%% Mapping the underlying protection
%% mechanisms to policy states and step function would be a delicate operation, as
%% those are tightly coupled to the hardware design. However, separating the
%% enforcement aspects of a concrete policy (such as StkTokens, where policy state
%% would encompass details like the abstract call stack, the capability sealing
%% scheme, etc. \rb{is this digging too deep? or on the contrary, say more?}) from
%% the machine would be relatively straightforward.  \bcp{Not sure that any of
%%   this is comprehensible... :-(}

\paragraph*{Software-only policies}
%
Some policies are implemented in software, by modifying code in the
compiler, for example to perform bounds checking~\citep{NagarakatteZMZ09} or
to insert stack canaries~\citep{Cowan+98}. Such approaches should
still satisfy our formal notion of stack safety with a trivial null
policy, but only for programs produced by the compiler.
%These approaches are represented as policies that
%accept\bcp{what does it mean for a policy to accept a state??} only initial machine states that are well-formed for the policy (due to
%being produced by the compiler.) The set of policy states is again the unit type
%and the step function constant. Property enforcement comes from the fact that
%only ill-formed states can induce a trace that violates the property.


%% \Paragraph*{Null policy}
%% %
%% The simplest possible policy is the neutral policy that carries no information
%% and does nothing. Its set of policy states is the unit type, and its policy step
%% function is the constant unit function, thereby allowing all calls to the machine
%% step function. Its initialization function is defined on all states. This
%% corresponds to the lifting of our machine model to the policy setting. Machines
%% that fulfill a property by construction will also fulfill that property with the
%% null policy.

%
%\leo{TODO: Add citations of mitigation techniques}
%\rb{And for those techniques, explain how they reflect their motivating
%examples. What does each technique do for those examples? How are they
%connected to this work?}
%
%\paragraph*{Bad Write}
%
%\[
%44 : [\rsp - 5] \leftarrow r_4
%%44 : ~ \sw ~ \rsp ~ r_4 ~ \negate 5
%\]
%
%Instruction 44 currently is
%$ [\rsp - 2] \leftarrow r_4$,
%%$\sw ~ \rsp ~ r_4 ~ \negate 2$,
%with the
%effect of storing the contents of $r_4$ as the result of {\tt h}. If
%instead it wrote to location $\rsp - 5$ then it would be overwriting
%private data (the return address) belonging to {\tt g}.
%
%\paragraph*{Bad Read}
%
%\[
%30 : r_5  \leftarrow [\rsp - 6]
%%30 : ~ \lw ~ r_5 ~ \rsp ~ \negate 6
%\]
%
%Instruction 30 currently is
%$ r_5 \leftarrow [\rsp - 4]$,
%%$\lw ~ r_5 ~ \rsp ~ \negate 4$,
%with the
%effect of loading the argument of {\tt g} to $r_5$. If instead it
%loaded the contents of location $\rsp - 6$, it would obtain access
%to the value of {\tt main}'s local variable {\tt x}. Worse, since the next instruction
%outputs the contents of $r_5$, that value would immediately be made public.
%
%\paragraph*{Bad Control Flow}
%
%\[
%5  : \rra \leftarrow \PCname + 1 ; ~ \PCname \leftarrow r_4
%%5 : \jalr ~ r_4 ~ \rra ~ 0
%\]
%If a {\jalr} instruction was added to {\tt main} with its target being
%the middle of the code block of {\tt h}.\apt{describe result of this?}

\section{Running Example}
\label{sec:running-example}

\begin{figure}[b]
\hfill
    \begin{minipage}{.3\textwidth}
\begin{verbatim}
main = {
  int x = 42, y = 0;
  y = g(0);
  print (x + y);
}
\end{verbatim}
    \end{minipage}
    \begin{minipage}{.3\textwidth}
\begin{verbatim}
g(z) = {
  int w = h(17);
  print z;
  return (z + w);
}
\end{verbatim}
    \end{minipage}
    \begin{minipage}{.3\textwidth}
\begin{verbatim}
h(v) = {
  return (v + 1);
}


\end{verbatim}
    \end{minipage}
\caption{A High-level Program With Nested Calls}
\label{fig:running-program}
\end{figure}


\newcommand*{\add}{\textsc{add}}
\newcommand*{\addi}{\textsc{addi}}
\newcommand*{\sw}{\textsc{sw}}
\newcommand*{\lw}{\textsc{lw}}
\newcommand*{\jal}{\textsc{jal}}
\newcommand*{\jalr}{\textsc{jalr}}
%\newcommand*{\rsp}{\textsc{sp}}
\newcommand*{\rra}{\textsc{ra}}
\newcommand*{\rout}{\textsc{out}}

\newcommand*{\tagInstr}{\textsc{instr}}
\newcommand*{\tagCall}{\textsc{call}}
\newcommand*{\tagHa}{\textsc{h1}}
\newcommand*{\tagHb}{\textsc{h2}}
\newcommand*{\tagRa}{\textsc{r1}}
\newcommand*{\tagRb}{\textsc{r2}}
\newcommand*{\tagRc}{\textsc{r3}}
\newcommand*{\tagNoDepth}{\textsc{unused}}
\newcommand*{\tagStackDepth}[1]{\textsc{stack} ~ #1}
\newcommand*{\tagPCDepth}[1]{\textsc{pc} ~ #1}
\newcommand*{\tagSP}{\textsc{sp}}

\newcounter{pcctr}
\setcounter{pcctr}{0}
%  \thepcctr & \stepcounter{pcctr} #1 & #2 & #3 & \text{#4}\\
\newcommand*{\row}[4]{
  \thepcctr & \stepcounter{pcctr} #2 & #3 & \text{#4}\\
}
\newcommand*{\tracerow}[5]{
  #1 & #2 & #3 & #4 & \text{#5}\\
}
\newcommand*{\summary}[6]{
\[
\begin{array}{cccccc}
  \PCname = #1 & r_0 = #2 & \rra = #3 & \rsp = #4 & r_4 = #5 & r_5 = #6
\end{array}
\]
}
\newcommand{\negate}{\textrm{-}}

\colorlet{lgray}{gray!40}

\newcommand{\instrc}{lgray}
\newcommand{\fprivc}{cyan}
\newcommand{\fcallc}{green}
\newcommand{\gprivc}{yellow}
\newcommand{\gcallc}{orange}
\newcommand{\hprivc}{red}
\newcommand{\unusedc}{gray}
\newcommand{\emptyoutc}{white} % or gray for consistency with unusedc ?
\newcommand{\fulloutc}{white}

\begin{figure}

%Starting Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{25em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{Output}}]%
\memory{10}{\unusedc}[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\\
\end{center}
% Starting Register File
\summary{0}{0}{?}{100}{?}{?}
\vspace*{0.2em}
\ifaftersubmission\bcp{A very small nit: Change
  $\rsp-2$ to $\rsp\mathord{-}2$}\apt{??}\bcp{I meant remove spaces around +
and $-$ when then are used inside brackets.  I think it will look better.
But not critical.}\fi
\[
  \begin{array}{l|l|l|l}
    PC & \mathit{Instruction} & \mathit{Effect} & \\
    \hline
    \row{\addi ~ \rsp ~ \rsp ~ 2}{\rsp \leftarrow \rsp + 2}{\rsp \leftarrow 102}
        {Allocate private data for {\tt main}}
    \row{\addi ~ r_4 ~ r_0 ~ 42}{r_4 \leftarrow r_0 + 42}{r_4 \leftarrow 42}
        {Load 42 into $r_4$}
    \row{\sw ~ \rsp ~ r_4 ~ \negate 2}{[\rsp-2] \leftarrow r_4}{[100] \leftarrow 42}
        {Set {\tt x} to 42}
    \row{\sw ~ \rsp ~ r_0 ~ \negate 1}{[\rsp-1] \leftarrow r_0}{[101] \leftarrow 0}
        {Set {\tt y} to 0}
    \row{\addi ~ \rsp ~ \rsp ~ 2}{\rsp \leftarrow \rsp + 2}{\rsp \leftarrow 104}
        {Allocate {\tt g}'s call frame}
    \row{\sw ~ \rsp ~ r_0 ~ \negate 2}{[\rsp-2] \leftarrow r_0}{[102] \leftarrow 0}
        {Set argument to 0}
    \row{\sw ~ \rsp ~ r_0 ~ \negate 1}{[\rsp-1] \leftarrow r_0}{[103] \leftarrow 0}
        {Zero out result\apt{why?}\bcp{+1}}
    \row{\jal ~ \rra ~ 20}{\rra \leftarrow \PCname + 1; ~ \PCname \leftarrow 20}{\rra \leftarrow \thepcctr; ~ \PCname \leftarrow 20}
        {Call ($\jal$ to) {\tt g}}
  \end{array}
  \]
  ~ \\
  ~\\
%  \apt{How's that description for last line?}
%  \apt{Where did these RISC-V insruction formats come from? I think some of them are just wrong, e.g.
%    $\jal$ takes a PC-relative argument, not an absolute one, and the proper way to code a return to $\rra$ is $\jalr  ~ \rra ~ r_0$.
%  But also the instruction operand ordering is awkward. Why not use standard AT\&T syntax?}
% At Call to G
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{43.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{{\tt g}'s call frame }}]%
\memory{6}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-46.5em}{0.75em}{42}
\MemoryLabel{-42.5em}{0.75em}{0}
\MemoryLabel{-38.5em}{0.75em}{0}
\MemoryLabel{-34.5em}{0.75em}{0}
\\
\end{center}
% Starting Register File
\summary{20}{0}{\thepcctr}{104}{42}{?}
%\vspace*{0.2em}
\setcounter{pcctr}{20}%
% G - Body - 1
\vspace*{0.2em}
  \[
  \begin{array}{l|l|l|l}
    \row{\addi ~ \rsp ~ \rsp ~ 2}{\rsp \leftarrow \rsp + 2}{\rsp \leftarrow 106}
        {Allocate stack space for {\tt w}}
    \row{\sw ~ \rsp ~ \rra ~ \negate 2}{[\rsp - 2] \leftarrow \rra}{[104] \leftarrow 8}
        {Save return address}
    % Zero out z?
    \row{\addi ~ \rsp ~ \rsp ~ 2}{\rsp \leftarrow \rsp + 2}{\rsp \leftarrow 108}
        {Allocate space for call frame}
    \row{\addi ~ r_4 ~ r_0 ~ 17}{r_4 \leftarrow r_0 + 17}{r_4 \leftarrow 17}
        {Store 17 into $r_4$}
    \row{\sw ~ \rsp ~ r_4 ~ \negate 2}{[\rsp - 2] \leftarrow r_4}{[106] \leftarrow 17}
        {Store 17 as the argument {\tt v}}
    \row{\sw ~ \rsp ~ r_0 ~ \negate 1}{[\rsp - 1] \leftarrow r_0}{[107] \leftarrow 0}
        {Zero out result \apt{why?}}
    \row{\jal ~ \rra ~ 40}{\rra \leftarrow \PCname + 1 ; ~ \PCname \leftarrow 40}{\rra \leftarrow \thepcctr; ~ \PCname \leftarrow 40}
        {Call {\tt h}}
  \end{array}
  \]
  ~ \\
  ~ \\
% At Call to H
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{61.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{{\tt g}'s call frame }}]%
\memory{2}{\gprivc}[{\makebox[0pt]{${\texttt g}_{\mathit{priv}}$}}]%
\memory{2}{orange}[{\makebox[0pt]{{\tt h}'s call frame }}]%
\memory{2}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-46.5em}{0.75em}{42}
\MemoryLabel{-42.5em}{0.75em}{0}
\MemoryLabel{-38.5em}{0.75em}{0}
\MemoryLabel{-34.5em}{0.75em}{0}
\MemoryLabel{-30.5em}{0.75em}{8}
\MemoryLabel{-26.5em}{0.75em}{}
\MemoryLabel{-22.5em}{0.75em}{17}
\MemoryLabel{-18.5em}{0.75em}{0}
\\
\end{center}
% Starting Register File
\summary{40}{0}{\thepcctr}{108}{17}{?}
\setcounter{pcctr}{40}
\vspace*{0.2em}
% H - Body
\[
\begin{array}{l|l|l|l}
  \row{\addi ~ \rsp ~ \rsp ~ 1}{\rsp \leftarrow \rsp + 1}{\rsp \leftarrow 109}
      {Allocate space for return address}
  \row{\sw ~ \rsp ~ \rra ~ \negate 1}{[\rsp - 1] \leftarrow \rra}{[108] \leftarrow 27}
      {Save return address}
  \row{\lw ~ r_4 ~ \rsp ~ \negate 3}{r_4 \leftarrow [\rsp - 3]}{r_4 \leftarrow 17}
      {Load the argument ({\tt v}) into $r_4$}
  \row{\addi ~ r_4 ~ r_4 ~ 1}{r_4 \leftarrow r_4 + 1}{r_4 \leftarrow 18}
      {Increment $r_4$}\end{array}
\]
~\\
~\\
% At Middle of H
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{65.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{{\tt g}'s call frame }}]%
\memory{2}{\gprivc}[{\makebox[0pt]{${\texttt g}_{\mathit{priv}}$}}]%
\memory{2}{orange}[{\makebox[0pt]{{\tt h}'s call frame }}]%
\memory{1}{\hprivc}%[{\makebox[0pt]{{\texttt h} ra}}]
\memory{1}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-46.5em}{0.75em}{42}
\MemoryLabel{-42.5em}{0.75em}{0}
\MemoryLabel{-38.5em}{0.75em}{0}
\MemoryLabel{-34.5em}{0.75em}{0}
\MemoryLabel{-30.5em}{0.75em}{8}
\MemoryLabel{-26.5em}{0.75em}{}
\MemoryLabel{-22.5em}{0.75em}{17}
\MemoryLabel{-18.5em}{0.75em}{0}
\MemoryLabel{-14.5em}{0.75em}{27}
\\
\end{center}
% Register File
\summary{40}{0}{\thepcctr}{109}{18}{?}
\vspace*{0.2em}
\label{fig:running-trace-a}
\end{figure}

\begin{figure}
\[
\begin{array}{l|l|l|l}
  \row{\sw ~ \rsp ~ r_4 ~ \negate 2}{[\rsp - 2] \leftarrow r_4}{[107] \leftarrow 18}
      {Store $r_4$ as the return value}
  \row{\lw ~ \rra ~ \rsp ~ \negate 1}{\rra \leftarrow [\rsp - 1]}{\rra \leftarrow 27}
      {Load return address}
  \row{\addi ~ \rsp ~ \rsp ~ \negate 1}{\rsp \leftarrow \rsp - 1}{\rsp \leftarrow 108}
      {Restore the stack pointer of {\tt g}}
  \row{\jalr ~ \rra ~ \rra ~ 0\apt{wrong}}{\PCname \leftarrow \rra}{\PCname \leftarrow 27}
      {Return to {\tt g} ($\jalr$)}
  \end{array}
\]

% After Return from H
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{61.5em}{2em}{\SP}
\memory{3}{\emptyoutc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{{\tt g}'s call frame }}]%
\memory{2}{orange}[{\makebox[0pt]{${\texttt g}_{\mathit{priv}}$}}]%
\memory{2}{\gprivc}[{\makebox[0pt]{{\tt h}'s call frame }}]%
\memory{2}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-46.5em}{0.75em}{42}
\MemoryLabel{-42.5em}{0.75em}{0}
\MemoryLabel{-38.5em}{0.75em}{0}
\MemoryLabel{-34.5em}{0.75em}{0}
\MemoryLabel{-30.5em}{0.75em}{8}
\MemoryLabel{-26.5em}{0.75em}{}
\MemoryLabel{-22.5em}{0.75em}{17}
\MemoryLabel{-18.5em}{0.75em}{18}
\\
\end{center}
% Starting Register File
\summary{27}{0}{\thepcctr}{108}{18}{?}
% \vspace*{0.2em}

\setcounter{pcctr}{27}
% H - Body
% \vspace*{0.2em}
\[
\begin{array}{l|l|l|l}
  \row{\lw ~ r_4 ~ \rsp ~ 0}{r_4 \leftarrow [\rsp]}{r_4 \leftarrow 18}
      {Load return value into $r_4$}
  \row{\sw ~ \rsp ~ r_4 ~ \negate 3}{[\rsp - 3] \leftarrow r_4}{[105] \leftarrow 18}
      {Set {\tt w} to return value}
  \row{\addi ~ \rsp ~ \rsp ~ \negate 2}{\rsp \leftarrow \rsp - 2}{\rsp \leftarrow 106}
      {Deallocate {\tt h}'s call frame}
  \row{\lw ~ r_5 ~ \rsp ~ \negate 4}{r_5 \leftarrow [\rsp - 4]}{r_5 \leftarrow 0}
      {Load argument {\tt z} to $r_5$}
  \row{\sw ~ \rout ~ r_5 ~ 0}{[\rout] \leftarrow r_5}{[99] \leftarrow 0}
      {Print {\tt z}}
  \row{\add ~ r_4 ~ r_4 ~ r_5}{r_4 \leftarrow r_4 + r_5}{r_4 \leftarrow 18}
      {Add $r_4$ and $r_5$}
  \row{\sw ~ \rsp ~ r_4 ~ \negate 3}{[\rsp - 3] \leftarrow r_4}{[103] \leftarrow 18}
      {Store $r_4$ as the return value}
  \row{\lw ~ \rra ~ \rsp ~ \negate 2}{\rra \leftarrow [\rsp - 2]}{\rra \leftarrow 8}
      {Load return address}
  \row{\addi ~ \rsp ~ \rsp ~ \negate 2}{\rsp \leftarrow \rsp - 2}{\rsp \leftarrow 104}
      {Deallocate {\tt g}'s local state}
  \row{\jalr ~ \rra ~ \rra ~ 0\apt{wrong}}{\PCname \leftarrow \rra}{\PCname \leftarrow 8}{Return to {\tt main} ($\jalr$)}
\end{array}
\]
% Return to main
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{43.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\fulloutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{{\tt g}'s call frame }}]%
\memory{6}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-51em}{0.75em}{0}
\MemoryLabel{-47em}{0.75em}{42}
\MemoryLabel{-43em}{0.75em}{0}
\MemoryLabel{-39em}{0.75em}{0}
\MemoryLabel{-35em}{0.75em}{18}
\\
\end{center}
% Register File
\summary{8}{0}{\thepcctr}{104}{18}{0}
%\vspace*{0.2em}
\setcounter{pcctr}{8}
\[
\begin{array}{l|l|l|l}
  \row{\lw ~ \rsp ~ r_4 ~ \negate 1}{r_4 \leftarrow [\rsp - 1]}{r_4 \leftarrow 18}
      {Load return value to $r_4$}
  \row{\sw ~ \rsp ~ r_4 ~ \negate 3}{[\rsp - 3] \leftarrow r_4}{[101] \leftarrow 18}
      {Set {\tt y} to the result}
  \row{\addi ~ \rsp ~ \rsp ~ \negate 4}{\rsp \leftarrow \rsp - 2}{\rsp \leftarrow 102}
      {Deallocate {\tt g}'s call frame}
  \row{\lw ~ \rsp ~ r_5 ~ \negate 2}{r_5 \leftarrow [\rsp - 2]}{r_5 \leftarrow 42}
      {Load {\tt x} to $r_5$}
  \row{\add ~ r_4 ~ r_4 ~ r_5}{r_4 \leftarrow r_4 + r_5}{r_4 \leftarrow 60}
      {Add {\tt x} and {\tt y}}
  \row{\sw ~ \rout ~ r_4 ~ 0}{[\rout] \leftarrow r_4}{[99] \leftarrow 60}
      {Print {\tt x + y}}
\end{array}
\]
\vspace*{0.2em}
% Return to main
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{31.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\fulloutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{8}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-51em}{0.75em}{60}
\MemoryLabel{-47em}{0.75em}{60}
\MemoryLabel{-43em}{0.75em}{42}
\\
\end{center}
% Starting Register File
\summary{\thepcctr}{0}{37}{102}{60}{42}
\caption{Detailed Execution Trace
%  \rb{A suggestion for the description of $\jal$ and $\jalr$:
%    call(function label) [if labels are added next to the entrypoints]
%    or call(address of entrypoint) and return()?}
}
\label{fig:running-trace-b}
\end{figure}

\ifaftersubmission
\bcp{We really want readers to understand this trace.  I think we should
  spend a few more words walking through it in detail.}\leo{Not sure
  exactly what you mean here. It would take roughly a page to go through
  each instruction in detail - that's what the last column is for in my mind.
  Or do you have something else in mind?}
\bcp{I was thinking about just a few words, not a page.  But let's do this
  later.}
\fi

\Cref{fig:running-program} shows a high-level view of our running example,
written in C-like pseudo-code.  It consists of a {\tt main} function that
performs a call to some function {\tt f}, which in turn makes a nested call
to some function {\tt g} before returning, while performing some simple
arithmetic operations in the process. \Cref{fig:running-trace-b} shows an
execution trace of the corresponding machine instructions. These might have
been generated by compiling the high-level code, but it is only the behavior
of the machine instructions that we care about
here---\Cref{fig:running-trace-b} is our actual example.

To streamline the example, we use a small instruction set reminiscent of
RISC-V and make a few simplifying assumptions about the organization of
memory.
%
First, as noted above, since our goal is to formalize stack safety, we
ignore the heap
and assume that all variables are stack allocated.
%
We also assume that the machine is word- (not byte-) addressed, that program
instructions start from location 0, that the machine communicates with the
outside world through a single memory-mapped output port at address 99 (so
a {\tt print} statement will be compiled to a store to this
location), and that the stack begins at location 100 and grows upwards.
% \leo{Explain more?  How to connect to realistic one? Observations? DMA?
%   Interrupt handlers?}\bcp{Yes.}

A sketch of the initial memory layout appears at the top of
\Cref{fig:running-trace-b}: the instructions for {\tt main} begin at 0,
and the (uninitialized)
stack begins at 100. Directly below the memory sketch, we summarize the parts
of the register file that are relevant at this point in the example.
%
The rest of \Cref{fig:running-trace-b} traces the execution of the
program, showing the machine state at call and return points.
Instructions are intended to
be similar to RISC-V, but are described in a (hopefully more readable) an
ad-hoc notation
rather than using assembler syntax. The $\jal$ (jump-and-link)
instruction used for calls atomically simultaneously the return address in a
register
and jumps to a specified new $\PCname$; the $\jalr$ (jump-and-link-via-register)
instruction used for returns jumps to the address stored in a register.
Register $r_0$ is hardwired to zero, so that, e.g., instruction 3 stores $0$
into address 101.

%\apt{Need to clarify to what extent our properties depend on the
%particular compilation style, calling sequences, etc. illustrated here.}


\section{Machines, Traces, and Observations}
\label{sec:prelim}

We next describe our machine model. To make our definition of stack safety
as generic as possible, this section proposes an abstract interface to a
machine model plus some kind of (static or dynamic, software- or
hardware-enforced) policy monitor. In~\cref{sec:enforcement}, we will
instantiate this model with a concrete dynamic policy enforcement mechanism
based on \citet{DBLP:conf/sp/RoesslerD18}.

\subsection{Values, States, and Observations}

The basic building blocks of the machine are {\em values} and {\em
  addresses}. Both are drawn from some set of {\em words}
$\WORDS$, ranged over by $\word$.
%
Our machine states are composed of {\em components} $k$, addressed either by
words (memory addresses) or by register names ($r$) drawn from some set
$\REGS$.
%
    \[\component \in \COMPONENTS = \WORDS + \REGS \]
%
The register names are assumed to include two special purpose registers: the
program counter {\PCname} and the stack pointer \SP.

A {\em machine state} is a map from components to values:
%
\[\mach \in \MACHS = \COMPONENTS \rightarrow \WORDS\]

The step function of the machine takes a machine state and produces a
pair of a machine state and an {\em observation}, which may be either
silent (written $\tau$) or a word of data\bcp{This is a rather concrete
  choice!  Why not leave the set of observations abstract?} that the machine
communicates to the outside world:
%
\[\obs \in \OBSS = \{\tau\} \uplus \WORDS\]
\[\mach \stepstoobs{\obs} \mach' : \MACHS \rightarrow \MACHS \times \OBSS \]
%
This step function is total: execution traces are infinite unless
cut short externally by a policy fault (as explained below).

We choose to model observations explicitly, rather than simply
treating
a subset of registers or memory as being observable.  This choice gives
us the flexibility to treat programs as observationally equivalent even when
their internal states may differ.
%The choice of modelling observations is an interesting one. A first approach
%would be to consider any change to the registers or memory as observable.
%However, as some parts of the stack will be considered ``private''
%this choice won't work. A relaxation of this to consider all changes
%to ``non-private'' data as observable could work in principle, but
%does not allow for an interesting weaker-but-more-efficient enforcement
%mechanism. We will come back to this point in \Cref{sec:lazy}.

In the running example of \Cref{sec:running-example},
$\WORDS$ is the
set of 64-bit integers and $\REGS$ is the set $\{r_0, \cdots, r_{31}\}
\cup \{\PCname,\SP\}$. Observations are writes to the
special $\rout$ location\bcp{Which is 100! (do we need a name for it? seems
  not...)}, which can be thought of as a memory-mapped
  output port: if during an execution step a word $w$ is
written to $\rout$ then $\obs = w$, otherwise $\obs = \tau$.

\subsection{Policies}

We now present our model of enforcement, which we introduced
informally in \Cref{sec:threat}.  A policy is a general model of an
enforcement mechanism, consisting of a set of policy states \(\pol \in
\POLS\), a policy step function \((\mach, \pol) \polstep \pol' :
\MACHS \times \POLS \rightharpoonup \POLS\). We assume that the
compiler provides an initial policy state $\pol_0$ to accompany
the initial machine state.
%
A concrete policy based on \citet{DBLP:conf/sp/RoesslerD18} will be described in
\Cref{sec:enforcement}.

We write $\MPS$ for the set of all pairs of machine states and policy
states.
%
\[\mpstatename \in \MPS = \MACHS \times \POLS\]
%
We lift the policy step function to operate on such pairs
by combining it with the regular step function for machine states.

\judgmenttwo{\(\mach_1 \stepstoobs{\obs} \mach_2\)}{\((\mach_1, \pol_1)
               \polstep \pol_2\)}
            {\(\mpstate{\mach_1}{\pol_1} \stepstopol{\obs}
               \mpstate{\mach_2}{\pol_2}\)}


\subsection{Traces}

A trace over a type $\TRACEELEMS$ is a nonempty, finite or infinite sequence of
$\TRACEELEMS$s; we write $\TRACE{\TRACEELEMS}$ for the set of traces over
$\TRACEELEMS$. We will mostly be concerned with sequences of pairs of
machine states
and observations, called machine traces and denoted $\machT \in \MOTRACE$,
and with sequences of triples of a machine state, a policy state, and an
observation, denoted $\MPT \in \MPOTRACE$ and referred to as MP-traces.

\paragraph*{Trace-Of}

The ``trace-of'' operator, written \(\mach \hookrightarrow \machT\),
coinductively relates a machine state with the trace of machine states
and observations produced by repeated application of step:

\judgmenttwo{\(\mach_0 \stepstoobs{\obs} \mach_1\)}{\(\mach_1 \hookrightarrow \machT\)}
            {\(\mach_0 \hookrightarrow (\mach_0,\obs) \machT\)}%
%
\noindent
(We use juxtaposition of an element and a sequence to represent ``cons.'')
Since the step function is total, if \(\mach \hookrightarrow \machT\),
then \(\machT\) must be infinite.

In our running example in \Cref{fig:running-trace-b} we can
see a depiction of such a trace: starting from an initial machine
state at the very top, each instruction leads to a new machine state
(the diff of which, compared to the previous one, appears in the
``{\textit{Effect}'' column), and the majority of observations are $\tau$, except
for instructions 31 and 13, which are writes to $\rout$
where the observations are $0$ and $60$, respectively.

In a similar fashion, we define \(\mpstatename \hookrightarrow \MPT\)
to relate a machine-policy state pair to the MP-trace
induced by the step function on $\MPS$. Unlike the $\MOTRACE$ above, this trace can
be finite as the policy can cause a fault, in which case the final observation is
a \(\tau\):

\begin{minipage}{.4\textwidth}
\judgment{\(\neg \exists \pol_1 . \mpstate{\mach_0}{\pol_0} \polstep \pol_1\)}
         {\(\mpstate{\mach_0}{\pol_0} \hookrightarrow \mpostate{\mach_0}{\pol_0}{\tau}\)}
\end{minipage}
\begin{minipage}{.55\textwidth}
  \judgmenttwo{\(\mpstate{\mach_0}{\pol_o} \stepstopol{\obs}
                 \mpstate{\mach_1}{\pol_1}\)}
              {\(\mpstate{\mach_1}{\pol_1} \hookrightarrow \MPT\)}
              {\(\mpstate{\mach_0}{\pol_0} \hookrightarrow
                 \mpostate{\mach_0}{\pol_0}{\obs} \MPT\)}
\end{minipage}

We will also use \(\pi_m\) to project the trace of machine states
out of a trace, \(\pi_p\) to project the trace of policy states, and
\(\pi_o\) to project the observations, with \(\pi_m\) and \(\pi_o\) overloaded
for machine traces and MP-traces.

\paragraph*{Head and Last}

We take the first element of a trace with \(\head(\Trace)\), which is a total
function since traces are non-empty, and the final element (if one exists) with
\(\last(\Trace)\), which is partial.

\paragraph*{Until}
The operation \(\PUT~(f,\Trace)\)
%\bcp{Wouldn't
%``While'' be more mnemonic?} \sna{Appealing, but it's more of a
%``while-not''? Trying out ``until''. In any case... moving away
%from doing joins means this needs to get some work to eliminate
%the trailing observation. Here's an attempt.}
takes a trace\bcp{I changed a : here to $\in$.  We should check if there are
any more to fix.}
\(\Trace \in \TRACE{\TRACEELEMS} \times \OBSS\) and a predicate
on elements \(f \subset \TRACEELEMS\) and gives the prefix of
\(\Trace\) ending with the first element on which \(f\) holds.
One subtlety is that, because the observation associated with some element
in a trace
represents what can be observed when this element is executed (i.e., the
observation on that step), when we take a prefix from a trace containing
observations
we must replace the final observation with a \(\tau\).

  \begin{center}
  \begin{minipage}{.3\textwidth}
    \judgment{\(f\ \traceelem\)}
             {\(\PUT~(f,(\traceelem,\obs)\Trace) = (\traceelem,\tau)\)}
  \end{minipage}
%
  \begin{minipage}{.3\textwidth}
  \judgment{}
           {\(\PUT~(f,(\traceelem,\obs)) = (\traceelem,\tau)\)}
%
  \end{minipage}
  \begin{minipage}{.3\textwidth}
  \judgmenttwo{\(\neg f\ \traceelem\)}{\(\PUT~(f,\Trace) = \Trace'\)}
              {\(\PUT~(f,(\traceelem,\obs)\Trace) = (\traceelem,\obs)\Trace'\)}
  \end{minipage}
  \end{center}
%
If the resulting trace is a strict prefix of the parameter, then the
predicate must hold on its final element. If the predicate never holds, then
\(\PUT\) is the identity function.

% The {\it join} operation, written \(T_1 \cdot T_2\) is the reverse of
%$\mathit{split}$: it takes two traces and links them by replacing the
%last element of the first (if it has one) with the first element of
%the second

%\judgment{} {\(t \cdot T = T\)}
%\judgment{\(T_1 \cdot T_2 = T\)}{\(tT_1 \cdot T_2 = tT\)}
%\leo{Lemma/theorem: split/join = id?}
%\leo{TODO: FORMATTING: Remove force line break/par at end of judgments}

We will frequently take a prefix of the trace from an initial state up
through the first state where some condition holds on the machine state.
This can easily be implemented using \(\PUT\), and we provide special notation
for convenience.
%
If \(f\) be a predicate on machine states, we define \(\mach
\hookrightarrow \machT | f\) (read ``\(\machT\) is the prefix of
running \(\mach\) up to \(f\)'')

\judgmenttwo{\(\mach \hookrightarrow \machT'\)}
            {\(\PUT~(f,\machT')
              = \machT\)}
            {\(\mach \hookrightarrow \machT | f\)}
\noindent
and similarly for traces with policies:

\judgmenttwo{\(\mpstatename \hookrightarrow \MPT'\)}
            {\(\PUT~(\lambda \mpstate{\mach}{\pol}.f\ \mach,\MPT') = \MPT\)}
         {\(\mpstatename \hookrightarrow \MPT | f\)}

%    \COQ{this operation steps until it reaches a state on which \(f\) holds,
%    and is infinite if it doesn't. It doesn't compute the observation of the step after the final,
%    which coq would. So coq may need a ``step until'' relation rather than ``prefix up to''.
%    Still thinking about this.}\leo{So this is strictly weaker than the one we have in Coq, right?
%      So its only the Eager implies Lazy direction that might need tweaking, but not the Test implies Eager one?}
%    \leo{Also, it steps until it reaches an f-state or if the policy raises a fault}

\paragraph*{Observational Similarity}

We say that a trace of observations $\obsT_1$ is a prefix of $\obsT_2$
as far as an external observer is concerned, written \(\obsT_1 \lesssim
\obsT_2\), if the sequence of
non-silent observations of $\obsT_1$ is a prefix of those of
$\obsT_2$; that is, we operate up to deletion of \(\tau\) observations,
coinductively:

\begin{minipage}{.3\textwidth}
  \judgment{}{\(\obsT \lesssim \obsT\)}
\end{minipage}
\begin{minipage}{.3\textwidth}
\judgment{}{\(\tau \lesssim \obsT\)}
\end{minipage}
\begin{minipage}{.3\textwidth}
\judgment{}{\(w \lesssim w\obsT\)}
\end{minipage}

\begin{minipage}{.3\textwidth}
\judgment{\(\obsT_1 \lesssim \obsT_2\)}
         {\(\tau \obsT_1 \lesssim \obsT_2\)}
\end{minipage}
\begin{minipage}{.3\textwidth}
\judgment{\(\obsT_1 \lesssim \obsT_2\)}
         {\(\obsT_1 \lesssim \tau \obsT_2\)}
\end{minipage}
\begin{minipage}{.3\textwidth}
\judgment{\(\obsT_1 \lesssim \obsT_2\)}
         {\(w\obsT_1 \lesssim w\obsT_2\)}
\end{minipage}

\smallskip
We then define similarity of observation traces as traces prefixing each other:
\[\obsT_1 \simeq \obsT_2 \triangleq \obsT_1 \lesssim \obsT_2 \land \obsT_2 \lesssim \obsT_1\]
%
%\leo{I still don't know how to do this transition. Maybe contrast
%with the ``perhaps surprisingly'' later?} Note that
%similarity of observation traces could alternatively be defined coinductively,
%just like the prefix relation, but by dropping the asymmetric rules that allow
%for a finite trace ($\tau \lesssim \obsT$ or $w \lesssim w\obsT$).\apt{Is this immportant?}\leo{I agree. Probably not}

Note that an infinite silent trace is a
prefix of (and equivalent\bcp{similar?} to) any other trace. While this might seem
surprising at first, it makes sense in a timing-insensitive context:
an external observer looking at two machine runs cannot (computably)
distinguish between a machine that steps forever and a machine that
steps for a long time before producing some output.

\section{Stack Safety, Formally}
\label{sec:lse-and-wbcf}

We are finally ready for our definition of stack safety. We begin
by describing how we model knowledge about the program structure,
then dive into the formal definitions of local state encapsulation and
well-bracketed control flow, which together constitute stack safety.

\subsection{Program Structure}

Our properties and policies are parameterized by several types of
annotations describing features of a program.

\paragraph*{Function Map}

A {\em function map} identifies some addresses as code and assigns
each to a function. Formally, a function map is a
partial function from addresses to a function
identifier drawn from the set \(\FUNIDS\).
  %
\[\codemap \in \CODEMAPS = \WORDS \rightharpoonup \FUNIDS\]
%
In our running example, instructions 1-13 correspond to {\tt main},
instructions 20-36 correspond to {\tt g}, and instructions 40-47
correspond to {\tt h}, which means that the function map would be:
\[ \codemap = \{\texttt{main} \mapsto \{1\ldots13\}, \texttt{g} \mapsto \{20\ldots36\}, \texttt{h} \mapsto \{40\ldots47\}\}\]

\paragraph*{Call Map}

A {\em call map} identifies addresses that complete a call sequence,
abstracting away from any concrete calling convention. Formally, it is
a partial function from addresses to a natural number, the number of
arguments and return values of the call.
  %
\[\callmap \in \CALLMAPS = \WORDS \rightharpoonup \mathbb{N}\]
%
In our running example, the callmap contains two entries: the word 7
corresponding to the call to {\tt g} which has one argument and one
return value; and the word 26 corresponding to the call to {\tt h},
also with a single argument and return value:
\[ \callmap = \{ 7 \mapsto 2, 26 \mapsto 2\}\]

For concreteness, in a typical calling convention, a call map may be
considered to identify the state just before the \jal, in which
space for arguments is already allocated, but the mechanism is more
general. A state in which a call map is defined on the program counter
is referred to as a {\it call state}.

\paragraph*{Return Map}
Similarly, a {\em return map} identifies addresses that complete a
return sequence. Formally, it is simply a set of words; each one
is the address of the final jump corresponding to a function return:
%
\[\retmap \in \RETMAPS \subseteq \WORDS\]
%
In our running example, the return map identifies the $\jalr$
instructions 36 and 47:
\[ \retmap = \{36, 47\} \]

\paragraph*{Entry Map}
Finally, the entry map identifies valid entry points to a
function and is also a set:
\[\entmap \in \ENTMAPS \subseteq \WORDS\]
%
In our running example, the entry map contains the entry
points of {\tt g} and {\tt h}:
\[ \entmap = \{20, 40\} \]

\paragraph*{What is a return?}

We separately identify, for any call state, what it means for a state
to have correctly returned from a call. We consider the call to have
returned when control returns to the instruction following
the \jal with the stack restored. Formally, this is a predicate on
states that says when the machine has just returned from a specified call state
(where $\nextPC$ gives the address of the next instruction after a given address):
\[%\begin{split}
    \ret{\mach_c} \triangleq  \lambda \mach_r . \mach_r(\PCname) =
    \nextPC(\mach_c(\PCname)) \land  \mach_r(\SP) = \mach_c(\SP)
%\end{split}
\]
There are two such return points in our running example, both of which
are depicted in the figure: the state before the execution of
instruction 27 corresponding to the return from {\tt h} and the state
before instruction 8 corresponding to the return from {\tt g}.

\medskip

In the rest of this section we implictly parameterize all
definitions by a function map $\codemap$, a call map $\callmap$, a return
map $\retmap$ and an entry map $\entmap$.

\subsection{Local State Encapsulation}
\label{sec:lse}

The first part of stack safety is {\em local state encapsulation}.
Informally, it captures the notion that a caller's data is
protected from a callee's actions. We formalize this notion
as a security property with an integrity and a confidentiality
component, where the former protects the caller's data from being
written and the latter from being read.

As is standard with security properties, we associate with each
component of the machine a {\em label}: a pair of security levels
denoting high or low confidentiality and high or low integrity.
%
\[\mathit{label} ::= \{\HIGHSEC,\LOWSEC\} \times \{\HIGHINT,\LOWINT\}\]
%
In a traditional setting, integrity would enforce that the contents of
$\HIGHINT$ locations remain unchanged, while confidentiality would
enforce that the contents of $\HIGHSEC$ locations do not influence the
observable behavior of the machine. However, when dealing with nested
calls and returns, stack safety needs to enforce integrity and
confidentiality for {\em every} function call in a trace; that is, we
must treat the security level of data dynamically.
%
To that end, we introduce the notion of a {\em contour}, a map from
components to labels:
%
\[\contour \in \CONTOURS ::= \COMPONENTS \rightarrow \mathit{label}\]

When \(\mach_c\) is a call state (\(\callmap(\mach_c(\PCname)) = n\) for some $n$) and
\(\mach_c \stepstoobs{\obs} \mach_e\) for some
$\mach_e$ and $\obs$, we can construct a contour based on the bounds of the
callee's stack frame.
%
The private state of the callee is the entire area of the memory from
stack base to stack pointer, with the exception of the $n$ locations
corresponding to the arguments and result locations of the
call. Private components are marked high confidentiality and high
integrity: the callee should be able to neither read nor write them.
%
Everything above the stack pointer at the point of the call is
``uninitialized'' memory that can be written into but should not be
read. To protect the callee itself from such reads, these components
are marked high confidentiality and low integrity.
%
The same is true for the designated output location: it can be
freely written into but should not be read.
%
Code is always high integrity and low confidentiality.
%
Finally, registers and the frame of arguments and results are free
for the callee to use, and are therefore tagged with low integrity and
low confidentiality.

 \[\mathit{Cof}(\mach,n)(\component) =
  \begin{cases}
    (\LOWSEC,\HIGHINT) & \text{if } \component \in \WORDS
                         \text{ and } \codemap(\component) = \funid \text{ for some }\funid\\
    (\HIGHSEC,\LOWINT) & \text{else if } \component \in \WORDS
                          \text{ and } \component \geq \mach(\SP)
                          \text{ or } \component = \rout\\
    (\HIGHSEC,\HIGHINT) & \text{else if } \component \in \WORDS
                          \text{ and } \component \leq \mach(\SP) \negate  n \\
    (\LOWSEC,\LOWINT) & \text{else} \\
  \end{cases}\]

Going back to our running example, here is the state of the machine at
the call from {\tt main} to {\tt g}, showing addresses annotated with their
corresponding labels:
\vspace*{0.2em}
% At Call to G
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{43.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{$(\HIGHSEC,\HIGHINT)$}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{$(\HIGHSEC, \LOWINT)$}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{$(\HIGHSEC, \HIGHINT)$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{$(\LOWSEC, \LOWINT)$}}]%
\memory{6}{\unusedc}[{\makebox[0pt]{$(\HIGHSEC, \LOWINT)$}}]
~$\cdots$
\MemoryLabel{-46.5em}{0.75em}{42}
\MemoryLabel{-42.5em}{0.75em}{0}
\MemoryLabel{-38.5em}{0.75em}{0}
\MemoryLabel{-34.5em}{0.75em}{0}
\\
\end{center}

%If $\mach$ is the state at this call, the corresponding contour would
%be:
%\[
%\mathit{Cof}(\mach,2) = \left \{
%\begin{array}{l}
%  0\ldots98\} \mapsto (\LOWSEC, \HIGHINT)\\
%  99 \mapsto (\HIGHSEC, \LOWINT)\\
%  100, 101 \mapsto (\HIGHSEC, \HIGHINT)\\
%  102, 103 \mapsto (\LOWSEC, \LOWINT)\\
%  104\ldots \mapsto (\HIGHSEC, \LOWINT)\\
%  r \mapsto (\LOWSEC, \LOWINT)\\
%\end{array}
%\right .
%\]


\subsubsection{Stack Integrity}

The first component of local state encapsulation is an integrity
property: it ensures that the caller's data is never overwritten by a
callee. We will formally define integrity in two steps: first, we will
define integrity as a trace property over the trace corresponding to a
single call (from its entry point to its corresponding return), and
then we will lift that to a property for every such subtrace of a
callee.

\definition

Let \(\contour\) be a contour and \(\MPT\) be a (potentially infinite)
\(\MPOTRACE\). We say \(\MPT\) satisfies {\em trace integrity} with
respect to \(\contour\) if its final state (if any) agrees with its
initial one on all components marked \(\HIGHSEC\) in \(\contour\):
%
\[\begin{split}
  \propdef{TraceInt} ~ \contour ~ \MPT \triangleq &
    \mpostate{\mach_e}{\pol_e}{\obs_e} = \head(\MPT) \Rightarrow \\
  & \mpostate{\mach_r}{\pol_r}{\obs_r} = \last(\MPT) \Rightarrow \\
  & \forall \component. ~ \contour(\component) = \HIGHSEC \Rightarrow
    \mach_e(\component) = \mach_r(\component) \\
\end{split}\]
\sna{Experimenting with font on the mathy version of the property.}

Intuitively, the caller expects to find their private data untouched
after the callee returns. That means that if the callee never returns,
integrity is trivially satisfied. Similarly, the callee is allowed to
temporarily overwrite these locations, as long as they are restored
once control returns. We will see variations of this later on: a
stronger, inductive integrity property that ensures that the caller's
private data is never overwritten, even during the caller's execution
(which leads to easier reasoning and more effective testing);
and a weaker, lazy integrity property that only ensures the preservation
of locations that subsequently affect the caller's observable actions
(which allows for a more efficient enforcement mechanism).

\begin{figure}
  \integrityexample
  \caption{Failing Trace Integrity}
  \label{fig:intex}
\end{figure}

Trace integrity characterizes the trace corresponding to a single
callee.
Going back to our running example, such a trace would be, for
instance, the entire trace of {\tt h} from instruction 40 to
instruction 47.
As an example of an integrity violation affecting this trace, \cref{fig:intex} shows what happens
if we change line 44 of the example program to $[\rsp - 5] \leftarrow r_4$.
Instead of storing data to the return value slot,
the changed version overwrites {\tt g}'s local variable {\tt z}.
The figure shows the modified trace, with snapshots of the initial
and final states colored to show the contour; high
integrity memory is in \high, while low integrity is in \low.
At the end of the trace high integrity address 103 should match the initial
state, and does not. So trace integrity is violated.

We now lift this definition to an integrity property for a complete
execution trace. We do this by requiring that trace integrity holds
for every subtrace delimited by a call and its corresponding return.

\definition Given a trace \(\MPT\) and a call map \(\callmap\)
%and a function map \(\codemap\),
an \(n\)-{\em transition} is a pair of
machine-policy state pairs \(\mpstate{\mach_c}{\pol_c}\) and
\(\mpstate{\mach_e}{\pol_e}\) in the trace such that
\(\mach_c\) is a valid call with \(n\) arguments, and
\(\mpstate{\mach_c}{\pol_c}\) steps to \(\mpstate{\mach_e}{\pol_e}\).

%and \(\mach_e\) is an entry point for some function \(f\):

  \[\begin{split}
    \mathit{Tr}_n ~ \MPT ~ \mpstate{\mach_c}{\pol_c} ~ \mpstate{\mach_e}{\pol_e}
    \triangleq & \exists \obs.
    ~ \mpstate{\mach_c}{\pol_c} \stepstopol{\obs} \mpstate{\mach_e}{\pol_e} \\
    & \land \callmap(\mach_c(\PCname)) = n
      %\land \codemap(\mach_e(\PCname)) = f
  \end{split}\]

\definition

We say that a system enjoys {\em stack integrity} if for every initial
state $(\mach_0,\pol_0)$ and its corresponding induced trace $\MPT$ (with
$\mpstate{\mach_0}{\pol_0} \hookrightarrow \MPT$), for every
$n$-transition from $\mpstate{\mach_c}{\pol_c}$ to
$\mpstate{\mach_e}{\pol_e}$ in $\MPT$, if we take the prefix of the
call until its corresponding return $\mpstate{\mach_e}{\pol_e}
\hookrightarrow \MPT_{call} ~ | ~ \ret{\mach_c}$, then $\MPT_{call}$ must
satisfy trace integrity:
\[\propdef{TraceInt} ~ \mathit{Cof}(\mach_c,n) ~ \MPT_{call}\]


%{\em Stack integrity} is a property of a system with respect to a call map
%\(\callmap\) that holds when every \(n\)-transition  in every legal trace exhibits trace integrity
%on the prefix up to its return, if any. For any initial state \(\mach_0\)
%we take the induced trace. For each \(n\)-transition \(\mathit{Tr}_n ~ \MPT ~
%\mpstate{\mach_c}{\pol_c} ~ \mpstate{\mach_e}{\pol_e}\) we take the prefix of
%the call up to its return, \(\mpstate{\mach_e}{\pol_e} \hookrightarrow
%\MPT_{call} | \ret{\mach_c}\). If for any such call trace \(\MPT_{call}\),
%\(\propdef{TraceInt} ~ \mathit{Cof}(\mach_c,n) ~ \MPT_{call}\), then the
%system as a whole enjoys stack integrity with respect to \(\callmap\).
%
%\apt{Some more words needed here to smooth the technicalities.}
%\sna{Attempt...}
%Rewrote for clarity

\subsubsection{Stack Confidentiality}

The second component of local state encapsulation is a confidentiality
property: just like integrity ensures that a caller's data is never
overwritten by a callee, confidentiality ensures that the caller's data never
influences the callee's observable behavior. We will formally define
confidentiality in two similar steps: a trace version and a system
version.

Unlike integrity, confidentiality is a noninterference-style property,
comparing the behavior of a machine with an arbitrary variation that
preserves low confidentiality data.

\definition%{Variations}
We say two machine states \(\mach\) and \(\mach'\) are {\em variations}
of one another given a contour \(\contour\) if they agree on low
confidentiality data:
%
\[
\mach \approx_\contour \mach' \triangleq \forall \component .
\contour(\component) = \LOWSEC \Rightarrow \mach(\component) =
\mach'(\component)
\]
%
Then, the trace version of confidentiality operates on two traces: the
``original'' trace $\MPT \in \MPOTRACE$ that corresponds to a callee $f$
and a ``variant'' trace $\machT \in \MTRACE$ that corresponds to how $f$
would behave if it were started from a variant initial machine state.
%
As an example of variations, consider the top of \Cref{fig:confex}
which shows a snapshot of the state as in the running example (top
memory layout) and a variation of it (bottom).
%
The ``Effect'' column shows differences between the two runs by writing values
in the original run in {\high} and values in the variant run in {\varied}
separated by a slash.
%
This example will end up a violation of confidentiality, as a
difference in a confidential location (\textcolor{cyan}{42} vs
\textcolor{magenta}{5} in location 100) leads to a visible
difference in return value.

\definition

{\em Trace confidentiality} will be a property of two traces, \(\MPT\) and
\(\machT\), with respect to a return predicate \(R \subset \MACHS\) that
reflects the states that are considered to have returned. We abstract over
\(R\) because what it means to return depends on the state from which
\(f\) was called. There are three cases in which \(\MPT\) and \(\machT\)
enjoy trace confidentiality with respect to \(R\).

\begin{itemize}
  \item If \(\MPT\) has a final state \(\last(\MPT) = \mpostate{\mach_r}
    {\pol_r}{\obs_r}\) and \(R\ \mach_r\), then \(\machT\) is also finite with
    some final state \(\mach_r'\) and any changes from the initial states are
    matched between \(\mach_r\) and \(\mach_r'\). In addition their
    observations are similar.
    \[\begin{split}
      \mathit{ReturnCase} ~ R ~ \MPT ~ \machT \triangleq &
      \forall ~ \mach_r ~ \pol_r ~ \obs_r ~ \component . \last(\MPT) =
        \mpostate{\mach_r}{\pol_r}{\obs_r} \Rightarrow \\
      & \exists \mach_r' ~ \obs_r' . \last(\machT) = (\mach_r',\obs_r')
        \land \pi_o(\MPT) \eqsim \pi_o(\machT) \land \\
      & ~ (\mach_e(\component) \not = \mach_r(\component)
        \lor \mach_e'(\component) \not = \mach_r'(\component) \Rightarrow
      \mach_r(\component) = \mach_r'(\component))
    \end{split}\]
  \item If \(\MPT\) is infinite, then \(\machT\) is also infinite and their
  observations are similar.
    \[\begin{split}
      \mathit{InfCase} ~ R ~ \MPT ~ \machT \triangleq
      & \neg (\exists mpo . \last(\MPT) = mpo) \Rightarrow \\
      & \neg (\exists mo . \last(\machT) = mo)
        \land \pi_o(\MPT) \eqsim \pi_o(\machT)
    \end{split}\]
\item If \(\MPT\) ends prematurely without fulfilling \(R\), then
  its observations are a prefix of those of \(\machT\).
    \[\begin{split}
      \mathit{FailCase} ~ R ~ \MPT ~ \machT \triangleq
      & \forall \mach_r ~ \pol_r ~ \obs_r .
        \last(\MPT) = \mpostate{\mach_r}{\pol_r}{\obs_r} \Rightarrow \\
      & \neg ~ R ~ \mach_r \Rightarrow \\
      & \pi_o(\MPT) \lesssim \pi_o(\machT)
    \end{split}\]
\end{itemize}

Putting it all together:

\[\begin{split}
  \propdef{TraceConf} ~ R ~ \MPT ~ \machT \triangleq
  & \mathit{ReturnCase} ~ R ~ \MPT ~ \machT \land \\
  & \mathit{InfCase} ~ R ~ \MPT ~ \machT \land
    \mathit{FailCase} ~ R ~ \MPT ~ \machT \\
\end{split}\]

In the non-return cases, we only care that the traces exhibit the same
observable behavior (or a prefix if the trace halts prematurely), as changes
in the state will not affect the caller absent a return.  In the return case
we must additionally guarantee that no changes were made based on secret data
that could corrupt the caller upon return.

Consider the result of modifying line 42 of our running example to $r_4 \leftarrow [\rsp - 9]$.
Instead of reading the proper argument {\tt v}, {\tt h} now reads directly from the
secret value of {\tt x} that belongs to {\tt main}. \Cref{fig:confex}
shows \(\mach_e\), the entry state of {\tt h}, with high confidentiality memory
in {\high} and low confidentiality in {\low}. Below it, the variant state
\(\mach_e'\) agrees on low confidentiality memory, but all other addresses
hold $-5$, in {\varied}.  After the last step, the return states \(\mach_r\) and
\(\mach_r'\) should agree on every component that changed since \(\mach_e\) or
\(\mach_e'\). Addresses 108 and 109 have changed, shown in light {\low}, and while 109
had changed in a consistent way (independent of the variation), 108 holds either 43 or $-4$, so the trace does not obey trace confidentiality.
%\rb{Color name macros}
%\apt{Explain slash notation in effects column.}
%\rb{Wrote some words to explain after def. 5.4 (variations).}

As another example, changing instruction 30 of the running example to
$r_5 \leftarrow [\rsp - 6]$ would cause {\tt g} to read the value of
{\tt main}'s local variable {\tt x} and then immediately output it,
violating the internal observation clause of the confidentiality
definition.

\begin{figure}
  \confidentialityendexample
  \caption{Failing Trace Confidentiality}
  \label{fig:confex}
\end{figure}

To lift trace confidentiality to a system property, we follow the same
pattern as in stack integrity:

\definition%{Stack Confidentiality}
%Let $\callmap$ be a call map and $\codemap$ a function map.
For every initial state \((\mach_0,\pol_0)\), we take the induced trace
\(\mpstate{\mach_0}{\pol_0} \hookrightarrow \MPT\). Then for
any \(n\)-transition from $\mpstate{\mach_c}{\pol_c}$ to
$\mpstate{\mach_e}{\pol_e}$ in $\MPT$, we take the prefix of the trace
from the entry point until its corresponding return:
%
\[\mpstate{\mach_e}{\pol_e} \hookrightarrow \MPT_{\mathit{call}} ~ | ~ \ret{\mach_c}\]
%
We also take the corresponding trace from any variant \(\mach_e'
\approx_{\mathit{Cof}(\mach_c,n)} \mach_e\):
%
\[\mach_e' \hookrightarrow \machT_{\mathit{call}} ~ | ~ \ret{\mach_c}\]
%
%For all such pairs of traces, \(\propdef{TraceConf} ~
%\ret{\mach_c} ~ \MPT_{\mathit{call}} ~ \machT{\mathit{call}}\) must hold.
%Trace confidentiality must also hold on the trace as a whole, so that
%unallocated memory is still secret. Let \(\mach_0'
%\approx_{\mathit{Cof}(\mach_0),0} \mach_0\) and \(\mach_0' \hookrightarrow
%\machT\). Then \(\propdef{TraceConf} ~ \emptyset ~ \MPT ~ \machT\) must hold.
%
If trace confidentiality holds for all such traces,
\(\propdef{TraceConf} ~ \ret{\mach_c} ~ \MPT_{\mathit{call}} ~
\machT_{\mathit{call}}\) and it also holds for the toplevel execution
trace to account for unallocated memory \(\propdef{TraceConf} ~
\emptyset ~ \MPT ~ \machT\) , then the system as a whole enjoys {\em
  stack confidentiality} with respect to \(\callmap\).

\subsection{Well-bracketed Control Flow}
\label{sec:wbcf}

Both the integrity and confidentiality components of local state
encapsulation concern themselves only with the accessibility of data,
and may still hold on a wide range of programs that violate expected
control flow. For instance, if {\tt g} managed to jump in the middle of
the code of {\tt h} with its call, confidentiality and integrity would
still be satisfied.
%
However, that is still unwanted behavior: for example, a caller (or a
callee) should not be able to bypass a password check by jumping (or
returning) in the middle of a block of code --- even if such an execution
would ostensibly satisfy local state encapsulation.
%
Stack safety enforcement mechanisms like \citet{Skorstengaard+19}
usually aim to prevent such unwanted flows: every jump between
functions should either be a call or a return, and each return should
be to the instruction after its corresponding call.

To formally capture this aspect of stack safety, we introduce three
security properties that rely on the underlying knowledge of the
program structure (call map $\callmap$, function map $\codemap$, return map $\retmap$, and entry
map $\entmap$): {\em control separation} ensures the validity of transition
sources between functions, {\em entry integrity} ensures the validity
of call targets, and {\em return integrity} ensures that of
return targets.

\definition%{Control Separation}
A system enjoys {\em control separation}
% with respect to a function map
%\(\codemap\), a call map \(\callmap\), and a return map \(\retmap\),
if, for any initial state \((\mach_0, \pol_0)\) and any adjacent pair of states
\(\mpostate{\mach_1}{\pol_1}{\obs_1}\) and \(\mpostate{\mach_2}{\pol_2}{\obs_2}\)
in the induced trace from \(\mpstate{\mach_0}{\pol_0}\),
if \(\codemap(\mach_1(\PCname)) \not = \codemap(\mach_2(\PCname))\),
then \(\mpstate{\mach_1}{\pol_1}\) is either a call \(\callmap(\mach_1(\PCname))\)
or a return \(\retmap(\mach_1(\PCname))\).

\smallskip

For example, consider changing line 5 of the running example to a $\jalr$,
$\PCname \leftarrow r_4$, with effect $\PCname \leftarrow 42$, causing {\tt main}
to jump into the middle of {\tt h}.
This violates control separation because the instruction that causes a
function switch is not a valid call (or a return) according to the
call map. On the other hand we do permit functions to jump freely internally.

\definition%{Entry Integrity}
A system enjoys {\em entry integrity}
%with respect to a call map
%\(\callmap\) and entry map \(\entmap\)
if, for any initial state \((\mach_0, \pol_0)\)
and any n-transition from \((\mach_c,\pol_c)\) to
\((\mach_e, \pol_e)\) in the induced trace from
\(\mpstate{\mach_0}{\pol_0}\), $\mach_e$ is a valid entry:
\[\callmap(\mach_c(\PCname)) = n \Rightarrow \entmap(\mach_e)\]

The changed program described just above also violates entry integrity,
because the target (instruction 42) of the new $\jalr$ is not an established
entry point according to the entry map. Our properties to not enforce which
call points jump to which entry points, however; that is left for a stronger
notion of control flow integrity.

\newcommand*{\Unmatched}{\mathit{um}}

Return integrity captures the expected behavior of marked returns with
respect to their call points. Intuitively, it says that the marked return
matching a call $\mach_c$ should satisfy $\ret{\mach_c}$.
Observe that, given an MP-trace $\mpstate{\mach_c}{\pol}\MPT$, if $\mach_c$ is
a call state then the matching return will be the first \emph{unmatched} return
in $\MPT$. So we begin by defining an auxiliary ``unmatched'' relation between
two traces.

\definition
We write $\Unmatched~\MPT~\MPT'$ if $\MPT'$ is
obtained from $\MPT$ by dropping elements until we reach the first unmatched return
(according to the return map).  Formally, $\Unmatched$ is defined coinductively as follows:
\begin{itemize}
\item A trace that starts with a return is related to itself:

\begin{minipage}{.3\textwidth}
  \judgmenttwo{\(\callmap(\mach(\PCname)) = \bot\)}
              {\(\retmap(\mach(\PCname))\)}
              {\(\Unmatched ~ \mpstate{\mach}{\pol} ~ \mpstate{\mach}{\pol}\)}
\end{minipage}
\hspace*{0.1\textwidth}
\begin{minipage}{.3\textwidth}
  \judgmenttwo{\(\callmap(\mach(\PCname)) = \bot\)}
              {\(\retmap(\mach(\PCname))\)}
              {\(\Unmatched ~ \mpstate{\mach}{\pol}\MPT ~ \mpstate{\mach}{\pol}\MPT\)}
\end{minipage}

\item If a trace \(\MPT\) starts with a non-call, non-return state,
  its unmatched return must come later:

  \judgment{\(\callmap(\mach(\PCname)) = \bot
              \hspace{.5cm} \neg \retmap(\mach(\PCname))
              \hspace{.5cm}\Unmatched ~ \MPT ~ \MPT'\)}
           {\(\Unmatched ~ \mpstate{\mach}{\pol}\MPT ~ \MPT'\)}

\item Finally, if a trace starts with a call, then we must discard the first
  unmatched return from its tail to get to the real one:


  \judgmentbr{\(\callmap(\mach(\PCname)) = n \hspace{.5cm} \neg \retmap(\mach(\PCname)) \)}
             {\(\MPT = (m,p)\MPT_{\mathit{call}}\) \quad \(\Unmatched ~ \MPT_{\mathit{call}} ~ \MPT_{\mathit{matched}}\)}
             {\(\MPT_{\mathit{matched}} = \mpstate{\mach'}{\pol'} \MPT_{\mathit{tail}}\) \quad
              \(\Unmatched ~ \MPT_{\mathit{tail}} ~ \MPT_{\mathit{unmatched}}\)}
            {\(\Unmatched ~ \MPT ~ \MPT_{\mathit{unmatched}}\)}
\end{itemize}
\ifspace
\apt{Could cut formal definition for space.}
\fi

\definition%{Return Integrity}
A system enjoys {\em return integrity} if all of its returns match prior calls
and return to the appropriate location. For any initial state \((\mach_0\, \pol_0)\), let
\(\MPT\) be the induced trace of \(\mpstate{\mach_0}{\pol_0}\).
\(\MPT\) may not have an unmatched return -- \(\Unmatched ~ \MPT ~ \MPT_{tail}\)
may not hold for any \(\MPT_{tail}\). For any state pair \((\mach_c, \pol_c)\)
corresponding to a call \(\MPT\), if
\(\mpstatename = \mpostate{\mach_r}{\pol_r}{\obs_r}\)
is the first unmatched return such that
\( \Unmatched ~ \MPT ~ \MPT_{tail}\) and \(\head{\MPT_{tail}} = \mpstatename\),
then $\mach_r$ must correspond to a return state for $\mach_c$:
\(\ret{\mach_c}\ \mach_r\)

For example, if we modified the running example by adding
an instruction $ \rra \rightarrow \rra - 19$
between 45 and 46, this would cause the return from {\tt h} to go to instruction 8 and
return to {\tt main} instead of {\tt g}. While the instruction that
causes the return would still be a valid return (satisfying control
separation), the state after the return would not correspond to an
unmatched return for {\tt g}'s call to {\tt h}, violating return
integrity.

\definition% {Well-Bracketed Control Flow}
The above properties are somewhat orthogonal, but together they
capture a standard notion of control flow for a stack: functions keep
their code separate outside of calls and returns, calls respect
explicit entry points, and returns respect implicit entry points
corresponding to their call.  A system with all three
properties (with respect to a function map, call map, return map,
and entry map) is said to enjoy
{\em well-bracketed control flow} (with respect to those maps).


\section{Enforcement}
\label{sec:enforcement}

In this section we examine how an existing enforcement mechanism,
Depth Isolation from \citet{DBLP:conf/sp/RoesslerD18}, can implement
the formal stack safety property described in the previous section: it in
fact enforces a stronger, inductive version of that property which strengthens the
local state encapsulation component by checking for integrity and
confidentiality violations at every step of the callee's execution trace.

%\paragraph*{Micropolicies}
%
The enforcement policy of \citeauthor{DBLP:conf/sp/RoesslerD18} relies
on a programmable, tag-based reference monitor that runs alongside the
program.  To control this monitor, they use a programming model that
allows fine-grained manipulation of metadata tags to encode so-called
\emph{micropolicies}~\citep{pump_oakland2015}.
In such a system, all values in
memory addresses and registers (including the $\PCname$)
are enriched with an abstract metadata tag, which can represent
arbitrary information about the value. A micropolicy is defined as a set of tags and a
collection of software-defined rules, indexed by machine opcode.
At each step of the machine, the relevant rule is applied to the tags on
the instructions inputs (PC, registers, memory) and on the instruction itself, and produces
one of two outcomes: either the instruction is allowed to execute (and generates
tags for the result of the operation and the new PC), or the machine
fail-stops with a policy violation.
\citeauthor{pump_oakland2015} have shown that a wide range of micropolicies can
be defined using this scheme.

Efficient execution of these micropolicies relies on hardware implementations,
such as the PUMP architecture~\citep{pump:asplos2015}.  Tags are represented
as word-size bit vectors, stored separately from the regular memory and registers.
The hardware incorporates a rule cache
to allow quick retrieval of rule outputs for mapped inputs. If the cache misses,
the hardware traps to a software handler (running in a privileged context or
on a co-processor) to compute the rule result. To obtain adequate performance,
it is important to design micropolicies so that they hit in the cache as
much as possible. Thus, practical policies maintain a small working set of
distinct tags.
%% %
%% \rb{Maybe go into more detail, examples later\ldots or try to segue into stack
%% policies}

\subsection{A Conservative Policy}
\label{sec:conservative}
%
The first micropolicy we present to enforce the definition of stack
safety developed in \cref{sec:lse-and-wbcf} is a small variation
on the Depth Isolation policy presented by
\citet{DBLP:conf/sp/RoesslerD18}. Their policy tags the stack memory
with ownership information associated to each stack frame (and to each
separate object inside that frame, a more finely grained access
control that we do not need to consider here), and tags registers containing
stack pointers with access permission information. The compiler also
uses tags on instructions to identify the code
sequences that have permission to manage the stack, say during calls and returns.
%% \rb{Conceivably on alloc
%%   operations, etc., which we have not yet mentioned.}

Our micropolicy works as follows. (We assume for ease of exposition that no
arguments are passed on the stack.)
%% \rb{Come back to this later?}.
The micropolicy maintains tags on values in memory of the form $\tagStackDepth{n}$,
indicating locations that belong to the stack frame at activation depth $n$,
or $\tagNoDepth$; it tags the $\PCname$ with tags of the form $\tagPCDepth{n}$.
During normal execution, the micropolicy rules only permit load and store operations
when the target memory is tagged with the same depth as the current {\PCname} tag.
Initially, the entire stack is tagged $\tagNoDepth$,
%\rb{actually, the ``initial frame'' should be tagged with its proper depth}
and the {\PCname} has tag $\tagPCDepth{0}$. These tags are altered
at exactly those points in
the program where the contour of the stack safety property changes:

\begin{itemize}

\item From caller to callee, when the machine executes an instruction marked as a call in
  the call map.
  At this point, the current
  $\tagPCDepth{n}$ tag is incremented to $\tagPCDepth{(n + 1)}$, and the function
  entry sequence initializes  all locations of the new function frame with
  tag $\tagStackDepth{(n + 1)}$.

\item From callee back to caller, when execution is about to reach the return point
  $\ret{c}$
  corresponding to the call at $c$.  The exit sequence retags all locations in the function
  frame with $\tagNoDepth$. At the actual return instruction, the
  $\PCname$ tag is decremented.

\end{itemize}

This discipline suffices to enforce local stack encapsulation.
To implement it,  we define ``blessed'' instruction sequences
intended to appear at the entry and exit of each function,
which manipulate tags as just described in addition to performing the
usual calling convention tasks of saving/restoring the return address to/from
the stack and adjusting the stack pointer. With the aid of an additional tag on
the $\rsp$ register, these sequences also serve to enforce
well-bracketed control flow.
The micropolicy guarantees atomic execution of these sequences
using a combination of tags on the instructions
and an additional tag on the $\PCname$; we omit the details here.

There remains the question of how to ensure that the sequences are
invoked at the right places. For a program to enjoy the stack safety property
(with respect to a particular call map), all we need require is that
the entry sequence be initiated at any instruction marked as a call
in the call map. This is achieved by giving these instructions (another) special tag,
and it is easy to check statically that this has been done correctly.
If the code fails to initiate an exit
sequence at a point where the stack safety property expects a return,
the micropolicy will incorrectly behave as if execution
is continuing in the callee, but since the callee never has stronger access
rights than the caller, this is harmless.

%% APT: removed because the tag part is too mysterious and the instruction part
%% is standard.
%% This is the entry
%% sequence:
%% %
%% \setcounter{pcctr}{1}
%% \[
%%   \begin{array}{l|l|l|l}
%%      & \mathit{Instruction} & \mathit{Tags} & \\
%%     \hline
%%     \row{\sw ~ \rsp ~ \tta ~ 1}{[\rsp+1] \leftarrow \rra}{\tagHa, \tagInstr}
%%         {Store return address in stack}
%%     \row{\addi ~ \rsp ~ \rsp ~ 2}{\rsp \leftarrow \rsp + 2}{\tagHb, \tagInstr}
%%         {Increment stack pointer by frame size}
%%   \end{array}
%% \]
%% %
%% And the exit sequence:
%% %
%% \setcounter{pcctr}{1}
%% \[
%%   \begin{array}{l|l|l|l}
%%      & \mathit{Instruction} & \mathit{Tags} & \\
%%     \hline
%%     \row{\lw ~ \rra ~ \rsp ~ \negate 1}{\rra \leftarrow [\rsp - 1]}{\tagRa, \tagInstr}
%%         {Load return address}
%%     \row{\addi ~ \rsp ~ \rsp ~ \negate 2}{\rsp \leftarrow \rsp - 2}{\tagRb, \tagInstr}
%%         {Decrement stack pointer by frame size}
%%     \row{\jalr ~ \rra ~ \rra ~ 0\apt{wrong}}{\PCname \leftarrow \rra}{\tagRc, \tagInstr}
%%         {Return to caller ($\jalr$)}
%%   \end{array}
%% \]

%% \rb{Positioning of the above sequences, relation to running example. The tagging
%%   of stack frames would be considered part of these sequences.}

%% These sequences also enforce the $\SP$ discipline. When stack frames
%% are of fixed size, it suffices to increment $\SP$ and tag it with a
%% dedicated tag in the header sequence, which is later checked after
%% decrementing $\SP$ during the exit sequence to authorize the
%% return. The well-formedness of the blessed sequences can be checked
%% statically.

%% Only programs whose sequences are well-formed are
%% protected by the micropolicy, although programs are still protected
%% (by fail-stopping) even if the intended sequences are missing. By
%% tracking the execution of the blessed sequences in the tag state of
%% the {\PCname} register, the micropolicy ensures that the entry
%% sequences of calls declared in the call map are executed correctly.

Note that in this policy both the entry and exit sequences
must write to each element of
the frame, which can be quite expensive, especially for programs that
allocate large but sparsely populated frames; we return to this point
in \cref{sec:lazy}.
%
%\rb{Note that we have also considered and implemented more flexible schemes
%  based on allowing operations above the current activation depth. How do we put
%  these together?}
%\rb{Do we want to discuss variations involving frame pointers or more implicit
%  return addresses, argument passing on the stack, alloc/dealloc, etc.?}
%\rb{Where to talk about the role of the compiler?}

%% Because the access rights of callers subsume those of callees, it is essential
%% that the micropolicy change tags when the property thinks that a call occurs,
%% but it is safe for the micropolicy to fail to reset to the caller's tag when the
%% property thinks a return occurs. (Dually, it is safe for the micropolicy to
%% change tags even without executing a call point, but not for it to reset tags to
%% the caller when the property thinks execution is still in the caller).

%% Because the property does not identify return sites, we have no way to require
%% that ``intended returns'' are tagged correspondingly. Some unintended results
%% might also be so tagged, but as long as the jump has the effect of a legal
%% return, it is OK.

\subsection{A Stronger Lockstep Stack Safety Property}
\label{sec:lockstep}

%% \leo{Maybe lockstep?}

This conservative policy satisfies not only the stack safety policy of
\cref{sec:lse-and-wbcf},
but also a provably (in Coq) stronger one that enforces local state
encapsulation at every point during execution. To encode that
property, we not only keep track of the execution of one machine
(whose trace we are trying to characterize as safe), but of an entire
stack of machine variations corresponding to nested calls of the
original machine. For each step of the original machine, we take a
step in every variant machine (thus, keeping them in lockstep
execution) and enforce a single-step variant of integrity and
confidentiality tests. In addition, every time a call is made we push
a variation of the original machine state at the time of that call on
top of the variant stack (just like the stack confidentiality property
enforced trace confidentiality for every transition\apt{can we change ``transition'' to ``call transition'' at least sometimes? -- I keep thinking it means ``step''}), and every time
the machine returns from a call we pop the top variation (to account
for stack confidentiality taking the prefix of the transition trace
until its return).

We start by defining the integrity and confidentiality tests, as well
as the variant stack, before giving the full definition of lockstep
stack safety.

\newcommand{\vse}{\mathit{vse}}
\newcommand{\VSES}{\mathit{VSE}}
\newcommand{\vs}{\mathit{vs}}
\newcommand{\VSS}{\mathit{VS}}

\newcommand*{\vm}[1]{\ensuremath{\mathit{vm}_{#1}}}
\newcommand*{\testInt}[3]{\ensuremath{\mathit{int}_T ~ #1 ~ #2 ~ #3}}
\newcommand*{\testConf}[2]{\ensuremath{\mathit{conf}_T ~ #1 ~ #2}}
\newcommand*{\testVS}[2]{\ensuremath{\mathit{\vs}_T ~ #1 ~ #2}}
\newcommand*{\testProp}[3]{\ensuremath{\mathit{stack}_T ~ #1 ~ #2 ~ #3}}

\definition
  Given two machine states $\mach$ and $\mach'$ and a contour $\contour$, these
  satisfy the \emph{stack integrity test} if their high-integrity components
  match:
  \[
    \testInt{\contour}{\mach}{\mach'} \triangleq
    \forall \component . ~
    \contour(\component) = \HIGHINT \rightarrow
    \mach(\component) = \mach'(\component)
  \]
\apt{We could have used this to define trace integrity in the first place...}

\definition Two machine states $\mach_1$ and $\mach_2$ satisfy the
\emph{stack confidentiality test} if the machines they stepped to
have their changed components coincide and the observations during
these steps are equal:
\[
\begin{array}{rl}
  \mathit{conf}_T ~ \mach_1 ~ \mach_2 ~ \triangleq &
  \exists \obs_1 ~ \obs_2 ~ \mach_1' ~ \mach_2'. ~
  \mach_1 \stepstoobs{\obs_1} \mach_1' \wedge \mach_2 \stepstoobs{\obs_2} \mach_2' \Rightarrow \\
&    \obs_1 = \obs_2 \wedge \forall \component . ~
   (     \mach_1(\component) \neq \mach_1'(\component)
    \vee \mach_2(\component) \neq \mach_2'(\component))
    \rightarrow \mach_1'(\component) = \mach_2'(\component)
\end{array}
  \]
\apt{And the last clause here could have been used for trace confidentiality...}

\definition The testing property keeps track of a variation machine
for every nested call performed so far on a {\em variant stack}: a
list of machine states annotated with a contour, each element of which
(denoted $\vm{C}$) is a variation of the actual machine
according to a contour $C$.
%
\footnote{The full formal definition in Coq also records additional
  information (the initial machine state at the call, its initial
  variation, the contour, and a return predicate) which we elide
  here for simplicity of exposition.}
%%
%  $$\vse \in \VSES ::= \MACHS \times \MACHS \times \MACHS \times \CONTOURS \times \RETMAPS$$
%  $$\vse = (\mathit{init\_machine}(\vse), \mathit{init\_variant}(\vse), \mathit{curr\_variant}(\vse), \contour(\vse), \mathit{ret}(\vse))$$
%  $$\vs \in \VSS$$
%%
%\iflater
%\leo{This can be elided}
%  Given a machine state $\mach$, a stack $\vs$ is \emph{well-formed} with
%  respect to it if the stack is nonempty, the return map of the bottom element
%  is the false property, and for each element $\vse \in \vs$:
%  \begin{itemize}
%  \item $\mathit{curr\_variant}(\vse)$ is a variant of $\mach$.
%  \item $\mach$ is in the trace $\machT$ of its initial machine,
%    $\mathit{init\_machine}(\vse) \hookrightarrow \machT$.
%  \item Its variant state $\mathit{curr\_variant}(\vse)$
%    is in the trace of its initial variant,
%    $\mathit{init\_variant}(\vse) \hookrightarrow \machT$.
%  \item The return function is in the return map if not the last element. \rb{TODO}
%  \item The registers of its contour $\contour(\vse)$ are public.
%  \end{itemize}
%  \fi

%% \definition
%% %  Let $\callmap$ a call map and $\codemap$ a function map.
%%   Given a state $(\mach, \pol) \in \MPS$ that is well-formed w.r.t. a
%%   variant stack $\vs$, we say that an MP-trace induced from $(\mach,
%%   \pol)$ satisfies the \emph{strong stack safety} at a given call
%%   depth as follows.
%% % Refactor repetitive notation before case split
%%   In all cases that let $(\mach, \pol) \hookrightarrow_P
%%   (\mach', \pol', \obs)$.
%%   %and assume (unless the step is a return) that the
%%   %variant stack can step, $\vs \hookrightarrow \vs'$, i.e., all its variant
%%   %machines can step.

%% %  Let $\callmap$ a call map and $\codemap$ a code map. Given a state $(\mach,
%% %  \pol) \in \MPS$ that is well-formed w.r.t. a variant stack $\vs$ and induces
%% %  an MP-trace $(\mach, \pol) \hookrightarrow \MPT$, we say that the \emph{stack
%% %  testing property} is satisfied at call depth $d$, and write
%% %  $\mathit{stack}_T ~ d ~ \MPT ~ \vs$, as follows:

%%   \begin{itemize}

%%   \item
%% %
%%     If the machine takes a \emph{call step} and $\contour$ is the contour at
%%     the call then,
%% %
%%     (1) the variant stack test $\testVS{(\mach, \pol)}{\vs}$ must be
%%     satisfied,
%% %
%%     (2) the stack integrity test $\testInt{\contour}{\mach}{\mach'}$ is
%%     satisfied and the stack confidentiality test $\testConf{\mach}{\vm{\contour}}$
%%     is satisfied with resepct to an arbitrary $\contour$-variant
%%     of $\mach$,
%% =======
We also need two auxiliary notations that relate to variant stacks.
%
First, lockstep stack safety will check that the basic tests above hold for every
machine in the variant stack.  Given a machine that steps $(\mach,
\pol) \stepstopol{\obs} (\mach', \pol')$, say that a variant
stack $\vs$ safisfies the \emph{variant stack test} if for each
variant element $\vm{C}$ (which is a variation of $\mach$ for $C$),
$\vm{C}$ can take a step, denoted $\vm{C} \stepstoobs{\obs} \mach'$,
while satisfying the stack integrity test $\testInt{C}{\mach}{\mach'}$
and stack confidentiality test $\testConf{\mach}{\mach'}$ with regard
to the original machine state. We will write $\testVS{(\mach,
  \pol)}{\vs}$ for this compound check. \apt{I'm having trouble here and below with
  the scoping of $C$. Each variant stack is for one particular $C$, right?
  So why not write $vs_C$ rather than $vm_C$ ?}
%% >>>>>>> 1886f7a7bf858ce0c9518e407d9481518a4f028d
%
Second, we will write $\vs \stepsto \vs'$ if every variant machine
in $\vs$ steps to the corresponding machine in $\vs'$.
%

We are now ready to define lockstep stack safety coinductively.

\definition Given a state $(\mach, \pol) \in \MPS$ and a variant stack
$\vs$ in which every element $\vm{\contour}$ is a variation of $\mach$
with respect to its \apt{whose?} contour, we say that an MP-trace induced from
$(\mach, \pol)$ satisfies the \emph{trace lockstep stack safety}, and write
$\testProp{}{\MPT}{\vs}$, if the following conditions are satisfied:

\begin{itemize}

\item
  If the machine takes a \emph{non-call, non-return step}
  \[(\mach, \pol) \hookrightarrow_P (\mach', \pol', \obs)\MPT,\]
  then the variant stack test must be satisfied:
  \[\testVS{(\mach, \pol)}{\vs},\]
  and trace lockstep stack safety must be coinductively satisfied for
  the remainder of the trace and the variant stack $vs'$ that
  steps to ($\vs \stepsto \vs'$):
  \[ \testProp{}{((\mach',\pol',\obs)\MPT)}{\vs'}\]

\item
  If the machine takes a \emph{call step} and $\contour$ is the contour at
  the call
  %% \rb{Corrected the step function here, or should it be
  %% $\hookrightarrow$ and give the rest of the induced trace?}
  \[(\mach, \pol) \stepstopol{\obs} (\mach', \pol') \wedge \callmap(\mach) = n,\]
%
  then the variant stack test $\testVS{(\mach, \pol)}{\vs}$ must be
  satisfied:
  \[\testVS{(\mach, \pol)}{\vs},\]
%
%    (2) the stack integrity test $\testInt{\contour}{\mach}{\mach'}$ is
%    satisfied and the stack confidentiality test $\testConf{\mach}{\vm{\contour}}$
%    is satisfied with regard to an arbitrary $\contour$-variant
%    of $\mach$,
%
  and trace lockstep stack safety must be coinductively satisfied
  for the remainder of the trace and for every variant stack
  that is the result of adding a variation of $\mach'$ with
  respect to $C$ at the top of the stack $\vs'$ that $\vs$ steps
  to:
  \[\testProp{}{((\mach', \pol', \obs)\MPT)}{(\vm{\contour} : \vs')}\]

\item
%
  If the machine $\mach$ takes a \emph{return step},
  \[(\mach, \pol) \stepstopol{\obs} (\mach', \pol') \wedge \retmap(\mach),\]
  %
  the top of the variant stack also returns,
  the tail of $\vs$ satisfies the stack safety test
  \[\testVS{(\mach, \pol)}{\mathit{tail}(\vs)},\]
  %
  and trace lockstep stack safety must be coinductively satisfied for
  the remainder of the trace and for the tail of the varant stack
  that $\vs$ steps to:
  \[\testProp{}{((\mach', \pol', \obs)\MPT)}{(\mathit{tail}(\vs'))}\]

\item If the machine \emph{fail-stops}, i.e., $(\mach, \pol) \hookrightarrow_P
    (\mach, \pol, \tau)$, the property is safisfied for the singleton trace:
    $\testProp{}{[(\mach, \pol)]}{\vs}$.

%  \item If the machine takes a \emph{simultaneous return-call step}, that is,
%    the instruction to which execution returns immediately after completing a
%    call is itself a call instruction, the \emph{call step} and \emph{return
%    step} cases are combined.

  \end{itemize}

\definition
%
A system satisfies {\em lockstep stack safety} if for every initial machine $(\mach,\pol)$,
the trace induced from $(\mach, \pol)$ satisfies trace lockstep stack safety with
respect to the empty stack.

\medskip
\textsc{Theorem.}
Lockstep stack safety implies stack safety.
\smallskip

The proof is a fairly involved coinductive argument
(around 3K LoC in Coq) on the definition trace lockstep stack safety,
using an auxiliary depth-index to ensure the proper aligmnent of
calls and returns.

\section{Stack Safety Properties for Lazy Enforcement}
\label{sec:lazy}

The conservative policy described in the previous section, while
testable and enforceable, is rather slow to be of practical use. What
we want, instead, is a somewhat more permissive policy that can also
be efficiently implemented. Most of the performance overhead incurred
stems from the need to set stack activation tags as a frame is created
and reset them as it is destructed, as
\citet{DBLP:conf/sp/RoesslerD18} confirm in their evaluation. To
mitigate those costs, they propose optimizations like Lazy Tagging and
Lazy Clearing that relax and defer some of the checks of an eager
policy, being more permissive in their allowed operations and catching
violations if and when their effect becomes manifest.
%
These \emph{lazy policies} admit more efficient implementations, but
they deliberately allow violations of stack integrity temporarily,
with the checks deferred until the point a violation truly becomes
harmful. The natural question then is, how do we characterize the
protections provided by these policies once stack safety is broken?
How does a harmful violation that must be caught later differ from a
harmless one? The properties in this section rely on our notion of
observations to draw this distinction.

\subsection{Observable Integrity}

\paragraph{Rolling Back to Idealized State}

Observable integrity weakens eager integrity by allowing a returned
state to differ from its call state at high integrity components,
provided that the differences do not change the observable behavior of
the rest of the program. It is not immediately clear what constitutes
changing behavior: we construct an idealized return state that
contains only the changes that the caller was allowed to make, and use
the trace from that state as a baseline against which the real trace
will be compared.

      \definition

      Given a contour, a call state, and a returned state, we define a
      {\em rollback} function \(\mathit{roll} : \CONTOURS \times \MACHS \times
      \MACHS \rightarrow \MACHS\). The rollback returns a state that matches
      the call state on those components that are high integrity in its
      contour, and matches the return state on low integrity components:
      \[\mathit{roll}(\contour,\mach_e,\mach_r)(\component) =
      \begin{cases}
        \mach_e(\component) & \text{if } \contour(\component) = (\HIGHINT,\_) \\
        \mach_r(\component) & \text{if } \contour(\component) = (\LOWINT,\_) \\
      \end{cases}\]

      If \(\mach_e\) is an entry to a call with contour \(\contour\)
      and \(\mach_r\) its return, the result of
      \(\mathit{roll}(\contour,\mach_e,\mach_r)\) agrees with the
      entry \(\mach_e\) on every component the callee should not
      change, and with the actual return \(\mach_r\) on those
      components that it is permitted to change.  So the observable
      behavior that follows is the idealized behavior to which we
      compare the trace from \(\mach_r\).

      Now we can define a version of trace integrity that compares the trace
      from a returned state to that from its idealized counterpart.

    \definition%{Observable Trace Integrity}

      A trace enjoys {\em observable trace integrity} with respect to
      some contour \(\contour\) if the trace induced by its final
      state (if any) has observable behavior that prefixes that of its
      idealized version (to account for premature halts due to policy
      violations):

      \[\begin{split}
        \propdef{ObsTraceInt} ~ \contour ~ \MPT \ \ \triangleq \ \
        & \mpostate{\mach_e}{\pol_e}{\obs_e} = \head(\MPT) \Rightarrow \\
        & \mpostate{\mach_r}{\pol_r}{\obs_r} = \last(\MPT) \Rightarrow \\
        & \mpstate{\mach_r}{\pol_r} \hookrightarrow \MPT' \Rightarrow \\
        & \mathit{roll}(\contour,\mach_e,\mach_r) \hookrightarrow \machT'
          \Rightarrow \\
        & \pi_o(\MPT') \lesssim_O \pi_o(\machT')
      \end{split}\]

    \begin{figure}
      \integritylazyexample
      \caption{Rolling back from Figure \ref{fig:intex}\bcp{too much space!}}
      \label{fig:intlex}
    \end{figure}

    For our example, we return to the violation of trace integrity in
    \cref{fig:intex}, in which {\tt h} has written to {\tt z} and returned.
    Whether observable integrity holds depends on the continuing trace, shown
    in \cref{fig:intlex}. Above, we have the final state of \(\MPT\),
    \(\mach_r\), and the rolled-back state, \(\mach_r' =
    \mathit{roll}(\contour,\mach_e,\mach_r)\), in which high integrity
    components are restored to their values as of \(\mach_e\). Specifically,
    address 103 is restored to 0. When instruction 31 prints {\tt z} in the
    trace from \(\mach_r\), it prints 18, but in the trace from \(\mach_r'\)
    it prints 0. Only then is observable trace integrity violated.

    However, consider instead if we insert after instruction 44 a new
    instruction \(45: [\rsp-4] \leftarrow 50\), overwriting {\tt w} in
    {\tt g}'s frame. So \(\mach_r'\) maps address 105 to 50, while the
    rolled-back state \(\mach_r'\) maps it to 0. But in the trace from either
    state, instructions 27 and 28 load the return value (18) and store it to
    105, eliminating the only difference. The remainder of the observation
    traces must be identical, so this trace does obey observable trace
    integrity.

    \definition%{Observable Stack Integrity}

      A system enjoys {\em observable stack integrity}, like stack integrity,
      if, for any initial state and each \(n\)-transition from
      \(\mpstate{\mach_c}{\pol_c}\) to \(\mpstate{\mach_e}{\pol_e}\) in its
      induced trace, we take the prefix of the call
      \(\mpstate{\mach_e}{\pol_e} \hookrightarrow \MPT_{\mathit{call}} | \ret{\mach_c}\)
      and observable trace integrity holds on \(\MPT_{\mathit{call}}\) with
      contour \(\mathit{Cof}(\mach_c,n)\).

  \subsection{Observable Confidentiality}

      Two of the cases of trace confidentiality, \(\mathit{InfCase}\)
      and \(\mathit{FailCase}\), are purely properties of the
      observations produced by the traces they are properties of. If
      the traces are infinite, they should be similar; if one
      fail-stops, it should be a prefix. Only the
      \(\mathit{ReturnCase}\) checks machine states, because in that
      case the traces could continue, but have been cut off by a
      return. The key to making confidentiality lazy is not to perform that
      check but rather to consider the traces after that return,
      checking only whether they are observationally similar.

      This requires restoring varied components to their original
      values in the trace from the variant state, since after return
      they will once again be legitimately accessible. To return to
      the example in \cref{fig:confex}, the varied final state
      \(\mach_r'\) still has $-5$ as a return address for {\tt g}, so
      the trace after that return will behave oddly in a way that
      does not reflect a confidentiality violation.  That means we
      cannot immediately compare traces from \(\mach_r\) and
      \(\mach_r'\), but rather that we must restore the varied values
      while preserving differences that have occurred during
      execution.

      \definition

      The \(\mathit{restore}\) function takes four states: the
      original entry state, a variant entry state, and corresponding return
      states. It returns another state. The resulting state restores those
      components that varied between entries to match the original entry,
      unless they were changed during execution:
      \[\mathit{restore}(\mach_e,\mach_e',\mach_r,\mach_r')
        (\component) =
        \begin{cases}
          \mach_e(\component) & \text{if } \mach_e(\component) \not =
                                \mach_e'(\component) \text { and } \\
          & \mach_e(\component) = \mach_r(\component) \text{ and }
            \mach_e'(\component) = \mach_r'(\component) \\
          \mach_r'(\component) & \text{else} \\
        \end{cases}\]

      Now we can describe a trace property akin to trace confidentiality, but
      continuing execution after the end of the callee trace.

    \definition{%Observable Trace Confidentiality}

      {\em Observable trace confidentiality} is the lazy analog to
      trace confidentiality, and reuses the cases in which the traces
      do not return.  For a return predicate \(R\) and a pair of
      traces \(\MPT\) and \(\machT\), we consider the return case, in
      which $\MPT$ has a last element
      \(\mpostate{\mach_r}{\pol_r}{\obs_r}\) and that machine state is
      a return: \(R ~ \mach_r\).
%
      Observable trace confidentiality then requires that $\machT$
      also has a final state \((\mach_r',\obs_r')\) that is a return:
      \(R ~ \mach_r'\).
%
      In addition, just like in the eager case,
      observations of \(\MPT\) are similar to those of \(\machT\).

      The only thing that changes is the requirement that \(\mach_r\)
      and \(\mach_r'\) agree on components. Instead, let \(\mach_e\)
      be the machine state of \(\head(\MPT)\), and \(\mach_e'\) be
      that of \(\head(\machT)\). We restore \(\mach_r'\) based on
      \(\mach_e\) and \(\mach_e'\) to get \(\mach_r'' =
      \mathit{restore}(\mach_e,\mach_e',\mach_r,\mach_r')\).  Then
      observable trace confidentiality requires that the
      induced trace from \(\mpstate{\mach_r}{\pol_r}\) should be an
      observational prefix of the induced trace from \(\mach_r'\),
      reflecting the possibility of a fail-stop after return.

      \[\begin{split}
        \mathit{ObsReturnCase} ~ R ~
        (\mpostate{\mach_e}{\pol_e}{\obs_e}\MPT) ~
        ((\mach_e',\obs_e')\machT) \ \ \triangleq \ \
        & \last(\MPT) = \mpostate{\mach_r}{\pol_r}{\obs_r} \Rightarrow \\
        & \last(\machT) = (\mach_r',\obs_r') \Rightarrow \\
        & \mach_r'' = \mathit{restore}(\contour,\mach_e,\mach_e',\mach_r,\mach_r') \Rightarrow\\
        & \mpstate{\mach_r}{\pol_r} \hookrightarrow \MPT' \Rightarrow \\
        & \mach_r'' \hookrightarrow \machT' \Rightarrow \\
        & \pi_o(\MPT) \eqsim \pi_o(\machT) \land \\
        & \pi_o(\MPT') \lesssim \pi_o(\machT') \\
      \end{split}\]

      We combine this case with the other two cases from ordinary trace
      confidentiality:

      \[\begin{split}
        \propdef{ObsTraceConf} ~  R ~ \MPT ~ \machT \ \ \triangleq \ \
        & \mathit{ObsReturnCase} ~ R ~ \MPT ~ \machT \land \\
        & \mathit{InfCase} ~ R ~ \MPT ~ \machT \land \mathit{FailCase} ~ R ~
          \MPT ~ \machT \\
      \end{split}\]

      \begin{figure}
        \confidentialitylazyexample
        \caption{Continuing from \cref{fig:confex}\bcp{Spacing!}}
        \label{fig:conflex}
      \end{figure}

      In our example, \cref{fig:conflex} shows how execution continues from
      \(\mach_r'\) and the restored
      \[\mach_r'' = \mathit{restore}(\contour,
      \mach_e,\mach_e',\mach_r,\mach_r').
      \]
      Addresses 108 and 109
      are not restored; every address that was varied and not changed in one
      of the executions is. So 108 contains 43 in the trace from \(\mach_r\),
      and after returning from {\tt g}, {\tt main} prints 85. But in the trace
      from \(\mach_r''\), 108 contains $-4$, and ultimately 38 is printed.
      So observable trace confidentiality does not hold. This example
      illustrates the weakness of observable confidentiality as a testing
      property: it takes until the very end of the program to determine whether
      a tainted value actually influences observable behavior.

      On the other hand, suppose that we inserted an instruction at 43:
      \(r_6 \leftarrow [\rsp-8]\). \(r_6\) would hold 42 in \(\mach_r\)
      and $-5$ in both \(\mach_r'\) and \(\mach_r''\). But since \(r_6\) is
      never used otherwise, the traces of {\tt h} will enjoy observable trace
      confidentiality.

    \definition%{Observable Stack Confidentiality}

      {\em Observable stack confidentiality} is structured like stack
      confidentiality. Let \(\callmap\) be a callmap; for each initial
      state \((\mach_0, \pol_0)\) and \(n\)-transition from \(\mpstate{\mach_c}{\pol_c}\)
      to \(\mpstate{\mach_e}{\pol_e}\) in the induced trace
      \(\mpstate{\mach_0}{\pol_0} \hookrightarrow \MPT\), take any
      variation \(\mach_e' \approx_{\mathit{Cof}(\mach_c,n)} \mach_e\). Let
      \(\mpstate{\mach_e}{\pol_e} \hookrightarrow \MPT_{\mathit{call}} |
      \ret{\mach_c}\) and \(\mach_e' \hookrightarrow \machT_{\mathit{call}} |
      \ret{\mach_c}\). We must have \(\propdef{ObsTraceConf} ~
      \ret{\mach_c} ~ \MPT ~ \machT\).

      Additional, for any variation \(\mach_0' \approx_{\mathit{Cof}(\mach_0),0}
      \mach_0\), taking the induced trace  \(\mach_0' \hookrightarrow
      \machT\), we must have \(\propdef{TraceConf} ~ \emptyset ~ \MPT ~ \machT\).

      A system enjoys observable stack confidentiality if observable
      confidentiality holds in all such cases.

    \definition%{Observable Stack Safety}
    A system enjoys {\em observable stack safety}
    % with respect to a call map       and a function map
    if it enjoys both observable stack integrity and
      observable stack confidentiality with respect to them.

      \medskip
      \textsc{Theorem.}
      Stack safety implies observable stack safety.
      \smallskip

      This is more straightforward than the implication in the previous
      section (1,5K LoC in Coq) as the recursive
      structure of the two properties is similar.

    \paragraph{Connection to Policies}

    Observable properties allow us defer enforcement until a property
    violation would become visible, as in lazy policies. But by formalizing
    the connection to the eager policy, we can identify when lazy policies
    miss violations that can become visible. The basic lazy tag policy from
    \citet{DBLP:conf/sp/RoesslerD18} tags written memory with the depth in the
    stack at which it was written, and enforces that it must be read from the
    same depth. However, this allows violations of observable stack safety!
    Say we have functions {\tt foo}, {\tt bar} and {\tt baz}, where {\tt foo}
    calls {\tt bar}, and then after {\tt bar} returns {\tt foo} calls
    {\tt baz}. Since {\tt bar} and {\tt baz} are at the same stack depth, if
    {\tt bar} writes to {\tt foo}'s frame, {\tt baz} can then read the tainted
    write and use it to create an observable difference that violates both
    observable integrity and confidentiality without violating the policy.

    The lazy policy can be repaired if, instead of tagging each function
    activation with its depth in the stack, we generate a fresh activation
    identifier on each call, which prevents a program from exploiting stale
    tags from previous activations. A related mechanism was explored in the
    Static Authorities policy of \citet{DBLP:conf/sp/RoesslerD18}, which
    associates a unique activation identifier to each function, which is
    however shared by all activations of the same function in order to obtain
    good cacheability of tag rules. Static Authorities comes closer to
    observable stack safety, though the example above would still exist
    if {\tt bar} and {\tt baz} were merged into a single function that tracked
    whether it had been called previously and changed its behavior accordingly.


\section{Related Work}
\label{sec:relwork}

%% CHERI \rb{cite}

\paragraph{Formal Stack Safety on Capability Machines}
%
To our knowledge, the first and only line of work that has attempted
to furnish a positive and formal characterization of the meaning of
stack safety is \citet{Skorstengaard+19b}, who introduce a calling
convention that uses local capabilities to preserve local state
encapsulation and well-bracketed control flow, using a logical
relation to reason about the stack safety of concrete
programs. Although the required hardware support is readily available
in capability machines like CHERI, this technique incurs significant
costs, because it requires the entire unused part of the stack to be
cleared whenever a security boundary is crossed. Their logical
relation captures capability safety without ``externally observable
side-effects (like console output or memory access traces).'' In the
discussion, ``while [the authors] claim that [their] calling
convention enforces control-flow correctness, [they] do not prove a
general theorem that shows this, because it is not clear what such a
theorem should look like,'' noting that the correctness property
enjoyed by their technique ``is not made very explicit.''

StkTokens \citep{Skorstengaard+19} is a natural continuation of that work. Like
its predecessor, it aims to protect the stack by enforcing local state
encapsulation and well-bracketed control flow. It does so by defining a new
calling convention that makes use of linear capabilities for stack and return
pointers. The convention operates on a single shared stack and requires that
protected components avoid compromising their own security by following certain
simple rules---like avoiding to leak their private capability seals. More
precisely but still informally, local state encapsulation is defined as
restricting accesses to the range of memory allocated to the current stack
frame, and well-bracketed control flow as only allowing returns from the topmost
frame to the immediately adjacent frame below. Formally, it improves on
\citet{Skorstengaard+19b} by building those properties into the semantics of a
capability machine with a built-in call stack and call and return instructions,
which is proven fully abstract with respect to a more concrete capability
machine that replaces those pseudo-instructions with their calling convention.
Their proof of full abstraction uses a standard notion of components, which
import and export functions through their interfaces; their model of
observations is limited to cotermination.

We believe that the linear capability machines introduced by
\citep{Skorstengaard+19}, in combination with the StkTokens calling convention,
can be modeled in our framework and satisfy our definition of stack safety in
\cref{sec:lse-and-wbcf}. Further, we expect them to satisfy the even stronger
property developed in \cref{sec:enforcement}. Proving these conjectures would
involve materializing their definitions of local state encapsulation and
well-bracketed control flow, which exist only in enmeshed form as part of the
semantics of the capability machines. The main practical limitation of StkTokens
is its reliance on linear capabilities, as it is unclear now they could be added
to practical capability machines, especially in terms of efficiency---previous
work on micropolicies \citep{yannis-report} has shown how to use that framework
to implement linear return capabilities.

\paragraph{Protecting the Stack with Micropolicies}
%
\citet{DBLP:conf/sp/RoesslerD18} consider a standard attacker model where all
attacks against stack data are in scope (but not side channels or hardware
attacks), and study the protection of stack data through three families of
micropolicies that tag stack objects with a pair of frame and object identifiers
used to validate accesses to the stack: Return Address Protection (which
prevents an adversary from overwriting designated return addresses), Static
Authorities (which only allows the code of a function to access the stack frames
of its own dynamic instances), and Depth Isolation (described in
\cref{sec:enforcement}). All these policies exploit various kinds of spatial and
temporal locality of stack memory and local call graphs, as well as information
generated by the compilation toolchain, to strike various balances between
precision and cacheability, evaluated through benchmarks that demonstrate
limited performance overhead. In addition to the baseline ``eager'' policies,
they propose a number of lazy optimizations, notably Lazy Tagging and Lazy
Clearing, discussed in \cref{sec:lazy}, with associated improvements in
performance.

\paragraph{Heap Safety as a Security Property}

Heap safety, like stack safety, may be framed as a security property
in the form of noninterference~\citet{DBLP:conf/post/AmorimHP18}. Just
like~\citeauthor{DBLP:conf/post/AmorimHP18} give a rigorous
characterization of the meaning of (heap) memory safety, in this paper
we aim to do the same for the stack.
%
Their model describing safety of shared stack-allocated
objects extends naturally to heap safety, complicated by the fact that
these objects are not deallocated by returns, and therefore a
function's privilege may increase or decrease after its entry
point. For instance, if a callee allocates a heap object and returns
the pointer to its caller, that object's addresses become accessible
in contradiction to a contour computed at the caller's entry. So such
an extension must enforce trace confidentiality and integrity
properties separately on continuous segments of each call, with
contours computed at each crossing between caller and callee.

\section{Future Work}
  \label{sec:future}

  We have presented a pure notion of stack safety that omits many complicating
  factors common to real systems. In particular, our model as presented exploits
  the simplifying assumption that privilege never increases during a function
  call, and that therefore a contour computed once on the entry to a function
  describes its privilege throughout. Our future plans are to extend the model
  with common language features, some of which violate this assumption. Here we
  describe the basic principles by which our model can be extended to some of
  these cases. We also plan to develop a testing framework for quickly
  checking the validity of different enforcement mechanisms.

  \paragraph{Stack-derived Pointers}

    Common programming idioms involve a caller passing a pointer to
    its local data into a callee. Using standard notions of pointer
    provenance~\citep{provenance}, we can extend our model to
    distinguish safe use of this idiom from true stack safety
    violations. We require additional annotation to identify which
    addresses within a function's stack frame correspond to distinct
    objects. Then a valid pointer to an object is one derived through
    legal arithmetic from its base address, and at each call point, an
    object's addresses are marked low confidentiality and integrity if
    a valid pointer exists in a register or in the transitive closure
    of the callee's accessible memory. All pointers to an object cease
    to be valid when it is deallocated along with its stack frame.

  \paragraph{Non-stack control flow}

    Control structures beyond well-bracketed calls and returns require
    modifications to the model. Tail calls, for instance, reuse the caller's
    stack frame for its callee, and every nested tail call returns
    simultaneously to the top non-tail-calling function. Under normal stack
    integrity, the first function in a chain of tail calls returns and violates
    integrity, while subsequent tail calls never actually return at all.
    Instead we need a variant that treats the entry of a tail call as the
    return of its caller for purposes.

    More complex is the addition of a coroutine model, in which multiple stacks
    respect stack safety internally, but might also yield to one another.
    Here we must distinguish three levels of integrity: accessible, in the same
    stack, and in another stack. Stack integrity requires that same-stack data
    be unchanged when a function returns, but other-stack data may change. A
    similar {\em yield integrity} property requires that, from a yield out of
    a coroutine to the next yield back into it, all accessible and same-stack
    data are unchanged. Confidentiality properties are split similarly.

  \paragraph{Random Testing}

  Part of the motivation for the strong lockstep stack safety property
  is that it uncovers errors quickly, and therefore should be quicker
  to test just like the smarter testing properties
  of~\citet{TestingNI:ICFP}. We have already developed a testing
  framework for debugging our policy enforcement for this property, and
  it would be interesting to explore whether a testing-amenable variant
  of the lazy property also exists.

% \rb{Notes from meeting:
%   \begin{itemize}
%   \item Explain how the theory applies to production compilers like GCC and
%     LLVM, which aspects are directly applicable, what are the effects of
%     alternative calling conventions. Other less charted waters: tail calls,
%     coroutines, jumps into supervisor mode.
%   \item CHERI and its operation, documentation and practical configurations and
%     operation.
%   \item Compare and contrast with StkTokens.
%   \item Under what circumstances can stack safety exist without an enforcement
%     mechanism?
%   \item Zeroing out of allocated space inside blessed sequences, eager vs lazy.
%     Possibility of blessed alloc and dealloc sequences, which also manipulate SP
%     and would not be legal without blessing. In such an extended setting, the
%     return sequence would check for matching addresses (it would be nice to have
%     testing for this!).
%   \end{itemize}
% }

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bcp.bib,local.bib}


%% Appendix
%\appendix
%\section{Appendix}
%Text of appendix \ldots

\end{document}
