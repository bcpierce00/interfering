%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}

%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{POPL} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2021}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\input{macros}
\input{examples}

\begin{document}

%% Title information
\title{Stack Safety as a Security Property}         %% [Short Title] is optional;
                                        %% when present, will be used in
                                        %% header instead of Full Title.
%\titlenote{with title note}             %% \titlenote is optional;
%                                        %% can be repeated if necessary;
%                                        %% contents suppressed with 'anonymous'
%\subtitle{Subtitle}                     %% \subtitle is optional
%\subtitlenote{with subtitle note}       %% \subtitlenote is optional;
%                                        %% can be repeated if necessary;
%                                        %% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
%\author{First1 Last1}
%\authornote{with author1 note}          %% \authornote is optional;
%                                        %% can be repeated if necessary
%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
%\affiliation{
%  \position{Position1}
%  \department{Department1}              %% \department is recommended
%  \institution{Institution1}            %% \institution is required
%  \streetaddress{Street1 Address1}
%  \city{City1}
%  \state{State1}
%  \postcode{Post-Code1}
%  \country{Country1}                    %% \country is recommended
%}
%\email{first1.last1@inst1.edu}          %% \email is recommended
%
%%% Author with two affiliations and emails.
%\author{First2 Last2}
%\authornote{with author2 note}          %% \authornote is optional;
%                                        %% can be repeated if necessary
%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
%\affiliation{
%  \position{Position2a}
%  \department{Department2a}             %% \department is recommended
%  \institution{Institution2a}           %% \institution is required
%  \streetaddress{Street2a Address2a}
%  \city{City2a}
%  \state{State2a}
%  \postcode{Post-Code2a}
%  \country{Country2a}                   %% \country is recommended
%}
%\email{first2.last2@inst2a.com}         %% \email is recommended
%\affiliation{
%  \position{Position2b}
%  \department{Department2b}             %% \department is recommended
%  \institution{Institution2b}           %% \institution is required
%  \streetaddress{Street3b Address2b}
%  \city{City2b}
%  \state{State2b}
%  \postcode{Post-Code2b}
%  \country{Country2b}                   %% \country is recommended
%}
%\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
Text of abstract \ldots.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

%\ccsdesc[500]{Software and its engineering~General programming languages}
%\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{Stack Safety, Micropolicy, Random Testing, RISC-V}  %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle

\section{Introduction}

\newcommand*{\MemoryLabel}[3]{\raisebox{#2}{\makebox(0,0){\hspace{#1}#3}}}

%\begin{figure}
%  \begin{minipage}{\textwidth}
%    \begin{center}
%\MemoryLabel{10em}{1.5em}{40}
%\MemoryLabel{16em}{1.5em}{60}
%\MemoryLabel{22em}{1.5em}{80}
%$\cdots$
%\memory{4}{gray}%
%\memory{5}{green}[{\makebox[0pt]{Caller}}]%
%\memory{5}{yellow}[{\makebox[0pt]{Args}}]%
%\memory{8}{red}[{\makebox[0pt]{Callee}}]%
%\memory{4}{\unusedc}%
%~$\cdots$\\
%  \end{center}
%  \end{minipage}\\
%~\\
%~\\
%  \begin{minipage}{0.45\textwidth}
%    \begin{center}
%\begin{verbatim}
%jal ...
%lw r1 r0 40
%\end{verbatim}
%    \end{center}
%  \end{minipage}~
%  \begin{minipage}{0.45\textwidth}
%    \begin{center}
%\begin{verbatim}
%jal ...
%sw r0 r0 40
%\end{verbatim}
%    \end{center}
%  \end{minipage}
%  \caption{Examples of Unsafe Programs\bcp{The numbers don't line up with
%      the boxes; the program fragments need comments explaining what each
%      line does.}}
%  \label{fig:stackunsafety}
%\end{figure}
%
%\leo{I hate the writing here, but I wanted to make a start.}

The call stack is a perennial target for attacks
based on memory safety vulnerabilities, with potential consequences
ranging from leakage or corruption of private stack data to
control-flow hijacking. To detect or prevent such attacks, a menagerie of
software and hardware techniques for stack safety have been proposed,
%
including stack canaries~\citep{Cowan+98},
bounds checking~\citep{NagarakatteZMZ09,NagarakatteZMZ10,DeviettiBMZ08},
split stacks~\citep{Kuznetsov+14},
shadow stacks~\citep{Dang+15,Shanbhogue+19},
capabilities~\citep{Woodruff+14,Chisnall+15,Skorstengaard+19,Skorstengaard+19b},
and hardware tagging~\citep{DBLP:conf/sp/RoesslerD18}. \apt{Mostly from
  nick;there could be more}\bcp{How about static techniques??  We decided
  these were also in-scope.}\bcp{... or are they?  I guess in any case we should
list any that we know about.}

But what {\em is} this ``stack safety'' of which we speak? Precise formal
definitions are lacking in the literature; instead, the notion
is usually defined negatively, by enumerating the bad things that a given
enforcement mechanism
prevents, such as corruption of return addresses, buffer overflows, or
use of uninitialized variables.
%with the notion usually being
%defined negatively: through examples of stack-based exploits
%\rb{usually though not always; as noted below there are other
%  approaches}\bcp{Yes, we have to be very careful about this}.
%\leo{Examples at a high level}: such as -- does not overwrite return addresses, or ...
Indeed, we are only aware of one---quite recent---attempt to frame a
positive definition:
\citet{Skorstengaard+19} define stack safety as
the conjunction of two properties, {\em local state encapsulation} and {\em
  well-bracketed control flow}.
They formalize these properties by defining an abstract capability-based machine
that ``satisfies [stack safety] by construction.''
%
Although this represents an important step in the right direction, we believe
there is still room to craft a more abstract, more generic characterization
of stack safety that is independent of capabilities or any other specific
enforcement
technique.  In other words, we seek formal criteria that can be applied
against \emph{any} stack-based system + enforcement mechanism to judge
whether or not the combination is actually stack-safe.

\iflater
\leo{Should this be its own paragraph?}
\fi
The key contribution of this paper is a novel, generic presentation of
local state encapsulation and well-bracketed control flow using the
technical framework of language-based security. 

The intuition behind \citeauthor{Skorstengaard+19}'s use of the term {\em
  local state encapsulation} is that callers should be protected from
callees: a callee should be not be able to access or overwrite private data
in the caller's stack frame. We formalize this intuition as a security
property with both confidentiality and integrity components.
%
We reflect this intuition in a formal
{\em stack confidentiality} property, which promises that a callee's
observable behavior is not affected by memory outside its stack frame
(e.g., a caller's private data or uninitialized memory).  Conversely, {\em stack
  integrity} promises that, if a function call ever returns, the caller's
stack data at the point of return will be identical to what it was before
the call.

\iflater
\bcp{We need to point out somewhere that we are only dealing with
stack safety, though we discuss (somewhere) how our property can be combined
with the heap safety property of [Azevedo et al]}\leo{Should this be
  here or in the assumptions as presented in the running
  example?}\bcp{Probably better there.}
\fi

The intuition behind \citeauthor{Skorstengaard+19}'s {\em well-bracketed control
  flow} is
the desire to protect the call graph itself: a callee should pass control
back to the caller only by returning in the standard way (transferring
control to the instruction following the call); it should
not be
allowed to jump back into the caller's code at an arbitrary point, either
directly (via a jump instruction) or indirectly (by corrupting stack
data and returning). Well-bracketed control flow establishes safety
between functions: each instruction is uniquely owned by some
function, and all jumps between functions are either calls that enter
at a marked entry point or returns that re-enter just after their
associated call in the standard nested call structure.  \apt{clarify
  what we are contributing here.}

To phrase these two aspects of stack safety in terms of security
properties \leo{in terms of security properties or ``using security
  language''?}  requires an explicit attacker model: an clear
understanding of who is being protected and from what. Most existing
stack protection mechanisms deal with scenarios where a callee gets
influenced by external inputs and ends up executing potentially
malicious code. To avoid the details of exactly how this happens and
keep the presentation clear, we pick an even stronger model: when
stating the protections that a function can rely on when it makes a
call, we assume that the callee can execute arbitrary instructions
until it returns.

Adopting that model in our setting, however, poses another novel
challege: not only does a caller need to be protected from its callee,
but the callee itself needs to be protected from {\em its}
callees. That is, the notion of ``attacker'' changes throughout the
execution of a program!  We address this problem by using a similarly
changing notion of accessibility for the different components of the
machine: we adjust the integrity and confidentiality level of
different stack locations and registers at every transition (call or
return) between functions.  \bcp{that's way too terse!}\leo{Slightly
  better, still needs a bit probably}
%\apt{connection to ``attacker'' still vague.}  \rb{Mention
%  to varying ``accessing power'' of the attacker?  The notion of
%  attacker changes on certain actions that are not externally
%  visible.} \bcp{Maybe the best way is to grab the bull by the horns:
%  ``If we're going to phrase stack safety as a security property, we
%  need to talk about an attacker model, and this is where the
%  technicalities get really interesting...''}

\bcp{This little paragraph is our entire explanation of the second and third
contributions!  Needs to be expanded considerably...}%
To provide evidence that our definitions capture the inituitive notion
of stack safety, we show that they rule out a range of exploitable bad
behaviors.\apt{``from the literature''??}  To assess whether they are
implementable, we compare them against
%proposed capability-based
%enforcement mechanism of \citet{Skorstengaard+19} \apt{we really
%  should} and
the existing tag-based enforcement mechanism of
\citet{DBLP:conf/sp/RoesslerD18}.
%\leo{Is this where we would rephrase this because we would only talk about it in related work?}

In summary, we offer the following contributions:\bcp{I would still like to
  see these points phrased in ``contribution normal form'': say exactly what
  we did for each one (it's a bit vague---''considers,'' etc.), and
  explicitly say why it is (a) useful, (b) challenging, and (c) novel.}
\begin{itemize}
\item
  % \leo{More? Extensional}\bcp{We might need to invent a word for   this---''quasi-extensional''?}
  Abstract formal properties capturing the
  intuitive concepts of strict local state encapsulation and well-bracketed
  control flow~(\cref{sec:lse-and-wbcf}) in a generic setting. These properties
  rule out common examples of stack memory abuse.
\item
  A case study of the Depth Isolation policy of \citet{DBLP:conf/sp/RoesslerD18}, based on hardware tags~(\cref{sec:enforcement}).
  This policy enforces our strict stack safety property, and also a (provably) stronger property that is easier to test.
  \apt{If we have no testing, do we even want to talk about the testing
    property?} \bcp{Not here; just in future work.  I guess we need to see
    whether we wind up with any results at all about testing.}
\item
  A refinement of the case study that considers the more efficient Lazy Tagging and Clearing policy
  of \citet{DBLP:conf/sp/RoesslerD18}~(\cref{sec:lazy}).  This policy does not enforce our strict
  local state encapsulation property,
  but a modified version of it using unique per-activation tags enforces
  a (provably) weaker lazy variant of the property.
%
% \apt{Awkward, but the truth I fear.} \bcp{I agree the phrasing is awkward,
%   but the point we can make is still strong: To make the property easier
%   to enforce, we can slightly weaken its guarantees; the weaker version is
%   a bit more complicated to state but still retains the pragmatic
%%   protections of the original.}\apt{To clarify: Nick's LT\&C policy uses
%   depth-based tags, which do not enforce even our lazy policy. So we need to
%   introduce a version of LT\&C that uses unique activation tags.}

  %\item As evidence that the property is not too strong\apt{But we add the lazy version because the strict version \emph{is} too strong, in some sense.}, we show that it is
%  realizible by
%  a previously proposed micropolicy enforcement
%  mechanism~(\Cref{sec:micropolicy}). \leo{And it says yes on a
%    substantial body of code}. We also present a variation of the
%  property + policy that is lazy, easier/more efficient to implement,
%  and provably weaker (\Cref{sec:lazy}).
%\item A provably stronger (inductive? step-by-step/stepwise) variant
%  of this property tuned for testing/verification.  We test the whole
%  thing with a cool framework. \bcp{Which section?}
\end{itemize}
\Cref{sec:relwork} discusses related work;
\cref{sec:future} sketches directions for future work.
%
We begin with a running example that we refer to throughout the paper
(\cref{sec:running-example}), a description of our threat model
(\cref{sec:threat}) and some technical preliminaries
(\cref{sec:prelim}).

\section{Running Example}
\label{sec:running-example}

\leo{We've said this literally in the previous sentence. What should this intro
  be in the new reorg?}
%We begin with a running example that will serve both to demonstrate several
%``stack-unsafe'' behaviors that our stack safety property should prohibit
%and to ground the technical presentation in later sections.

The example program appears in \Cref{fig:running-program}. It consists
of a {\tt main} function, written in some C-like high-level language,
that performs a call to some function {\tt f}, which in turns makes a
nested call to some function {\tt g} before returning, while
performing some simple arithmetic operations in the process.

\begin{figure}[b]
\hfill
    \begin{minipage}{.3\textwidth}
\begin{verbatim}
main = {
  int x = 42, y = 0;
  y = g(0);
  print (x + y);
}
\end{verbatim}
    \end{minipage}
    \begin{minipage}{.3\textwidth}
\begin{verbatim}
g(z) = {
  int w = h(17);
  print z;
  return (z + w);
}
\end{verbatim}
    \end{minipage}
    \begin{minipage}{.3\textwidth}
\begin{verbatim}
h(v) = {
  return (v + 1);
}


\end{verbatim}
    \end{minipage}
\caption{A High-level Program With Nested Calls}
\label{fig:running-program}
\end{figure}


\newcommand*{\add}{\textsc{add}}
\newcommand*{\addi}{\textsc{addi}}
\newcommand*{\sw}{\textsc{sw}}
\newcommand*{\lw}{\textsc{lw}}
\newcommand*{\jal}{\textsc{jal}}
\newcommand*{\jalr}{\textsc{jalr}}
\newcommand*{\rsp}{\textsc{sp}}
\newcommand*{\rra}{\textsc{ra}}
\newcommand*{\rout}{\textsc{out}}

\newcommand*{\tagInstr}{\textsc{instr}}
\newcommand*{\tagCall}{\textsc{call}}
\newcommand*{\tagHa}{\textsc{h1}}
\newcommand*{\tagHb}{\textsc{h2}}
\newcommand*{\tagRa}{\textsc{r1}}
\newcommand*{\tagRb}{\textsc{r2}}
\newcommand*{\tagRc}{\textsc{r3}}
\newcommand*{\tagNoDepth}{\textsc{unused}}
\newcommand*{\tagStackDepth}[1]{\textsc{stack} ~ #1}
\newcommand*{\tagPCDepth}[1]{\textsc{pc} ~ #1}
\newcommand*{\tagSP}{\textsc{sp}}

\newcounter{pcctr}
\setcounter{pcctr}{0}
%  \thepcctr & \stepcounter{pcctr} #1 & #2 & #3 & \text{#4}\\
\newcommand*{\row}[4]{
  \thepcctr & \stepcounter{pcctr} #2 & #3 & \text{#4}\\
}
\newcommand*{\tracerow}[5]{
  #1 & #2 & #3 & #4 & \text{#5}\\
}
\newcommand*{\summary}[6]{
\[
\begin{array}{cccccc}
  \PCname = #1 & r_0 = #2 & \rra = #3 & \rsp = #4 & r_4 = #5 & r_5 = #6
\end{array}
\]
}
\newcommand{\negate}{\textrm{-}}

\colorlet{lgray}{gray!40}

\newcommand{\instrc}{lgray}
\newcommand{\fprivc}{cyan}
\newcommand{\fcallc}{green}
\newcommand{\gprivc}{yellow}
\newcommand{\gcallc}{orange}
\newcommand{\hprivc}{red}
\newcommand{\unusedc}{gray}
\newcommand{\emptyoutc}{white} % or gray for consistency with unusedc ?
\newcommand{\fulloutc}{white}

\begin{figure}

%Starting Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{25em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{Output}}]%
\memory{10}{\unusedc}[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\\
\end{center}
% Starting Register File
\summary{0}{0}{?}{100}{?}{?}
\vspace*{0.2em}
\bcp{A very small nit: Change
  $\rsp-2$ to $\rsp\mathord{-}2$}\apt{??}
\[
  \begin{array}{c|c|c|c}
    PC & \mathit{Instruction} & \mathit{Effect} & \\
    \hline
    \row{\addi ~ \rsp ~ \rsp ~ 2}{\rsp \leftarrow \rsp + 2}{\rsp \leftarrow 102}
        {Allocate private {\tt main} data}
    \row{\addi ~ r_4 ~ r_0 ~ 42}{r_4 \leftarrow r_0 + 42}{r_4 \leftarrow 42}
        {Put 42 in $r_4$}
    \row{\sw ~ \rsp ~ r_4 ~ \negate 2}{[\rsp-2] \leftarrow r_4}{[100] \leftarrow 42}
        {Set {\tt x} to 42}
    \row{\sw ~ \rsp ~ r_0 ~ \negate 1}{[\rsp-1] \leftarrow r_0}{[101] \leftarrow 0}
        {Set {\tt y} to 0}
    \row{\addi ~ \rsp ~ \rsp ~ 2}{\rsp \leftarrow \rsp + 2}{\rsp \leftarrow 104}
        {Allocate {\tt g}'s call frame}
    \row{\sw ~ \rsp ~ r_0 ~ \negate 2}{[\rsp-2] \leftarrow r_0}{[102] \leftarrow 0}
        {Set argument to 0}
    \row{\sw ~ \rsp ~ r_0 ~ \negate 1}{[\rsp-1] \leftarrow r_0}{[103] \leftarrow 0}
        {Zero out result\apt{why?}}
    \row{\jal ~ \rra ~ 20}{\rra \leftarrow \PCname + 1; ~ \PCname \leftarrow 20}{\rra \leftarrow \thepcctr; ~ \PCname \leftarrow 20}
        {Call to {\tt g} ($\jal$)}
  \end{array}
  \]
  ~ \\
  ~\\
%  \apt{How's that description for last line?}
%  \apt{Where did these RISC-V insruction formats come from? I think some of them are just wrong, e.g.
%    $\jal$ takes a PC-relative argument, not an absolute one, and the proper way to code a return to $\rra$ is $\jalr  ~ \rra ~ r_0$.
%  But also the instruction operand ordering is awkward. Why not use standard AT\&T syntax?}
% At Call to G
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{43.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{{\tt g}'s call frame }}]%
\memory{6}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-46.5em}{0.75em}{42}
\MemoryLabel{-42.5em}{0.75em}{0}
\MemoryLabel{-38.5em}{0.75em}{0}
\MemoryLabel{-34.5em}{0.75em}{0}
\\
\end{center}
% Starting Register File
\summary{20}{0}{\thepcctr}{104}{42}{?}
%\vspace*{0.2em}
\setcounter{pcctr}{20}%
% G - Body - 1
\vspace*{0.2em}
  \[
  \begin{array}{c|c|c|c}
    \row{\addi ~ \rsp ~ \rsp ~ 2}{\rsp \leftarrow \rsp + 2}{\rsp \leftarrow 106}
        {Allocate local {\tt g} state}
    \row{\sw ~ \rsp ~ \rra ~ \negate 2}{[\rsp - 2] \leftarrow \rra}{[104] \leftarrow 8}
        {Store return address}
    % Zero out z?
    \row{\addi ~ \rsp ~ \rsp ~ 2}{\rsp \leftarrow \rsp + 2}{\rsp \leftarrow 108}
        {Allocate for call frame}
    \row{\addi ~ r_4 ~ r_0 ~ 17}{r_4 \leftarrow r_0 + 17}{r_4 \leftarrow 17}
        {Store 17 to $r_4$}
    \row{\sw ~ \rsp ~ r_4 ~ \negate 2}{[\rsp - 2] \leftarrow r_4}{[106] \leftarrow 17}
        {Store 17 as the argument {\tt v}}
    \row{\sw ~ \rsp ~ r_0 ~ \negate 1}{[\rsp - 1] \leftarrow r_0}{[107] \leftarrow 0}
        {Zero out result \apt{why?}}
    \row{\jal ~ \rra ~ 40}{\rra \leftarrow \PCname + 1 ; ~ \PCname \leftarrow 40}{\rra \leftarrow \thepcctr; ~ \PCname \leftarrow 40}
        {Call to {\tt h} ($\jal$)}
  \end{array}
  \]
  ~ \\
  ~ \\
% At Call to H
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{61.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{{\tt g}'s call frame }}]%
\memory{2}{\gprivc}[{\makebox[0pt]{${\texttt g}_{\mathit{priv}}$}}]%
\memory{2}{orange}[{\makebox[0pt]{{\tt h}'s call frame }}]%
\memory{2}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-46.5em}{0.75em}{42}
\MemoryLabel{-42.5em}{0.75em}{0}
\MemoryLabel{-38.5em}{0.75em}{0}
\MemoryLabel{-34.5em}{0.75em}{0}
\MemoryLabel{-30.5em}{0.75em}{8}
\MemoryLabel{-26.5em}{0.75em}{}
\MemoryLabel{-22.5em}{0.75em}{17}
\MemoryLabel{-18.5em}{0.75em}{0}
\\
\end{center}
% Starting Register File
\summary{40}{0}{\thepcctr}{108}{17}{?}
\setcounter{pcctr}{40}
\vspace*{0.2em}
% H - Body
\[
\begin{array}{c|c|c|c}
  \row{\addi ~ \rsp ~ \rsp ~ 1}{\rsp \leftarrow \rsp + 1}{\rsp \leftarrow 109}
      {Allocate for return address}
  \row{\sw ~ \rsp ~ \rra ~ \negate 1}{[\rsp - 1] \leftarrow \rra}{[108] \leftarrow 27}
      {Store return address}
  \row{\lw ~ r_4 ~ \rsp ~ \negate 3}{r_4 \leftarrow [\rsp - 3]}{r_4 \leftarrow 17}
      {Load the argument {\tt v} to $r_4$}
  \row{\addi ~ r_4 ~ r_4 ~ 1}{r_4 \leftarrow r_4 + 1}{r_4 \leftarrow 18}
      {Increment $r_4$ by 1}\end{array}
\]
~\\
~\\
% At Middle of H
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{65.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{{\tt g}'s call frame }}]%
\memory{2}{\gprivc}[{\makebox[0pt]{${\texttt g}_{\mathit{priv}}$}}]%
\memory{2}{orange}[{\makebox[0pt]{{\tt h}'s call frame }}]%
\memory{1}{\hprivc}%[{\makebox[0pt]{{\texttt h} ra}}]
\memory{1}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-46.5em}{0.75em}{42}
\MemoryLabel{-42.5em}{0.75em}{0}
\MemoryLabel{-38.5em}{0.75em}{0}
\MemoryLabel{-34.5em}{0.75em}{0}
\MemoryLabel{-30.5em}{0.75em}{8}
\MemoryLabel{-26.5em}{0.75em}{}
\MemoryLabel{-22.5em}{0.75em}{17}
\MemoryLabel{-18.5em}{0.75em}{0}
\MemoryLabel{-14.5em}{0.75em}{27}
\\
\end{center}
% Register File
\summary{40}{0}{\thepcctr}{109}{18}{?}
\vspace*{0.2em}
\label{fig:running-trace-a}
\end{figure}

\begin{figure}
\[
\begin{array}{c|c|c|c}
  \row{\sw ~ \rsp ~ r_4 ~ \negate 2}{[\rsp - 2] \leftarrow r_4}{[107] \leftarrow 18}
      {Store $r_4$ as the return value}
  \row{\lw ~ \rra ~ \rsp ~ \negate 1}{\rra \leftarrow [\rsp - 1]}{\rra \leftarrow 27}
      {Load return address}
  \row{\addi ~ \rsp ~ \rsp ~ \negate 1}{\rsp \leftarrow \rsp - 1}{\rsp \leftarrow 108}
      {Restore the stack pointer of {\tt g}}
  \row{\jalr ~ \rra ~ \rra ~ 0\apt{wrong}}{\PCname \leftarrow \rra}{\PCname \leftarrow 27}
      {Return to {\tt g} ($\jalr$)}
  \end{array}
\]

% After Return from H
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{61.5em}{2em}{\SP}
\memory{3}{\emptyoutc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{{\tt g}'s call frame }}]%
\memory{2}{orange}[{\makebox[0pt]{${\texttt g}_{\mathit{priv}}$}}]%
\memory{2}{\gprivc}[{\makebox[0pt]{{\tt h}'s call frame }}]%
\memory{2}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-46.5em}{0.75em}{42}
\MemoryLabel{-42.5em}{0.75em}{0}
\MemoryLabel{-38.5em}{0.75em}{0}
\MemoryLabel{-34.5em}{0.75em}{0}
\MemoryLabel{-30.5em}{0.75em}{8}
\MemoryLabel{-26.5em}{0.75em}{}
\MemoryLabel{-22.5em}{0.75em}{17}
\MemoryLabel{-18.5em}{0.75em}{18}
\\
\end{center}
% Starting Register File
\summary{27}{0}{\thepcctr}{108}{18}{?}
\vspace*{0.2em}

\setcounter{pcctr}{27}
% H - Body
\vspace*{0.2em}
\[
\begin{array}{c|c|c|c}
  \row{\lw ~ r_4 ~ \rsp ~ 0}{r_4 \leftarrow [\rsp]}{r_4 \leftarrow 18}
      {Load return value to $r_4$}
  \row{\sw ~ \rsp ~ r_4 ~ \negate 3}{[\rsp - 3] \leftarrow r_4}{[105] \leftarrow 18}
      {Set {\tt w} to 18}
  \row{\addi ~ \rsp ~ \rsp ~ \negate 2}{\rsp \leftarrow \rsp - 2}{\rsp \leftarrow 106}
      {Deallocate {\tt h}'s call frame}
  \row{\lw ~ r_5 ~ \rsp ~ \negate 4}{r_5 \leftarrow [\rsp - 4]}{r_5 \leftarrow 0}
      {Load argument {\tt z} to $r_5$}
  \row{\sw ~ \rout ~ r_5 ~ 0}{[\rout] \leftarrow r_5}{[99] \leftarrow 0}
      {Print {\tt z}}
  \row{\add ~ r_4 ~ r_4 ~ r_5}{r_4 \leftarrow r_4 + r_5}{r_4 \leftarrow 18}
      {Add $r_4$ and $r_5$}
  \row{\sw ~ \rsp ~ r_4 ~ \negate 3}{[\rsp - 3] \leftarrow r_4}{[103] \leftarrow 18}
      {Store $r_4$ as the return value}
  \row{\lw ~ \rra ~ \rsp ~ \negate 2}{\rra \leftarrow [\rsp - 2]}{\rra \leftarrow 8}
      {Load return address}
  \row{\addi ~ \rsp ~ \rsp ~ \negate 2}{\rsp \leftarrow \rsp - 2}{\rsp \leftarrow 104}
      {Deallocate {\tt g}'s local state}
  \row{\jalr ~ \rra ~ \rra ~ 0\apt{wrong}}{\PCname \leftarrow \rra}{\PCname \leftarrow 8}{Return to {\tt main} ($\jalr$)}
\end{array}
\]
% Return to main
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{43.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\fulloutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{{\tt g}'s call frame }}]%
\memory{6}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-51em}{0.75em}{0}
\MemoryLabel{-47em}{0.75em}{42}
\MemoryLabel{-43em}{0.75em}{0}
\MemoryLabel{-39em}{0.75em}{0}
\MemoryLabel{-35em}{0.75em}{18}
\\
\end{center}
% Register File
\summary{8}{0}{\thepcctr}{104}{18}{0}
%\vspace*{0.2em}
\setcounter{pcctr}{8}
\[
\begin{array}{c|c|c|c}
  \row{\lw ~ \rsp ~ r_4 ~ \negate 1}{r_4 \leftarrow [\rsp - 1]}{r_4 \leftarrow 18}
      {Load return value to $r_4$}
  \row{\sw ~ \rsp ~ r_4 ~ \negate 3}{[\rsp - 3] \leftarrow r_4}{[101] \leftarrow 18}
      {Set {\tt y} to the result}
  \row{\addi ~ \rsp ~ \rsp ~ \negate 4}{\rsp \leftarrow \rsp - 2}{\rsp \leftarrow 102}
      {Deallocate {\tt g}'s call frame}
  \row{\lw ~ \rsp ~ r_5 ~ \negate 2}{r_5 \leftarrow [\rsp - 2]}{r_5 \leftarrow 42}
      {Load {\tt x} to $r_5$}
  \row{\add ~ r_4 ~ r_4 ~ r_5}{r_4 \leftarrow r_4 + r_5}{r_4 \leftarrow 60}
      {Add {\tt x} and {\tt y}}
  \row{\sw ~ \rout ~ r_4 ~ 0}{[\rout] \leftarrow r_4}{[99] \leftarrow 60}
      {Print {\tt x + y}}
\end{array}
\]
\vspace*{0.2em}
% Return to main
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{31.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{Instructions}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\fulloutc}[{\makebox[0pt]{Output}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{${\texttt{main}}_{\mathit{priv}}$}}]%
\memory{8}{\unusedc}%[{\makebox[0pt]{Uninitialized}}]
~$\cdots$
\MemoryLabel{-51em}{0.75em}{60}
\MemoryLabel{-47em}{0.75em}{60}
\MemoryLabel{-43em}{0.75em}{42}
\\
\end{center}
% Starting Register File
\summary{\thepcctr}{0}{37}{102}{60}{42}
\caption{Detailed Execution Trace
%  \rb{A suggestion for the description of $\jal$ and $\jalr$:
%    call(function label) [if labels are added next to the entrypoints]
%    or call(address of entrypoint) and return()?}
}
\label{fig:running-trace-b}
\end{figure}

To show a trace of the execution of this program, we need a low-level
view of both the code and the machine it runs on. While the concrete
implementation of our enforcement mechanism (\Cref{sec:enforcement})\apt{Is it ``ours'' in this context?}
operates on a full conventional RISC-V architecture (using the FORVIS
simulator\leo{cite}\apt{why mention this here?}), we make a few simplifying assumptions here to
ease the exposition.

First of all, we ignore the heap. We are mainly concerned with stack
interactions so that will be the main focus; integrating a safety
propety for the heap in the
style of \citet{AzevedoDeAmorim17} is a natural extension we discuss
in~\Cref{sec:future}.
%
We also abstract away low-level details of memory layout and present a
machine that is word-addressed, with instructions starting from
location 0, a dedicated memory-mapped output port at location 99, and
the stack beginning at location 100 and growing upwards with increasing
addresses.  \leo{Explain more? How to connect to realistic
  one? Observations? DMA? Interrupt handlers?}
%
A sketch of the initial memory layout can be found at the top of
\cref{fig:running-trace-b}: instructions for {\tt main} begin at 0,
the dedicated output is uninitialized, while the (also uninitialized)
stack begins at 100. Directly below the layout, we summarize the parts
of the register file that are relevant to the example.
%
The rest of \cref{fig:running-trace-b} traces the execution of the
program, showing the machine state at call and return points.
Instructions are intended to
be similar to RISC-V, but are described in an ad-hoc notation
rather than using assembler syntax. The $\jal$ (jump-and-link)
instruction used for calls atomically saves the return address in a register
and jumps to a specified new $\PCname$; the $\jalr$ (jump-and-link-via-register)
instruction used for returns jumps to the address stored in a register.
Register $r_0$ is hardwired to zero. \leo{Expand upon this?}

\apt{Need to clarify to what extent our properties depend on the
particular compilation style, calling sequences, etc. illustrated here.}

\section{Threat Model}
\label{sec:threat}

\leo{Needs high level signposting, transitions}

Stack safety is meant to protect a caller from a malicious callee's
attempts to access private data or highjack its control flow. Our
attacker model reflects this intention: we assume that the attacker
can run arbitrary code as a caller and the enforcement mechanism
should protect against that. Hardware and timing attacks are out of
scope. \leo{Anything else to add here?}
\leo{Maybe a good place to discuss calling conventions and that they
  are essentially enforced by the policy or sth?}
\rb{Intuition that the callee can do anything in principle, but the machine will
halt if it does not follow the calling convention, etc.?}

\apt{Informal definition of policies as auxiliary state here.}

This model is flexible enough to capture any kind of mechanism used for dynamic
enforcement of properties of interest, including the following representative
families of policies.

%% \leo{Policies of interest: null, micro, cherri, software-only}
%% \leo{TODO: Write down carefully}

\paragraph*{Null policy}
%
The simplest possible policy is the neutral policy that carries no information
and does nothing. Its set of policy states $\POLS$ is the unit type, and its
policy step function is the constant function that produces the unit, $\lambda
\_ . \top$, thereby allowing all calls the machine step function. Its
initialization function is defined on all states. This corresponds to the
lifting of our machine model to the policy setting. Machines that fulfill a
property by construction will also fulfill that property with the null
policy.

\paragraph*{Software-only policies}
%
Some policies are implemented in software, by modifying code in the compiler
to (e.g.) perform bounds checking \citep{NagarakatteZMZ09} or to insert stack
canaries \citep{Cowan+98}. These approaches are represented as policies that
accept only initial machine states that are well-formed for the policy (due
to being produced by the compiler.) The set of policy states \(\POLS\) is again
the unit type and the step function constant. Property enforcement comes from
the fact that only ill-formed states can induce a trace that violates the
property.

\rb{TODO In a way, in these schemes the policy state is built in as part of the
  program state and transparent to the hardware, although it could be simulated
  by an overlay where enforcement is represented at the policy level.}

\paragraph*{Capability machines}
%
\rb{TODO Here the policy is built into the hardware, although the extended ISA
  could be split into a machine without capabilities and capabilities as the
  policy.}

\newcommand{\TAGS}{\mathcal{T}}
\newcommand{\tagname}{t}
\newcommand{\uP}{{\mu P}}

\paragraph*{Micropolicies}
%
Micropolicies are another major family of policies \citep{pump_oakland2015},
which are applied to stack safety in \citep{DBLP:conf/sp/RoesslerD18}.
Here the machine state is extended with tags paired with all components of the
system, and a monitor checks for each operation that the tags on the operands
obey a set of rules. One could treat tags directly as part of the machine
state, and build the rules into the step function. But local state
encapsulation properties as we frame them are not intuitive in their
interaction with tags or other additional enforcement state, so it is helpful
to separate tags for clarity. This also distinguishes a hardware fail-stop from
a software fail state.
\rb{TODO Similarly to above, should we consider tags as part of the machine or part of the
  policy? }


% 
%\leo{TODO: Add citations of mitigation techniques}
%\rb{And for those techniques, explain how they reflect their motivating
%examples. What does each technique do for those examples? How are they
%connected to this work?}
% 
%\paragraph*{Bad Write}
% 
%\[
%44 : [\rsp - 5] \leftarrow r_4
%%44 : ~ \sw ~ \rsp ~ r_4 ~ \negate 5
%\]
% 
%Instruction 44 currently is
%$ [\rsp - 2] \leftarrow r_4$,
%%$\sw ~ \rsp ~ r_4 ~ \negate 2$,
%with the
%effect of storing the contents of $r_4$ as the result of {\tt h}. If
%instead it wrote to location $\rsp - 5$ then it would be overwriting
%private data (the return address) belonging to {\tt g}.
% 
%\paragraph*{Bad Read}
% 
%\[
%30 : r_5  \leftarrow [\rsp - 6]
%%30 : ~ \lw ~ r_5 ~ \rsp ~ \negate 6
%\]
% 
%Instruction 30 currently is
%$ r_5 \leftarrow [\rsp - 4]$,
%%$\lw ~ r_5 ~ \rsp ~ \negate 4$,
%with the
%effect of loading the argument of {\tt g} to $r_5$. If instead it
%loaded the contents of location $\rsp - 6$, it would obtain access
%to the value of {\tt main}'s local variable {\tt x}. Worse, since the next instruction
%outputs the contents of $r_5$, that value would immediately be made public.
% 
%\paragraph*{Bad Control Flow}
% 
%\[
%5  : \rra \leftarrow \PCname + 1 ; ~ \PCname \leftarrow r_4
%%5 : \jalr ~ r_4 ~ \rra ~ 0
%\]
%If a {\jalr} instruction was added to {\tt main} with its target being
%the middle of the code block of {\tt h}.\apt{describe result of this?}

\section{Machines, Traces, and Observations}
\label{sec:prelim}

In this section we describe our machine model. Our definition of stack
safety is generic and this section discusses an abstract interface to
our machine model and some kind of static or dynamic, software- or
hardware-enforced security monitor. We will refer back to the running
example of the previous section for concreteness, and then,
in~\cref{sec:enforcement}, extend this model with a dynamic policy
enforcement mechanism based on
\citet{DBLP:conf/sp/RoesslerD18}.\apt{needs a relook}

\subsection{Values, States, and Observations}

The basic building blocks of the machine are {\em values} and {\em
  addresses}. Both are drawn from some set of {\em words}
$\WORDS$, ranged over by $\word$.
%
Our machine states are composed of {\em components} $k$, addressed either by
words (memory addresses) or by register names ($r$) drawn from some set
$\REGS$.
%
    \[\component \in \COMPONENTS = \WORDS + \REGS \]
%
The register names are assumed to include two special purpose registers: the
program counter {\PCname} and the stack pointer \SP.

A machine state is a map from components to values:
%
\[\mach \in \MACHS = \COMPONENTS \rightarrow \WORDS\]

The step function of the machine takes a machine state and produces a
pair of a machine state and an {\em observation}, which may be either
silent (written $\tau$) or a word of data that the machine
communicates to the outside world:
%
\[\obs \in \OBSS = \{\tau\} \uplus \WORDS\]
\[\mach \stepstoobs{\obs} \mach' : \MACHS \rightarrow \MACHS \times \OBSS \]
%

Notice that we choose to model observations explicitly, rather than simply treating
a subset of registers or memory as being observable.  This choice gives
us the flexibility to treat programs as observationally equivalent even when
their internal states may differ.
%The choice of modelling observations is an interesting one. A first approach
%would be to consider any change to the registers or memory as observable.
%However, as some parts of the stack will be considered ``private''
%this choice won't work. A relaxation of this to consider all changes
%to ``non-private'' data as observable could work in principle, but
%does not allow for an interesting weaker-but-more-efficient enforcement
%mechanism. We will come back to this point in \Cref{sec:lazy}.

In the running example of \Cref{sec:running-example}, 
$\WORDS$ is the
set of 64-bit integers and $\REGS$ is the set $\{r_0, \cdots, r_{31}\}
\cup \{\PCname,\SP\}$. Observations are the writes to the
  special $\rout$ location, which can be thought of as a memory-mapped
  output port: if during an execution step a word $w$ is
written to $\rout$ then $\obs = w$, otherwise $\obs = \tau$.

\subsection{Policies}

A policy is a general model of an enforcement mechanism, consisting of a
set of policy states \(\pol \in \POLS\), a policy step function
\((\mach, \pol) \polstep \pol' : \MACHS \times \POLS
\rightharpoonup \POLS\), and an initializer \(\pinit : \MACHS \rightharpoonup
\POLS\). The initializer establishes the initial policy state for a given
machine state, but is partial to reflect that some policies are only defined
on states that are well-formed in some way.\apt{Is this our current thinking?}

We write $\MPS$ for the set of all pairs of machine states and policy
states.
%
\[\MPS = \MACHS \times \POLS\]
%
We lift the policy step function to operate on such pairs
by combining it with the regular step function for machine states.

\judgmenttwo{\(\mach_1 \stepstoobs{\obs} \mach_2\)}{\((\mach_1, \pol_1)
               \polstep \pol_2\)}
            {\(\mpstate{\mach_1}{\pol_1} \stepstopol{\obs}
               \mpstate{\mach_2}{\pol_2}\)}

\apt{TODO: relate back to \Cref{sec:threat} and forward to \Cref{sec:enforcement}.}
%\leo{TODO: Forward pointer to policies right?}\bcp{Yes.  But also we can say
%in more detail that the intention is to capture any kind of dynamic
%enforcement mechanism and give as many names and citations as we can.}

\paragraph*{Machine Termination}

In our model, the machine step function is total -- a program does not halt
on its own, but may instead enter a silent terminal loop. Runs are only cut
short by the policy step function. This means that software-only policies that
can catch errors must be modeled as reaching an error state\apt{??}, not 
halting outright.\apt{Is this our current thinking?}


\subsection{Traces}

A trace over a type $\TRACEELEMS$ is a nonempty, finite or infinite sequence of
$\TRACEELEMS$s. We will mostly be concerned with sequences of pairs of machine states
and observations, called machine traces and denoted $\machT \in \MOTRACE$,
and with sequences of triples of a machine state, a policy state, and an
observation, denoted $\MPT \in \MPOTRACE$ and referred to as MP-traces.

\bcp{TODO: Let's also try to clean up the spacing a little -- many of these
  sequences of rules can be typeset on fewer lines}

\paragraph*{Trace-Of}

The ``trace-of'' operator, written \(\mach \hookrightarrow \machT\),
coinductively relates a machine state with the trace of machine states
paired with observations produced by repeated application of step:

\judgmenttwo{\(\mach_0 \stepstoobs{\obs} \mach_1\)}{\(\mach_1 \hookrightarrow \machT\)}
            {\(\mach_0 \hookrightarrow (\mach_0,\obs) \machT\)}%
%
\noindent
Since the step function is total, if \(\mach \hookrightarrow \machT\),
then \(\machT\) must be infinite.

In our running example in \Cref{fig:running-trace-b} we can
see a depiction of such a trace: starting from an initial machine
state at the very top, each instruction constructs a new machine state
(the diff of which compared to the previous one appears in the
``Effect'' column) and the majority of observations are $\tau$ with
the exception of instructions 31 and 13 which are writes to $\rout$
and where the observations are $0$ and $60$ respectively.

In a similar fashion, we define \(\mpstatename \hookrightarrow \MPT\)
to relate a machine-policy state pair to the MP-trace
induced by the step function on $\MPS$. Unlike the $\MOTRACE$ above, this trace can
be finite as the policy can cause a fault, in which case the final observation is
a \(\tau\):
\rb{This $\hookrightarrow_P$ is often enough written just $\hookrightarrow$.
  Overload everywhere?}\apt{Done, and for $\rightharpoonup$ too.}

\begin{minipage}{.4\textwidth}
\judgment{\(\neg \exists \pol_1 . \mpstate{\mach_0}{\pol_0} \polstep \pol_1\)}
         {\(\mpstate{\mach_0}{\pol_0} \hookrightarrow \mpostate{\mach_0}{\pol_0}{\tau}\)}
\end{minipage}
\begin{minipage}{.55\textwidth}
  \judgmenttwo{\(\mpstate{\mach_0}{\pol_o} \stepstopol{\obs}
                 \mpstate{\mach_1}{\pol_1}\)}
              {\(\mpstate{\mach_1}{\pol_1} \hookrightarrow \MPT\)}
              {\(\mpstate{\mach_0}{\pol_0} \hookrightarrow
                 \mpostate{\mach_0}{\pol_0}{\obs} \MPT\)}
\end{minipage}

We will also use \(\pi_m\) to project the trace of machine states
out of a trace, \(\pi_p\) to project the trace of policy states, and
\(\pi_o\) to project the observations, with \(\pi_m\) and \(\pi_o\) overloaded
for machine traces and MP-traces.

\paragraph*{Head and Last}

We take the first element of a trace with \(\head(\Trace)\), which is a total
function since traces are non-empty, and the final element (if one exists) with
\(\last(\Trace)\), which is partial.

\paragraph*{Until}
The operation \(\PUT~(\Trace,f)\)
%\bcp{Wouldn't
%``While'' be more mnemonic?} \sna{Appealing, but it's more of a
%``while-not''? Trying out ``until''. In any case... moving away
%from doing joins means this needs to get some work to eliminate
%the trailing observation. Here's an attempt.}
takes a trace
\(\Trace : \mathit{trace} ~ \TRACEELEMS \times \OBSS\) and a predicate
on elements \(f \subset \TRACEELEMS\) and gives the prefix of
\(\Trace\) ending with the first element on which \(f\) holds.
Subtly, because the observation associated with a trace represents its
next step, when we take a prefix from a trace containing observations
we must replace the final observation with a \(\tau\).

  \begin{center}
  \begin{minipage}{.3\textwidth}
    \judgment{\(f\ \traceelem\)}
             {\(\PUT~(f,(\traceelem,\obs)\Trace) = (\traceelem,\tau)\)}
  \end{minipage}
%
  \begin{minipage}{.3\textwidth}
  \judgment{}
           {\(\PUT~(f,(\traceelem,\obs)) = (\traceelem,\tau)\)}
%
  \end{minipage}
  \begin{minipage}{.3\textwidth}
  \judgmenttwo{\(\neg f\ \traceelem\)}{\(\PUT~(f,\Trace) = \Trace'\)}
              {\(\PUT~(f,(\traceelem,\obs)\Trace) = (\traceelem,\obs)\Trace'\)}
  \end{minipage}
  \end{center}
%
Note that if the resulting trace is a strict prefix of the parameter, then the
predicate must hold on its final element. If the predicate never holds,
\(\PUT\) is the identity function.

% The {\it join} operation, written \(T_1 \cdot T_2\) is the reverse of
%$\mathit{split}$: it takes two traces and links them by replacing the
%last element of the first (if it has one) with the first element of
%the second

%\judgment{} {\(t \cdot T = T\)}
%\judgment{\(T_1 \cdot T_2 = T\)}{\(tT_1 \cdot T_2 = tT\)}
%\leo{Lemma/theorem: split/join = id?}
%\leo{TODO: FORMATTING: Remove force line break/par at end of judgments}

We will frequently take a prefix of the trace from an initial state up
through the first state where some condition holds on the machine state.
This can easily be implemented using \(\PUT\), and we provide special notation
for convenience.
%
Let \(f\) be a predicate on machine states. Then we define \(\mach
\hookrightarrow \machT | f\) (read ``\(\machT\) is the prefix of
running \(\mach\) up to \(f\)''):

\judgmenttwo{\(\mach \hookrightarrow \machT'\)}
            {\(\PUT~(f,\machT')
              = \machT\)}
            {\(\mach \hookrightarrow \machT | f\)}
\noindent
And similarly for traces with policies:

\judgmenttwo{\(\mpstatename \hookrightarrow \MPT'\)}
            {\(\PUT~(\lambda \mpstate{\mach}{\pol}.f\ \mach,\MPT') = \MPT\)}
         {\(\mpstatename \hookrightarrow \MPT | f\)}

%    \COQ{this operation steps until it reaches a state on which \(f\) holds,
%    and is infinite if it doesn't. It doesn't compute the observation of the step after the final,
%    which coq would. So coq may need a ``step until'' relation rather than ``prefix up to''.
%    Still thinking about this.}\leo{So this is strictly weaker than the one we have in Coq, right?
%      So its only the Eager implies Lazy direction that might need tweaking, but not the Test implies Eager one?}
%    \leo{Also, it steps until it reaches an f-state or if the policy raises a fault}

\paragraph*{Observational Similarity}

We say that a trace of observations $\obsT_1$ is a prefix of $\obsT_2$
as far as an external observer is concerned, if the sequence of
non-silent observations of $\obsT_1$ is a prefix of those of
$\obsT_2$; that is, we operate up to deletion of \(\tau\) observations,
coinductively:

\begin{minipage}{.3\textwidth}
  \judgment{}{\(\obsT \lesssim \obsT\)}
\end{minipage}
\begin{minipage}{.3\textwidth}
\judgment{}{\(\tau \lesssim \obsT\)}
\end{minipage}
\begin{minipage}{.3\textwidth}
\judgment{}{\(w \lesssim w\obsT\)}
\end{minipage}

\begin{minipage}{.3\textwidth}
\judgment{\(\obsT_1 \lesssim \obsT_2\)}
         {\(\tau \obsT_1 \lesssim \obsT_2\)}
\end{minipage}
\begin{minipage}{.3\textwidth}
\judgment{\(\obsT_1 \lesssim \obsT_2\)}
         {\(\obsT_1 \lesssim \tau \obsT_2\)}
\end{minipage}
\begin{minipage}{.3\textwidth}
\judgment{\(\obsT_1 \lesssim \obsT_2\)}
         {\(w\obsT_1 \lesssim w\obsT_2\)}
\end{minipage}

We then define similarity of observation traces as traces prefixing each other:

\bcp{Can we please call it something else?  An
  ``equivalence'' should always be transitive.}
\sna{Similarity seems less loaded?}
\[\obsT_1 \simeq \obsT_2 \triangleq \obsT_1 \lesssim \obsT_2 \land \obsT_2 \lesssim \obsT_1\]

\leo{I still don't know how to do this transition. Maybe contrast
with the ``perhaps surprisingly'' later?} Note that
similarity of observation traces could alternatively be defined coinductively,
just like the prefix relation, but by dropping the asymmetric rules that allow
for a finite trace ($\tau \lesssim \obsT$ or $w \lesssim w\obsT$).\apt{Is this immportant?}

Note that an infinite silent trace is a
prefix of (and equivalent to) any other trace. While this might seem
surprising at first, it makes sense in a timing-insensitive context:
an external observer looking at two machine runs cannot (computably)
distinguish between a machine that steps forever and a machine that
steps for a long time before producing some output.

%Let the predicate \(\isinf(T)\) hold when the trace $T$ is infinite.
%We then define {\em policy-sensitive observational equivalence}: a
%trace $\MPT \in \MPOTRACE$ is equivalent to a trace $\machT \in
%\MOTRACE$ if (1) \(\MPT\) is infinite and the observations of \(\MPT\)
%and \(\machT\) are equivalent, or (2) if the \(\MPT\) is finite (due to a
%policy fault) and its observations are a prefix of those of M.
%
%% Fixed by Sean
%%\leo{Why $\mathit{Obs}$ and not $\pi_o$ defined earlier?}
%\judgmenttwo{\(\neg \isinf(\MPT)\)}{\(\pi_o(\MPT) \lesssim \pi_o(\machT)\)}
%            {\(\MPT \sim_P \machT\)}
%
%\judgmenttwo{\(\isinf(\MPT)\)}{\(\pi_o(\MPT) \simeq \pi_o(\machT)\)}
%            {\(\MPT \sim_P \machT\)}

\section{Stack Safety, Formally}
\label{sec:lse-and-wbcf}

In this section we formalize our definition of stack safety.We
begin with our model of \leo{compiler-provided?} knowledge about the
program structure, and then dive into the formal definitions of local state
encapsulation and well-bracketed control flow that together constitute
stack safety.

\subsection{Program Structure}

Our properties and policies are parameterized by several types of
annotations describing features of a program.

\paragraph*{Function Map}

A {\em function map} identifies some addresses as code and assigns
each to a function. Formally, a function map is a
partial function from addresses to a function
identifier drawn from the set \(\FUNIDS\).
  %
\[\codemap \in \CODEMAPS = \WORDS \rightharpoonup \FUNIDS\]
%
In our running example, instructions 1-13 correspond to {\tt main},
instructions 20-36 correspond to {\tt g}, and instructions 40-47
correspond to {\tt h}, which means that the function map would be:
\[ \codemap = \{\texttt{main} \mapsto \{1\ldots13\}, \texttt{g} \mapsto \{20\ldots36\}, \texttt{h} \mapsto \{40\ldots47\}\}\]

\paragraph*{Call Map}

A {\em call map} identifies addresses that complete a call sequence,
abstracting away from any concrete calling convention. Formally, it is
a partial function from addresses to a natural number, the number of
arguments and return values of the call.
  %
\[\callmap \in \CALLMAPS = \WORDS \rightharpoonup \mathbb{N}\]
%
In our running example, the callmap contains two entries: the word 7
corresponding to the call to {\tt g} which has one argument and one
return value; and the word 26 corresponding to the call to {\tt h},
also with a single argument and return value:
\[ \callmap = \{ 7 \mapsto 2, 26 \mapsto 2\}\]

For concreteness, in a typical calling convention, a call map may be
considered to identify the state just before the \jal, in which
space for arguments is already allocated, but the mechanism is more
general. A state in which a call map is defined on the program counter
is referred to as a {\it call state}.

\paragraph*{Return Map}
Similarly, a {\em return map} identifies addresses that complete a
return sequence. Formally, it is simply a set of words; each one
is the address of the final jump corresponding to a function return:
%
\[\retmap \in \RETMAPS \subseteq \WORDS\]
%
In our running example, the return map identifies the $\jalr$
instructions 36 and 47:
\[ \retmap = \{36, 47\} \]

\paragraph*{Entry Map}
Finally, the entry map identifies valid entry points to a
function and is also a set:
\[\entmap \in \ENTMAPS \subseteq \WORDS\]
%
In our running example, the entry map contains the entry
points of {\tt g} and {\tt h}:
\[ \entmap = \{20, 40\} \]

\paragraph*{What is a return?}

We separately identify, for any call state, what it means for a state
to have correctly returned from a call. We consider the call to have
returned when control returns to the instruction following
the \jal with the stack restored. Formally, this is a predicate on
states that says when the machine has just returned from a specified call state
(where $\nextPC$ gives the address of the next instruction after a given address):
\[%\begin{split}
    \ret{\mach_c} \triangleq  \lambda \mach_r . \mach_r(\PCname) =
    \nextPC(\mach_c(\PCname)) \land  \mach_r(\SP) = \mach_c(\SP)
%\end{split}
\]
There are two such return points in our running example, both of which
are depicted in the figure: the state before the execution of
instruction 27 corresponding to the return from {\tt h} and the state
before instruction 8 corresponding to the return from {\tt g}.

\medskip

In the rest of this section we implictly parameterize all 
definitions by a function map $\codemap$, a call map $\callmap$, a return
map $\retmap$ and an entry map $\entmap$.

\subsection{Local State Encapsulation}
\label{sec:lse}

The first part of stack safety is {\em local state encapsulation}.
Informally, it captures the notion that a caller's data is
protected from a callee's actions. We formalize this notion
as a security property with an integrity and a confidentiality
component, where the former protects the caller's data from being
written and the latter from being read.

As is standard with security properties, we associate with each
component of the machine a {\em label}: a pair of security levels
denoting high or low confidentiality and high or low integrity.
%
\[\mathit{label} ::= \{\HIGHSEC,\LOWSEC\} \times \{\HIGHINT,\LOWINT\}\]
%
In a traditional setting, integrity would enforce that the contents of
$\HIGHINT$ locations remain unchanged, while confidentiality would
enforce that the contents of $\HIGHSEC$ locations do not influence the
observable behavior of the machine. However, when dealing with nested
calls and returns, stack safety needs to enforce integrity and
confidentiality for {\em every} function call in a trace; that is, we
must treat the security level of data dynamically.
%
To that end, we introduce the notion of a {\em contour}, a map from
components to labels:
%
\[\contour \in \CONTOURS ::= \COMPONENTS \rightarrow \mathit{label}\]

When \(\mach_c\) is a call state (\(\callmap(\mach_c(\PCname)) = n\) for some $n$) and
\(\mach_c \stepstoobs{\obs} \mach_e\) for some 
$\mach_e$ and $\obs$, we can construct a contour based on the bounds of the
callee's stack frame.
%
The private state of the callee is the entire area of the memory from
stack base to stack pointer, with the exception of the $n$ locations
corresponding to the arguments and result locations of the
call. Private components are marked high confidentiality and high
integrity: the callee should be able to neither read nor write them.
%
Everything above the stack pointer at the point of the call is
``uninitialized'' memory that can be written into but should not be
read. To protect the callee itself from such reads, these components
are marked high confidentiality and low integrity.
%
The same is true for the designated output location: it can be
freely written into but should not be read.
%
Special care is needed for the code memory corresponding to the
callee: they are marked low confidentiality if they belong to the
callee and high confidentiality otherwise; regardless they are always
high integrity.\apt{Sean:I think this is vestigial from an aborted version
  in which you were modeling WBCF using confidentiality. In any casen
  it is not reflected in the definition below.}
%
Finally, registers and the frame of arguments and results are free
for the callee to use, and are therefore tagged with low integrity and
low confidentiality.

 \[\mathit{Cof}(\mach,n)(\component) =
  \begin{cases}
    (\LOWSEC,\HIGHINT) & \text{if } \component \in \WORDS
                         \text{ and } \codemap(\component) = \funid \text{ for some }\funid\\
    (\HIGHSEC,\LOWINT) & \text{else if } \component \in \WORDS
                          \text{ and } \component \geq \mach(\SP)
                          \text{ or if } \component = \rout\\
    (\HIGHSEC,\HIGHINT) & \text{else if } \component \in \WORDS
                          \text{ and } \component \leq \mach(\SP) \negate  n \\
    (\LOWSEC,\LOWINT) & \text{else} \\
  \end{cases}\]

Going back to our running example, here is the state of the machine at
the call from {\tt main} to {\tt g}, showing addresses annotated with their 
corresponding labels (not shown: the labels of the instructions
corresponding to {\tt g} that are $(\LOWSEC, \HIGHINT)$ instead of
$(\HIGHSEC, \HIGHINT)$)\apt{see previous note}:
\vspace*{0.2em}
% At Call to G
% Memory Layout
\begin{center}
\MemoryLabel{4em}{2em}{0}
\MemoryLabel{21em}{2em}{99}
\MemoryLabel{43.5em}{2em}{\SP}
\memory{3}{\instrc}[{\makebox[0pt]{$(\HIGHSEC,\HIGHINT)$}}]%
\hspace*{3pt}
$\cdots$
\memory{1}{\emptyoutc}[{\makebox[0pt]{$(\HIGHSEC, \LOWINT)$}}]%
\memory{2}{\fprivc}[{\makebox[0pt]{$(\HIGHSEC, \HIGHINT)$}}]%
\memory{2}{\fcallc}[{\makebox[0pt]{$(\LOWSEC, \LOWINT)$}}]%
\memory{6}{\unusedc}[{\makebox[0pt]{$(\HIGHSEC, \LOWINT)$}}]
~$\cdots$
\MemoryLabel{-46.5em}{0.75em}{42}
\MemoryLabel{-42.5em}{0.75em}{0}
\MemoryLabel{-38.5em}{0.75em}{0}
\MemoryLabel{-34.5em}{0.75em}{0}
\\
\end{center}

%If $\mach$ is the state at this call, the corresponding contour would
%be:
%\[
%\mathit{Cof}(\mach,2) = \left \{
%\begin{array}{l}
%  0\ldots98\} \mapsto (\LOWSEC, \HIGHINT)\\
%  99 \mapsto (\HIGHSEC, \LOWINT)\\
%  100, 101 \mapsto (\HIGHSEC, \HIGHINT)\\
%  102, 103 \mapsto (\LOWSEC, \LOWINT)\\
%  104\ldots \mapsto (\HIGHSEC, \LOWINT)\\
%  r \mapsto (\LOWSEC, \LOWINT)\\
%\end{array}
%\right .
%\]


\subsubsection{Stack Integrity}

The first component of local state encapsulation is an integrity
property: it ensures that the caller's data is never overwritten by a
callee. We will formally define integrity in two steps: first, we will
define integrity as a trace property over the trace corresponding to a
single call (from its entry point to its corresponding return), and
then we will lift that to a property for every such subtrace of a
callee.

\definition
Let $\contour$ be a contour and $\MPT$ be a (potentially infinite)
$\MPOTRACE$. We will say $\MPT$ satisfies {\em trace integrity} with
respect to $\contour$ if its final state (if any) agrees with its
initial one on all components marked $\HIGHSEC$ in $\contour$:
%
\[\begin{split}
  \mathit{int} ~ \contour ~ \MPT \triangleq &
    \head(\MPT) = \mpostate{\mach_e}{\_}{\_}  \land 
    \last(\MPT) = \mpostate{\mach_r}{\_}{\_} \Rightarrow \\
  & \forall \component. ~ \contour(\component) = \HIGHSEC \Rightarrow
    \mach_e(\component) = \mach_r(\component) \\
\end{split}\]
%\leo{TODO: DISCUSS: Figure out notation for first/last machine state in a trace}
%\sna{We could do it like this, with finiteness implicit in the existence of
%     a final state.}+1

Intuitively, the caller expects to find their private data untouched
after the callee returns. That means that if the callee never returns,
integrity is trivially satisfied. Similarly, the callee is allowed to
temporarily overwrite these locations, as long as they are restored
once control returns. We will see variations of this later on: a
stronger, inductive integrity property that ensures that the caller's
private data is never overwritten, even during the caller's execution
(which leads to easier reasoning and more effective testing);
and a weaker, lazy integrity property that only ensures the preservation
of locations that subsequently affect the caller's observable actions 
(which allows for a more efficient enforcement mechanism).

\begin{figure}
  \integrityexample
  \caption{Failing Trace Integrity}
  \label{fig:intex}
\end{figure}

Trace integrity characterizes the trace corresponding to a single
callee.
Going back to our running example, such a trace would be, for
instance, the entire trace of {\tt h} from instruction 40 to
instruction 47. 
As an example of an integrity violation affecting this trace, \cref{fig:intex} shows what happens
if we change line 44 of the example program to $[\rsp - 5] \leftarrow r_4$.
Instead of storing data to the return value slot,
the changed version overwrites {\tt g}'s local variable {\tt z}.
The figure shows the modified trace, with snapshots of the initial
and final states colored to show the contour; high 
integrity memory is in red\apt{NO?}, while low integrity is in green\apt{NO?}.
At the end of the trace high integrity address 103 should match the initial state, and does not.
So trace integrity is violated.
\rb{There are some color name macros, but none for integrity yet? Use instead
  of hardcoded color names.}\apt{I don't understand what's going on with the colors.
  I thought we agreed to use the same coloring scheme throughout?}

We now lift this definition to an integrity property for a complete
execution trace. We do this by requiring that trace integrity holds
for every subtrace delimited by a call and its corresponding return.
%for every transition between a caller and a callee for the entirety of
%the trace of the callee.\apt{?????}

\apt{Some more words needed here to smooth the technicalities.}

\definition%{Transition}
Given a trace $\MPT$, an $n$-{\em transition} is a pair of
machine-policy state pairs $(\mach_c, \pol_c)$ and $(\mach_e, \pol_e)$
in the trace such that:
\begin{itemize}
\item one state pair steps to the other:
  $$\exists \obs. ~ (\mach_c, \pol_c) \stepstopol{\obs} (\mach_e, \pol_e),$$
\item $\mach_c$ is a valid call with $n$ arguments:
  $$\callmap(\mach_c(\PCname)) = n,$$
\item and $\mach_e$ is an entry point\apt{or is in some function?? and why do we need either??}:
  $$\exists f. \codemap(\mach_e(\PCname)) = f.$$
\end{itemize}

\definition%{Stack Integrity}
A system satisfies {\em stack
  integrity} if, for every
initial machine-policy state pair $(\mach_0, \pol_0)$ and its induced
trace $\MPT$, and every $n$-transition $(\mach_c, \pol_c)$ and
$(\mach_e, \pol_e)$ in $\MPT$, the prefix $\MPT_{pre}$ of $\MPT$ from
$(\mach_e, \pol_e)$ until the first return corresponding to $\mach_c$
(if any) satisfies trace integrity with respect to the contour at the
call:
%
$$\forall \MPT_{pre}. ~ \mpstate{\mach_e}{\pol_e} \hookrightarrow_P
\MPT_{pre} ~ | ~ \ret{\mach_c} \Rightarrow
\mathit{int}~\mathit{Cof}(\mach_c, n)~\MPT_{pre}$$

\subsubsection{Stack Confidentiality}

The second component of local state encapsulation is a confidentiality
property: just like integrity ensures that a caller's data is never
overwritten by a callee, confidentiality ensures that the caller's data never
influences the callee's observable behavior. We will formally define
confidentiality in two similar steps: a trace version and a system
version.

Unlike integrity, confidentiality is a noninterference-style property,
comparing the behavior of a machine with an arbitrary variant that
preserves low confidentiality data.

\definition%{Variations}
We say two machine states $\mach$ and $\mach'$ are {\em variations} of one
another with respect to a contour $\contour$ if they agree on low
confidentiality data:
%
\[
\mach \approx_\contour \mach' \triangleq \forall \component .
\contour(\component) = \LOWSEC \Rightarrow \mach(\component) =
\mach'(\component)
\]
%
Then, the trace version of confidentiality operates on two traces: the
``original'' tracce $MP \in \MPOTRACE$ that corresponds to a callee $f$
and a ``variant'' trace $M \in \MTRACE$ that corresponds to how $f$
would behaves if it were started from a variant initial machine state.
%
As an example of variations, consider the top of \Cref{fig:confex1}
which shows a snapshot of the state as in the running example (top
memory layout) and a variation of it (bottom). \leo{Finalize
  contents, describe}

\definition%{Trace Confidentiality}
%% Suppose $m_e \approx_\contour m_e'$.
%% Two traces $MP$ with $\head(MP) = m_e$ and $M$ with $head(M) = m_e'$
%% satisfy {\em trace confidentiality} with respect to $\contour$ and
%% a return predicate \(R \subset \MACHS\) if:
Two traces $MP$, with head $m_e$, and $M$, with head $m_e'$,
satisfy {\em trace confidentiality} with respect to contour $\contour$ and
a return predicate \(R \subset \MACHS\) if, whenever $m_e \approx_\contour m_e'$ then:
\begin{itemize}
\item If $\MPT$ is finite with final state $\mach_r$ and $\mach_r \in R$, 
  then $\machT$ is also finite with some final state $\mach_r'$ and
  any changes from the initial states have changed in the same way:
$$\forall \component. ~ \mach_e(\component) \not = \mach_r(\component)
  \vee \mach_e'(\component) \not = \mach_r'(\component) \Rightarrow
  \mach_r(\component) = \mach_r'(\component)$$
  In addition their observations must be similar:
  $$\pi_o(\MPT) \eqsim \pi_o(\machT)$$
\item If $\MPT$ is infinite, then $\machT$ is also infinite and their
  observations are similar:
  $$\pi_o(\MPT) \eqsim \pi_o(\machT)$$
\item If the $\MPT$ ends prematurely, without fulfilling \(R\), then
  we require that its observations are a prefix of those of $\machT$:
  $$\pi_o(\MPT) \lesssim \pi_o(\machT)$$
\end{itemize}
\apt{Needs words about why we need a return predicate abstraction.}

Consider the result of modifying line 42 of our running example to $r_4 \leftarrow [\rsp - 9]$.
Instead of reading the proper argument {\tt v}, {\tt h} now reads directly from the
secret value of {\tt x} that belongs to {\tt main}. \Cref{fig:confex}
shows \(\mach_e\), the entry state of {\tt h}, with high confidentiality memory
in {\high} and low confidentiality in \low. Below it, the variant state
\(\mach_e'\) agrees on low confidentiality memory, but all other addresses
hold -5, in orange.\apt{NO?}  After the last step, the return states \(\mach_r\) and
\(\mach_r'\) should agree on every component that changed since \(\mach_e\) or
\(\mach_e'\). Addresses 108 and 109 have changed, shown in \tainted, and while 109
had changed in a consistent way (independent of the variation), 108 holds either 43 or -4, so the trace does not obey trace confidentiality.
\rb{Color name macros}
\apt{Explain slash notation in effects column.}

As another example, 
changing line 30 of the running example to $r_5  \leftarrow [\rsp - 6]$ would cause
{\tt g} to read the value of {\tt main}'s local variable {\tt x} and then immediately
output it, violating the internal observation clause of the confidentiality definition.
%\Cref{fig:confex2} shows the initial states \(\mach_e\), above,
%and \(\mach_e'\), below. Low confidentiality data in green is shared
%between them, while high confidentiality data in red and yellow may differ.
%After executing the code shown, the final states below have written different
%values to address 42, represented by the black and white components.
%It is allowed for address 40 to differ between the states due to the initial
%variation, but address 42 changed differently between the traces, representing
%a leak of data. %Meanwhile \ref{fig:lazyex2}, while high confidentiality data
%is read, it is overwritten before return, and the write at step 3 always writes
%the same value. \Gprivc and red locations differ between variations only because
%of the initial variation, and the rest are identical. So this example passes.

\begin{figure}
  \confidentialityendexample
  \caption{Failing Trace Confidentiality}
  \label{fig:confex}
\end{figure}

%\Cref{fig:confex2} gives an example of a trace that fails trace
%confidentiality. At instruction 42, {\tt h} reads {\tt x} from {\tt main}.
%Since {\tt x}, at address 100, is high confidentiality (red) the variant
%may have a different value (yellow). So both \(r_4\) and address 107
%differ in the final state between the original trace and the variant one,
%failing the ending condition of trace confidentiality.

To lift trace confidentiality to a system property, we follow the same
pattern as in stack integrity:

\definition%{Stack Confidentiality}
%Let $\callmap$ be a call map and $\codemap$ a function map.
We say that a
system satisfies {\em stack confidentiality}
% with respect to $\callmap$ and $\codemap$
if, for every initial machine-policy state
pair $(\mach_0, \pol_0)$ and its induced trace $\MPT$, and every
$n$-transition $(\mach_c, \pol_c)$ and $(\mach_e, \pol_e)$ 
in $\MPT$, the following holds. Let $\MPT_{\mathit{call}}$ be the prefix where
\(\mpstate{\mach_e}{\pol_e} \hookrightarrow_P \MPT_{\mathit{call}} | \ret{\mach_c}\).
For each variant state \(\mach_e' \approx_{\mathit{Cof}(\mach_c,n)}
\mach_e\), let \(\machT\) be the similarly prefixed trace such that
\(\mach_e' \hookrightarrow \machT\). Then trace confidentiality holds on
\(\MPT_{\mathit{call}}\) and \(\machT\) with regard to \(\mathit{Cof}(\mach_c, n)\)
and \(R = \ret{\mach_c}\):

$$\forall \MPT_{\mathit{call}} ~ \machT. ~
\mpstate{\mach_e}{\pol_e} \hookrightarrow_P \MPT_{\mathit{call}} ~ | ~ \ret{\mach_c} \Rightarrow$$
$$\forall \mach_e'. ~ \mach_e \approx_{\mathit{Cof}(\mach_c, n)} \mach_e' \wedge
\mach_e' \hookrightarrow \machT ~ | ~ \ret{\mach_c} \Rightarrow$$
$$\mathit{conf}~\mathit{Cof}(\mach_c, n) ~ (\ret{\mach_c}) ~ \MPT_{\mathit{call}} ~ \machT_{\mathit{call}}$$

\apt{oy. still needs work to make this intelligible}

\subsection{Well-bracketed Control Flow}
\label{sec:wbcf}

Both the integrity and confidentiality components of local state
encapsulation concern themselves with the accessibility of data, and
may hold on a wide range of programs that violate expected control
flow. Say, if {\tt g} managed to jump in the middle of the
code of {\tt h} with its call, confidentiality and integrity would
still be satisfied.
%
However, that is still unwanted behavior: for example, a caller (or a
callee) should not be able to bypass a password check by jumping (or
returning) in the middle of a block of code --- even if such an execution
would ostensibly satisfy local state encapsulation.
%
Stack safety is traditionally associated with preventing such unwanted
flows: every jump between functions should either be a call or a
return, and each return should be to the instruction after its
corresponding call.

To formally capture this aspect of stack safety, we introduce three
security properties that rely on the underlying knowledge of the
program structure (call maps, function maps, return maps, and entry
maps): {\em control separation} ensures the validity of transition
sources between functions, {\em entry integrity} ensures the validity
of call targets, and {\em return integrity} ensures the validity of
return targets.

\definition{Control Separation}

A system enjoys {\em control separation} with regard to a function map
\(\codemap\), a call map \(\callmap\), and a return map \(\retmap\),
if for any initial state \((\mach_0, \pol_0)\) and any adjacent pair
of states \((\mach_1,\pol_1)\) and \((\mach_2,\pol_2)\) in the induced
trace from \(\mpstate{\mach_0}{\pol_0})\) whose current instruction
belongs to different functions according to the function map,
either $\mach_1$ is a valid call or a valid return:

\[ \codemap(\mach_1(\PCname)) \not = \codemap(\mach_2(\PCname)) \Rightarrow
\exists n. ~ \callmap(\mach_1(\PCname)) = n \vee
\retmap(\mach_1) \]

For example, consider the unsafe substitution:
\[
5 : ~ \jalr ~ r_4 ~ \rra ~ 0
\]
This violates control separation as the instruction that causes a
function switch is not a valid call (or a return) according to the
call map.

\definition{Entry Integrity}

A system enjoys {\em entry integrity} with regard to a call map
\(\callmap\) and entry map \(\entmap\) if for any initial state
\((\mach_0, \pol_0)\) and any n-transition \((\mach_c,\pol_c)\) and
\((\mach_e, \pol_e)\) in the induced trace from
\(\mpstate{\mach_0}{\pol_0}\), $\mach_e$ is a member of the entry map:
\[\callmap(\mach_c(\PCname)) = n \Rightarrow \entmap(\mach_e)\]

The same unsafe substitution violates entry integrity
\[
5 : ~ \jalr ~ r_4 ~ \rra ~ 0
\]
as its target (instruction 42) is not an established entry point for
{\tt h} according to the entry map.

\leo{Note something about not enforcing control flow integrity
  with allowing a call from {\tt main} to {\tt h}?}

\definition{Return Integrity}

\newcommand*{\Unmatched}{\mathit{Unmatched}}

Return integrity captures the expected behavior of marked returns with
regard to their call points. Given a call map $\callmap$ and a return
map $\retmap$, we begin by defining a coinductive relation
$\Unmatched$ over two $\MPOTRACE$ $\MPT$ and $\MPT'$, if $\MPT'$ is a
suffix of $\MPT$ whose head is the first unmatched return in $\MPT$.

Formally:
\begin{itemize}
\item A trace that starts with a return is related to itself:

  \judgmenttwo{\(\callmap(\mach(\PCname)) = \bot\)}
              {\(\retmap(\mach(\PCname))\)}
              {\(\Unmatched ~ \mpstate{\mach}{\pol} ~ \mpstate{\mach}{\pol}\)}
  \judgmenttwo{\(\callmap(\mach(\PCname)) = \bot\)}
              {\(\retmap(\mach(\PCname))\)}
              {\(\Unmatched ~ \mpstate{\mach}{\pol}\MPT ~ \mpstate{\mach}{\pol}\MPT\)}

\item If a trace \(\MPT\) starts with a non-call, non-return state,
  its unmatched return must come later:

  \judgment{\(\callmap(\mach(\PCname)) = \bot
              \hspace{.5cm} \neg \retmap(\mach(\PCname))
              \Unmatched ~ \MPT ~ \MPT'\)}
           {\(\Unmatched ~ \mpstate{\mach}{\pol}\MPT ~ \MPT'\)}

\item Finally, if a trace starts with the call, then we must discard the first
  unmatched return to get to the real one:


  \judgmentbr{\(\callmap(\mach(\PCname)) = n \hspace{.5cm} \neg \retmap(\mach(\PCname)) \)}
             {\(\MPT = (m,p)\MPT_{\mathit{call}}\) \quad \(\Unmatched ~ \MPT_{\mathit{call}} ~ \MPT_{\mathit{matched}}\)}
             {\(\MPT_{\mathit{matched}} = \mpstate{\mach'}{\pol'} \MPT_{\mathit{tail}}\) \quad
              \(\Unmatched ~ \MPT_{\mathit{tail}} ~ \MPT_{\mathit{unmatched}}\)}
            {\(\Unmatched ~ \MPT ~ \MPT_{\mathit{unmatched}}\)}
\end{itemize}
A system enjoys {\em return integrity} with regard to a call map
\(\callmap\) and return map \(\retmap\) if for any initial state pair
\((\mach_0, \pol_0)\) and any state pair \((\mach_c, \pol_c)\)
corresponding to a call in its induced trace, if
\(\mpstate{\mach_c}{\pol_c} \hookrightarrow_P \MPT\) and \(\mach_r\)
is the first unmatched return such that for some $\pol_r$
\[ \Unmatched ~ \MPT ~ (m_r,p_r)\MPT',\]
then $\mach_r$ corresponds to a return state for $\mach_c$:
\[\ret{\mach_c}\ \mach_r\]

For example, if we added an instruction between 45 and 46:
\[
45.5: ~ \addi ~ \rra ~ r_0 ~ \negate 19
\]
This would cause the return from {\tt h} to go to instruction 8 and
return to {\tt main} instead of {\tt g}. While the instruction that
causes the return would still be a valid return (satisfying control
separation), the state after the return would not correspond to an
$\Unmatched$ return for {\tt g}'s call to {\tt h}, violating return
integrity.

\definition{Well-Bracketed Control Flow}

The above properties are somewhat orthogonal, but together they
capture a standard notion of control flow for a stack: functions keep
their code separate outside of calls and returns, calls respect
explicit entry points, and returns respect implicit entry points
corresponding to their call.  A system that enjoys them with regard to
a code, a call, a return, and an entry map is said to enjoy
{\em well-bracketed control flow} with regard to those maps.


\section{Enforcement}
\label{sec:enforcement}

In this section we are going to see how an existing enforcement mechanism,
Depth Isolation from \citet{DBLP:conf/sp/RoesslerD18}, can implement
the formal stack safety property described in the previous section: it in
fact enforces a stronger, inductive version of it that strengthens the
local state encapsulation component by checking for integrity and
confidentiality violations at every step of the callee's execution trace.

\paragraph*{Micropolicies}
%
The enforcement policy of \citeauthor{DBLP:conf/sp/RoesslerD18} relies
on programmable, tag-based reference monitor that runs alongside the
program.  To control this monitor, they use a programming model that
allows fine-grained manipulation of metadata tags to encode so-called
\emph{micropolicies}~\citep{pump_oakland15}.

In such a system, all memory addresses and registers (including the
program counter) are enriched with an abstract metadata tag, which can
point to the representation of an arbitrary data structure. A
micropolicy is thus defined by a collection of rules to be checked as
each instruction executes and together define the transfer function of
the security policy. Each rule inspects the tags associated to the
inputs of an instruction (PC, registers, memory) as well as the
instruction opcode itself, and produces one of two outcomes: either
the instruction is allowed to execute (and generates and assigns tags
for the new PC and the result of the operation), or the machine
fail-stops with a policy violation.

Efficient execution of these micropolicies relies on hardware
implementations, such as the PUMP architecture~\citep{pump_oakland15},
which include a monitor rule cache that maps tag inputs to outputs and
a mechanism to trap misses to software handlers and thereby compute
the transfer function of the software-defined policy.  Previous work
has shown that a wide range of micropolicies can be defined and
enforced efficiently \rb{cite}.
%
\rb{Maybe go into more detail, examples later\ldots or try to segue into stack
policies}

\paragraph*{A conservative policy}
%
The first micropolicy we present to enforce the definition of stack
safety developed in \cref{sec:lse-and-wbcf} is \leo{a small variation
  of?}  the Depth Isolation policy presented by
\citet{DBLP:conf/sp/RoesslerD18}. Their policy tags the stack memory
with ownership information associated to each stack frame (and to each
separate object inside that frames, a more finely grained access
control that we do not need to consider here), and registers holding
stack pointers with matching access permission information. Beyond
those capabilities, the compiler generates designated sequences of
instructions with special tags that grant them permission to manage
the stack, say during calls and returns. \rb{Conceivably on alloc
  operations, etc., which we have not yet mentioned.}

Our micropolicy works as follows. We assume for ease of exposition that no
arguments are passed on the stack \rb{Come back to this later?}. Initially, the
entire stack is tagged as unused with an $\tagNoDepth$ tag \rb{actually, the
``initial frame'' should be tagged with its proper depth}, and the {\PCname}
carries in its tag at all times the depth of the current activation, starting
with a $\tagPCDepth{0}$ tag. The current activation depth needs to change
exactly at those points in the program where the contour of the stack safety
property changes:

\begin{itemize}

\item From caller to callee, when the machine executes an instruction tagged
  with $\tagCall$ as belonging to the call map. At this point, the current
  {\PCname} depth $n$ is incremented to $\tagPCDepth{n + 1}$; on function entry,
  the locations of the new frame is marked $\tagStackDepth{n + 1}$.

\item From callee back to caller, when execution reaches the corresponding
  return instruction for the call instruction, as defined by
  $\ret{\mach_c}\ \mach_r$. At this point, the {\PCname} tag is decremented.
  Prior to this point, the locations of the old frame have been restored to
  $\tagNoDepth$.

\end{itemize}

To enforce this discipline, we define blessed header and return instruction
sequences. These are specific sequences of tagged instructions that are intended
to appear at the beginning and end of each function:

\[
  \begin{array}{c|c|c}
    {\sw ~ \rsp ~ \rra ~ 1} & {\tagHa, \tagInstr} & \text{Store RA in stack} \\
    {\addi ~ \rsp ~ \rsp ~ 2} & {\tagHb, \tagInstr} & \text{Increment SP by frame size}
  \end{array}
  \]

\[
  \begin{array}{c|c|c}
    {\lw ~ \rra ~ \rsp ~ -1} & {\tagRa, \tagInstr} & \text{Load RA} \\
    {\addi ~ \rsp ~ \rsp ~ -2} & {\tagRb, \tagInstr} & \text{Decrement SP by frame size} \\
    {\jalr ~ \rra ~ \rra} & {\tagRc, \tagInstr} & \text{Jump back}
  \end{array}
\]

\rb{Positioning of the above sequences, relation to running example. The tagging
  of stack frames would be considered part of these sequences.}

These sequences also enforce the $\SP$ discipline. When stack frames
are of fixed size, it suffices to increment $\SP$ and tag it with a
dedicated tag in the header sequence, which is later checked after
decrementing $\SP$ during the exit sequence to authorize the
return. The well-formedness of the blessed sequences can be checked
statically. Only programs whose sequences are well-formed are
protected by the micropolicy, although programs are still protected
(by fail-stopping) even if the intended sequences are missing. By
tracking the execution of the blessed sequences in the tag state of
the {\PCname} register, the micropolicy ensures that the entry
sequences of calls declared in the call map are executed correctly.

% If anything overwrites the SP in between, the exit sequence will fail, which is safe.

During normal execution, the {\PCname} uses the current activation
depth in its tag $\tagPCDepth{n}$ to gate load and store operations,
which are allowed to operate only on the corresponding stack frame,
tagged $\tagStackDepth{n}$.  \rb{Note that we have also considered and
  implemented more flexible schemes based on allowing operations above
  the current activation depth. How do we put these together?}  \rb{Do
  we want to discuss variations involving frame pointers or more
  implicit return addresses?}  \rb{Where to talk about the role of the
  compiler?}

%% Because the access rights of callers subsume those of callees, it is essential
%% that the micropolicy change tags when the property thinks that a call occurs,
%% but it is safe for the micropolicy to fail to reset to the caller's tag when the
%% property thinks a return occurs. (Dually, it is safe for the micropolicy to
%% change tags even without executing a call point, but not for it to reset tags to
%% the caller when the property thinks execution is still in the caller).

%% Because the property does not identify return sites, we have no way to require
%% that ``intended returns'' are tagged correspondingly. Some unintended results
%% might also be so tagged, but as long as the jump has the effect of a legal
%% return, it is OK.

\paragraph*{Strong Stack Safety}
%
This conservative policy does not only satisfy the stack safety above,
but also a provably stronger one, which at each step of the
computation performs integrity and confidentiality tests for a stack
of running variants, which are kept in lockstep with the original
machine.

\definition
  Given two machine states $\mach$ and $\mach'$ and a contour $\contour$, these
  satisfy the \emph{stack integrity test} if their high-integrity components
  match:
  \[
    \mathit{int}_T ~ \contour ~ \mach ~ \mach' \triangleq
    \forall \component . ~
    \contour(\component) = \HIGHINT \rightarrow
    \mach(\component) = \mach'(\component)
  \]

\definition
  Given two machine states $\mach_1$ and $\mach_2$ with stepping machine states
  and observations $\mach_1 \stepstoobs{\obs_1} \mach_1'$ and $\mach_2
  \stepstoobs{\obs_2} \mach_2'$, all these satisfy the \emph{stack
    confidentiality test} if their observations and changed components coincide:
  \[
    \mathit{conf}_T ~ \mach_1 ~ \mach_2 ~ \obs_1 ~ \obs_2 ~ \mach_1' ~ \mach_2' ~ \triangleq
    \obs_1 = \obs_2 \wedge \forall \component . ~
   (     \mach_1(\component) \neq \mach_1'(\component)
    \vee \mach_2(\component) \neq \mach_2'(\component))
    \rightarrow \mach_1'(\component) = \mach_2'(\component)
  \]
\apt{scoping of $\forall$ is ambiguous.}
\rb{Fix notations, including for properties below.
  In particular, note that the last four arguments could be computed from the
  first two and it may be clearer to elide them.}
\newcommand{\vse}{\mathit{vse}}
\newcommand{\VSES}{\mathit{VSE}}
\newcommand{\vs}{\mathit{vs}}
\newcommand{\VSS}{\mathit{VS}}

\newcommand*{\vm}[1]{\ensuremath{\mathit{vm}_{#1}}}

\definition The testing property keeps track of relevant information
on a {\em variant stack}: a list of machine states, each element of
which (denoted $\vm{C}$) of which is a variation of the actual machine
according to a contour $C$.
%
\footnote{The full formal definition in Coq also records additional
  information (the initial machine state at the call, its initial
  variation, the contour, and a return predicate) which we elide
  here for simplicity of exposition.}
%%
%  $$\vse \in \VSES ::= \MACHS \times \MACHS \times \MACHS \times \CONTOURS \times \RETMAPS$$
%  $$\vse = (\mathit{init\_machine}(\vse), \mathit{init\_variant}(\vse), \mathit{curr\_variant}(\vse), \contour(\vse), \mathit{ret}(\vse))$$
%  $$\vs \in \VSS$$
%%
\iflater
\leo{This can be elided}
  Given a machine state $\mach$, a stack $\vs$ is \emph{well-formed} with
  respect to it if the stack is nonempty, the return map of the bottom element
  is the false property, and for each element $\vse \in \vs$:
  \begin{itemize}
  \item $\mathit{curr\_variant}(\vse)$ is a variant of $\mach$.
  \item $\mach$ is in the trace $\machT$ of its initial machine,
    $\mathit{init\_machine}(\vse) \hookrightarrow \machT$.
  \item Its variant state $\mathit{curr\_variant}(\vse)$
    is in the trace of its initial variant,
    $\mathit{init\_variant}(\vse) \hookrightarrow \machT$.
  \item The return function is in the return map if not the last element. \rb{TODO}
  \item The registers of its contour $\contour(\vse)$ are public.
  \end{itemize}
  \fi
  
\definition
%
  Our testing property extends the basic tests above to whole variant
  stacks.  Given a machine that steps $(\mach, \pol) \hookrightarrow_P
  (\mach', \pol', \obs)$, say that a variant stack $\vs$ \iflater that
  is well-formed with respect to $\mach$\fi safisfies the
  \emph{variant stack test} if for each variant element $\vm{C}$
  (which is a variation of $\mach$ for $C$), $\vm{C}$ can take a step,
  denoted $\vm{C} \stepstoobs{\obs} \mach'$, while
  satisfying the stack integrity test $\mathit{int}_T ~ C
  ~ \mach ~ \mach'$ and stack confidentiality test $\mathit{conf}_T ~
  \mach ~ \mach'$ with regard to the original machine state. We write
  this $\mathit{\vs}_T ~ (\mach, \pol) ~ \vs$.

\definition{Eager testing property}
  Let $\callmap$ a call map and $\codemap$ a function map. Given a state
  $(\mach, \pol) \in \MPS$ that is well-formed w.r.t. a variant stack $\vs$, we
  say that an MP-trace induced from $(\mach, \pol)$ satisfies the \emph{eager
  testing property} at a given call depth as follows.
% Refactor repetitive notation before case split
  In all cases that assume a machine step, $(\mach, \pol) \hookrightarrow_P
  (\mach', \pol', \obs)$, assume also (unless the step is a return) that the
  variant stack can step, $\vs \hookrightarrow \vs'$, i.e., all its variant
  machines can step.

%  Let $\callmap$ a call map and $\codemap$ a code map. Given a state $(\mach,
%  \pol) \in \MPS$ that is well-formed w.r.t. a variant stack $\vs$ and induces
%  an MP-trace $(\mach, \pol) \hookrightarrow \MPT$, we say that the \emph{stack
%  testing property} is satisfied at call depth $d$, and write
%  $\mathit{stack}_T ~ d ~ \MPT ~ \vs$, as follows:

  \begin{itemize}

  \item If the machine \emph{fail-stops}, i.e., $(\mach, \pol) \hookrightarrow_P
    (\mach, \pol, \tau)$, the property is safisfied for the singleton trace:
    $\mathit{stack}_T ~ d ~ [(\mach, \pol)] ~ \vs$, for any $d$ up to the size of
    $\vs$. (That is, a violation was detected $d$ levels into the stack.
    Elements are created and pushed to the variant stack on calls and popped
    from it on returns, so its size always reflects the depth of the program
    stack.)

  \item If the top variant of the stack (and only the top variant) returns,
    i.e., $\mathit{ret}(\head(\vs), \mach)$ holds, the property is safisfied for
    the singleton trace $[(\mach, \pol)]$ at depth equal to the size of the
    stack: $\mathit{stack}_T ~ |\vs| ~ [(\mach, \pol)] ~ \vs$. \rb{Explain the
    use of this vs the return case below.}

  \item If
%
    (1) the machine takes a \emph{non-call, non-return step},
%
    (2) the variant stack test $\mathit{\vs}_T ~ (\mach, \pol) ~ \vs$ is
    satisfied, and
%
    (3) the stack safety test $\mathit{stack}_T ~ d ~ ((\mach', \pol') : \MPT) ~
    \vs'$ is coinductively satisfied % at depth $d$
    %% and for a trace starting continuing after the step, $\head(\MPT) = (\mach',
    %% \pol')$,
%
    {\em then} we conclude $\mathit{stack}_T ~ d ~ ((\mach, \pol) : (\mach',
    \pol') : \MPT) ~ vs$.
    %% \rb{omitting stack size condition}

  \item
%
    If (1) the machine takes a \emph{call step} and $\contour$ is the contour at
    the call,
%
    (2) the variant stack test $\mathit{\vs}_T ~ (\mach, \pol) ~ \vs$ is
    satisfied,
%
    (3) the stack integrity test $\mathit{int}_T ~ \contour ~ \mach ~ \mach'$ is
    satisfied and the stack confidentiality test $\mathit{conf}_T ~ \mach ~
    \vm{\contour}$ is satisfied with regard to an arbitrary $\contour$-variant
    of $\mach$,
%
    and (4) the stack safety test $\mathit{stack}_T ~ d ~ ((\mach', \pol') :
    \MPT) ~ (\vm{\contour} : \vs')$ is coinductively satisfied, for an arbitrary
    $\contour$-variant of the machine,
%
    {\em then} we conclude $\mathit{stack}_T ~ d ~ ((\mach, \pol) : (\mach',
    \pol') : \MPT) ~ vs$.

    %% the contour $\contour$ is updated based on the top of the current machine.
    %% For the property to hold for a trace $(\mach, \pol) \cdot \MPT$ at depth $d$
    %% the eager integrity test must hold for $\contour$ at the call,
    %% the eager confidentiality test must hold for all variants at the call,
    %% including the new variant that is added to the top of the stack,
    %% and the property recurses on an arbitrary variant at the new contour
    %% at depth $d$ with trace $\MPT$.

  \item
%
    If (1) the machine takes a \emph{return step} at the top of the variant
    stack (and only the top variant),
%
    (2) the variant stack test $\mathit{\vs}_T ~ (\mach, \pol) ~ \vs$ is
    satisfied,
%
    (3) the stack safety test $\mathit{stack}_T ~ d ~ ((\mach', \pol') : \MPT) ~
    \mathit{tail}(\vs)$ is coinductively satisfied
%
    {\em then} we conclude $\mathit{stack}_T ~ d ~ ((\mach, \pol) : (\mach',
    \pol') : \MPT) ~ vs$.

  \item If the machine takes \emph{simultaneous return-call step}, that is, the
    instruction to which execution returns immediately after completing a call
    is itself a call instruction, the \emph{call step} and \emph{return step}
    cases are combined.

  \end{itemize}

\definition{Top-level stack testing property}
%
  \ldots wrap the coinductive stack testing property

By using property-based testing techniques, we can determine with a high degree
of confidence that an implementation of the conservative micropolicy satisfies
this eager testing property. Although we have not proved that the conservative
policy guarantees the stack safety property, the testing property is provably
stronger than the stack safety property \rb{theorem?} and, by this implication,
we can conclude that the conservative policy also enforces stack safety.

% The properties we give are indeed enforceable.

\rb{What is the strongest property enforced by the conservative policy?}

\paragraph*{End-to-end stack safety property}

Integrity

Confidentiality as a form of noninterference

\paragraph*{Eager vs lazy testing}

The conservative policy we just described, while testable and enforceable, is
too slow to be of practical use. What we want, instead, is a somewhat more
permissive policy that moreover can be efficiently implemented. Most of the
performance overhead incurred by this kind of \emph{eager policy} steps from the
need to set stack activation tags as a frame is created and reset them as it is
destructed, as \citet{DBLP:conf/sp/RoesslerD18} confirm in their evaluation. To
mitigate those costs, they propose optimizations like Lazy Tagging and Lazy
Clearing that relax and defer some of the checks of an eager policy, being more
permissive in their allowed operations and catching violations if and when their
effect becomes manifest.
\rb{How much detail to go into? Refer to examples if we have the space?}

These \emph{lazy policies} admit more efficient implementations while being
harder to test, given that potential violations may or may not materialize,
requiring in turn additional bookkeeping. However, a critical observation is
that the depth-based tagging scheme discussed so far with fail when combined
with a lazy policy. The reason for this is that because tags are not set and
cleared on function entry and exit points, stale tags may persist after a given
call, and a subsequent call sharing the same depth as the old call may access
memory contents tagged with the stale tags of a previous activation.
\rb{Again, example?}

The lazy policy can be repaired if, instead of tagging each function activation
with its depth in the stack, we generate a fresh activation identifier on each
call, which allows the policy to identify stale tags from previous activations.
Under this stricted tagging discipline, the eager policy behaves almost exactly
like its lazy counterpart. A related mechanism was explored in the Static
Authorities policy of \citet{DBLP:conf/sp/RoesslerD18}, which associates a
unique activation identifier to each function, which is however shared by all
activations of the same function in order to obtain good cacheability of tag
rules.

\rb{Parts of this discussion feel somewhat out of order...}

\rb{We can also test the lazy policy, even if less efficiently, and it should
  enforce an inductive property, which may be more amenable to proving --- this
  should be the connection to the following section.}

\rb{Implied by the property we started with?}

\rb{Explain and compare what each policy enforces.}

\section{Lazy Stack Safety}
\label{sec:lazy}

    \rb{Suggestion: name this ``observable \emph{trace? something else?}
      integrity'' to avoid confusion with observable stack integrity (in fact,
      it is called exactly this when discussing the example below). The rollback
      may also be a definition of its own to match the granularity of
      definitions in previous sections.}

    \sna{Use the \(n\)-transition language above in all of these.}

    \paragraph{Rolling Back to Idealized State}
      Observable integrity will weaken eager integrity by allowing a returned
      state to differ from its call state at high integrity components,
      provided the observable behavior of the induced trace from the return
      matches that of an idealized state whose high integrity components do
      match the call state.

      Given a contour, a call state, and a returned state, we define a
      ``rollback'' function \(\mathit{roll} : \CONTOURS \times \MACHS \times
      \MACHS \rightarrow \MACHS\). The rollback returns a state that matches
      the call state on those components that are high integrity in its
      contour, and matches the return state on low integrity components:
      \[\mathit{roll}(\contour,\mach_c,\mach_r)(\component) =
      \begin{cases}
        \mach_c(\component) & \contour(\component) = (\HIGHINT,\_) \\
        \mach_r(\component) & \contour(\component) = (\LOWINT,\_) \\
      \end{cases}\]

      If \(\mach_e\) is an entry to a call with contour \(\contour\) and
      \(\mach_r\) its return, \(\mathit{roll}(\contour,\mach_e,\mach_r)\)
      agrees with \(\mach_e\) on every component the callee should not change,
      but with \(\mach_r\) on those components that it is permitted to change.
      So the observable behavior that follows is the idealized behavior to
      which we compare the trace from \(\mach_r\), which must prefix it (to
      account for premature halts due to policy violations.)

      Now we can define a version of trace integrity that compares the trace
      from a returned state to that from its idealized counterpart.

    \definition{Observable Trace Integrity}

      An MP-Trace enjoys {\em observable trace integrity} with respect to
      some contour \(\contour\) if its final state (if any) has observable
      behavior that prefixes that of its idealized version, constructed by
      \(\mathit{roll}\):

      \[\begin{split}
        \text{\sc ObsInt}_\contour ~ \MPT \triangleq
        & \mpostate{\mach_e}{\pol_e}{\obs_e} = \head(\MPT) \\
        & \mpostate{\mach_r}{\pol_r}{\obs_r} = \last(\MPT) \Rightarrow \\
        & \mpstate{\mach_r}{\pol_r} \hookrightarrow_P \MPT' \Rightarrow \\
        & \mathit{roll}(\contour,\mach_e,\mach_r) \hookrightarrow \machT'
          \Rightarrow \\
        & \pi_o(\MPT') \lesssim_O \pi_o(\machT')
      \end{split}\]

    \begin{figure}
      \integritylazyexample
      \caption{Rolling back from Figure \ref{fig:intex}}
      \label{fig:intlex}
    \end{figure}

    For out example, we return to the violation of trace integrity in
    \cref{fig:intex}, in which {\tt h} has written to {\tt z} and returned.
    Whether observable integrity holds depends on the continuing trace, shown
    in \cref{fig:intlex}. Above, we have the final state of \(\MPT\),
    \(\mach_r\), and the rolled-back state, \(\mach_r' =
    \mathit{roll}(\contour,\mach_e,\mach_r)\), in which high integrity
    components are restored to their values as of \(\mach_e\). Specifically,
    address 103 is restored to 0. When instruction 31 prints {\tt z} in the
    trace from \(\mach_r\), it prints 18, but in the trace from \(\mach_r'\)
    it prints 0. So observable trace integrity does not hold.

    However, if {\tt g} had an additional instruction to overwrite {\tt z}
    before printing, observable trace integrity would hold.

    \definition{Observable Stack Integrity}

      A system enjoys {\em observable stack integrity} with regard to
      \(\callmap\) and \(\codemap\) if for any initial state \(\mach_0\) and
      each transition with entry state \(\mpostate{\mach_e}{\pol_e}{\obs_e}\)
      and contour \(\contour\) in the induced trace from
      \(\mpstate{\mach_0}{\mathit{pinit}(\mach_0)}\), if
      \(\mpstate{\mach_e}{\pol_e} \hookrightarrow_P \MPT | \ret{\mach_e}\),
      then \(\text{\sc ObsInt}_\contour ~ \MPT\).

    \paragraph{Restoring Varied States}

      Trace confidentiality is a property of two traces whose initial machine
      states are variations, with two sub-properties. First, the behavioral
      condition -- that their observable behaviors prior to the end of the
      trace are equivalent -- reflects the intuition that secret values should
      not influence visible behavior. Second, we have the end condition that
      their final states (if any) are equal up to the original variation. The
      end condition over-approximates the extension of the behavioral condition
      to future execution.

      We introduce {\em observable trace confidentiality}, which extends the
      behavioral condition to apply to execution from the final state on.
      This requires restoring varied components to their original values,
      since after return they will once again be accessible legitimately.

      To return to the example in \cref{fig:confex}, the varied final state
      \(\mach_r'\) might do anything depending on the values of the variation,
      so we cannot immediately compare traces from \(\mach_r\) and
      \(\mach_r'\). We must first restore the varied values to their original
      state, while preserving differences that have occurred during
      execution.
      \rb{To me, this reads like a prologue to the definitions properly
        speaking---maybe the definition header above should be a paragraph and
        a definition header appear next? I would also split it into two
        definitions.}
      \sna{Definitely better as a prologue. Where would you split it?}

%      In \cref{fig:lazyex1}, the final states of the original and variant
%      differ, because a written value (in black or white) depended on the value
%      of a high confidentiality location. So the resulting trace fails trace
%      confidentiality. For observable trace confidentiality, we ask whether the
%      differing values at address 42 cause any observable distinctions in
%      future behavior. To do so, we must undo the variation of formerly high
%      confidentiality locations, so that those in yellow match those in red,
%      while preserving the updated values where data may have been leaked.

      The \(\mathit{restore}\) function takes a contour and four states: the
      original call state, a variant call state, and corresponding return
      states, and returns another state. The resulting state restores those
      components that are high confidentiality to match the original call,
      unless they were changed during execution:
      \[\mathit{restore}(\contour,\mach_e,\mach_e',\mach_r,\mach_r')
        (\component) =
        \begin{cases}
          \mach_c(\component) & \text{if } \contour(\component) = (\HIGHSEC,\_)
            \text{ and } \\
          & \mach_e(\component) = \mach_r(\component) \text{ and }
            \mach_e'(\component) = \mach_r'(\component) \\
          \mach_r'(\component) & \text{else} \\
        \end{cases}\]

      Now we can describe a trace property that extends trace confidentiality.

    \definition{Observable Trace Confidentiality}

      A pair of traces \(\MPT\) and \(\machT\) starting from
      \(\mpstate{\mach_e}{\pol_e}\) and \(\mach_e'\), respectively, with
      \(\mach_e \approx_\contour \mach_e'\), enjoy observable trace
      confidentiality with respect to \(\contour\) if two conditions hold:

      The two traces are observationally equivalent: \(\pi_o(\MPT) \eqsim
      \pi_o(\machT)\).

      If \(\MPT\) is finite and ends with the state
      \(\mpostate{\mach_r}{\pol_r}{\obs_r}\), then \(\machT\) is finite. Let
      \(\mach_r' = \last(\machT)\). Then the induced traces
      \(\mpstate{\mach_r}{\pol_r} \hookrightarrow_P \MPT'\) and
      \(\mathit{restore}(\contour,\mach_e,\mach_e',\mach_r,\mach_r')
      \hookrightarrow \machT'\) are observationally prefixed,
      \(\pi_o(\MPT') \lesssim \pi_o(\machT')\).

      We write this \(\text{\sc ObsConf}_\contour ~ \MPT ~ \machT\).

      \begin{figure}
        \confidentialitylazyexample
        \caption{Continuing from \cref{fig:confex}}
        \label{fig:conflex}
      \end{figure}

      In our example, \cref{fig:conflex} shows how execution continues from
      \(\mach_r'\) and the restored \(\mach_r'' = \mathit{restore}(\contour,
      \mach_e,\mach_e',\mach_r,\mach_r')\). Addresses 108 and 109, in \tainted,
      are not restored; every address that was varied and not changed in one
      of the executions is. So 108 contains 43 in the trace from \(\mach_r\),
      and after returning from {\tt g}, {\tt main} prints 85. But in the trace
      from \(\mach_r''\), 108 contains -4, and ultimately 38 is printed.
      So observable trace confidentiality does not hold. This example
      illustrates the weakness of observable confidentiality as a testing
      property; it takes until the very end of the program to determine whether
      a tainted value actually influences observable behavior.

    \definition{Observable Stack Confidentiality}

      From observable trace confidentiality we construct {\em observable stack
      confidentiality}. A system enjoys {\em observable stack confidentiality}
      with regard to \(\callmap\) and \(\codemap\) if for any initial state
      \(\mach_0\) and each transition with entry state
      \(\mpostate{\mach_e}{\pol_e}{\obs_e}\) and contour \(\contour\) in the
      induced trace from \(\mpstate{\mach_0}{\mathit{pinit}(\mach_0)}\), if
      \(\mpstate{\mach_e}{\pol_e} \hookrightarrow \MPT | \ret{\mach_e}\),
      then \(\text{\sc ObsConf}_\contour ~ \MPT ~ \machT\).

    \definition{Observable Stack Safety}
      A system enjoys {\em observable stack safety} with regard to a call map
      and a function map if it enjoys both observable stack integrity and
      observable stack confidentiality with regard to them.

\section{Related Work}
\label{sec:relwork}

CHERI \rb{cite}

\citet{Skorstengaard+19b} introduce a calling convention to preserve local state
encapsulation and well-bracketed control flow by the use of local capabilities.
Although the required hardware support is readily available in capability
machines like CHERI, this technique incurs potentially prohibitive performance
costs, because it requires the unused part of the stack to be cleared whenever a
security boundary is crossed. In the discussion, ``while [the authors] claim
that [their] calling convention enforces control-flow correctness, [they] do not
prove a general theorem that shows this, because it is not clear what such a
theorem should look like,'' noting that the correctness property enjoyed by
their technique ``is not made very explicit.''

StkTokens \citep{Skorstengaard+19} protects the stack by enforcing local state
encapsulation and well-bracketed control flow. It does so by defining a calling
convention that makes use of linear capabilities for stack and return pointers
operating on a single shared stack, and by requiring that protected components
avoid compromising their own security by following certain simple rules.
Informally, local state encapsulation is defined by restricting accesses to the
range of memory allocated to the current stack frame, and well-bracketed control
flow by only allowing returns from the topmost frame to the immediately adjacent
frame below. Formally, it improves on \citet{Skorstengaard+19b} by building
those properties into the semantics of a capability machine with a built-in call
stack and call and return instructions, which is proven fully abstract with
respect to a more concrete capability machine that replaces those
pseudo-instructions with their calling convention.

We are confident \rb{how strong a claim to make, with substantiation} that
StkTokens satisfies the eager stack safety property, and even the stronger eager
testing property \rb{refs}. The main limitation of StkTokens is its reliance on
linear capabilities, as it is unclear now they could be added to practical
capability machines, especially in terms of efficiency.
%
\rb{On the other hand, we know that these can be implemented as micropolicies,
  cf. linear return capabilities in yannis-report (what about performance?)}

\rb{There are quite a few parallels at various levels, although the definitions
  are overall more implicit and not given formally.}

\section{Future Work}
  \label{sec:future}

  We have presented a pure notion of stack safety that omits many complicating
  factors common to real system. In particular, our model as presented exploits
  the simplifying assumption that privilege never increases during a function
  call, and that therefore a contour computed once on the entry to a function
  describes its privilege throughout. Our future plans are to extend the model
  with common language features, some of which violate this assumption. Here we
  describe the basic principles by which our model can be extended to some of
  these cases.

  \paragraph{Stack-derived Pointers}

    Common programming idioms involve a caller passing a pointer to its local
    data into a callee. Using standard notions of pointer provenance [cite],
    we can extend our model to distinguish safe use of this idiom from true
    stack safety violations. We require additional annotation to identify
    which addresses within a function's stack frame correspond to distinct
    objects. Then a valid pointer to an object is one derived through legal
    arithmetic from its base address, and at each call point, an object's
    addresses are marked low confidentiality and integrity if a valid pointer
    exists in a register or in the transitive closure of the callee's
    accessible memory. All pointers to an object cease to be valid when it is
    deallocated along with its stack frame.

  \paragraph{Adding Heap Safety}

    Heap safety, like stack safety, may be framed as a form of noninterference
    [cite Meaning of Memory Safety]. The above model describing safety of
    shared stack-allocated objects extends naturally to heap safety,
    complicated by the fact that these objects are not deallocated by returns,
    and therefore a function's privilege may increase or decrease after its
    entry point. For instance, if a callee allocates a heap object and returns
    the pointer to its caller, that object's addresses become accessible in
    contradiction to a contour computed at the caller's entry. So such an
    extension must enforce trace confidentiality and integrity properties
    separately on continuous segments of each call, with contours computed at
    each crossing between caller and callee.

  \paragraph{Non-stack control flow}

    Control structures beyond well-bracketed calls and returns require
    modifications to the model. Tail calls, for instance, reuse the caller's
    stack frame for its callee, and every nested tail call returns
    simultaneously to the top non-tail-calling function. Under normal stack
    integrity, the first function in a chain of tail calls returns and violates
    integrity, while subsequent tail calls never actually return at all.
    Instead we need a variant that treats the entry of a tail call as the
    return of its caller for purposes.

    More complex is the addition of a coroutine model, in which multiple stacks
    respect stack safety internally, but might also yield to one another.
    Here we must distinguish three levels of integrity: accessible, in the same
    stack, and in another stack. Stack integrity requires that same-stack data
    be unchanged when a function returns, but other-stack data may change. A
    similar {\em yield integrity} property requires that, from a yield out of
    a coroutine to the next yield back into it, all accessible and same-stack
    data are unchanged. Confidentiality properties are split similarly.


\section{Discussion}

\rb{Notes from meeting:
  \begin{itemize}
  \item Explain how the theory applies to production compilers like GCC and
    LLVM, which aspects are directly applicable, what are the effects of
    alternative calling conventions. Other less charted waters: tail calls,
    coroutines, jumps into supervisor mode.
  \item CHERI and its operation, documentation and practical configurations and
    operation.
  \item Compare and contrast with StkTokens.
  \item Under what circumstances can stack safety exist without an enforcement
    mechanism?
  \item Zeroing out of allocated space inside blessed sequences, eager vs lazy.
    Possibility of blessed alloc and dealloc sequences, which also manipulate SP
    and would not be legal without blessing. In such an extended setting, the
    return sequence would check for matching addresses (it would be nice to have
    testing for this!).
  \end{itemize}
}

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bcp.bib,local.bib}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots

\end{document}
