%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[10pt,conference]{ieeetran}%\settopmatter{printfolios=true,printccs=false,printacmref=false}

\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{amsmath,amsthm,amssymb}

\usepackage[table]{xcolor}

\usepackage{threeparttable}

\usepackage{wasysym}

\usepackage{listings}

\usepackage{tikz}

\usepackage{array,multirow}

\usepackage{stmaryrd}

\usepackage[noadjust]{cite}

\usepackage[multiple]{footmisc}

\usepackage[hyphens]{url}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\input{macros}

\makeatletter
\newcommand{\linebreakand}{%
  \end{@IEEEauthorhalign}
  \hfill\mbox{}\par
  \mbox{}\hfill\begin{@IEEEauthorhalign}
}
\makeatother

\begin{document}

%% Title information
\title{Formalizing Stack Safety as a Security Property}

\author{
  \IEEEauthorblockN{
    Sean Noble Anderson
  }
  \IEEEauthorblockA{
    Portland State University\\
    ander28@pdx.edu\\
  }
  \and
  \IEEEauthorblockN{
    Leonidas Lampropoulos
  }
  \IEEEauthorblockA{
    University of Maryland, College Park\\
    leonidas@umd.edu\\
  }
  \and
  \IEEEauthorblockN{
    Roberto Blanco
  }
  \IEEEauthorblockA{
    Max Planck Institute for Security and Privacy\\
    roberto.blanco@mpi-sp.org\\
  }
  \linebreakand
  \IEEEauthorblockN{
    Benjamin C. Pierce
  }
  \IEEEauthorblockA{
    University of Pennsylvania\\
    bcpierce@cis.upenn.edu\\
   }
  \and
  \IEEEauthorblockN{
    Andrew Tolmach
  }
  \IEEEauthorblockA{
    Portland State University\\
    tolmach@pdx.edu\\
  }
}

%% Keywords
%% comma separated list
\ifcameraready
\keywords{Stack Safety, Micro-Policies}  %% \keywords are mandatory in final camera-ready submission
\fi

\maketitle

\begin{abstract}

The term {\em stack safety} is associated with a
variety of compiler, run-time, and hardware mechanisms for protecting stack
memory. But, unlike ``the heap,'' the stack does not correspond to a single
high-level language concept. Rather, it corresponds to the fundamental
abstraction of functions, in all of the forms that they can take.
The protean nature of the functional abstraction makes stack safety
difficult to specify.

We propose a formal characterization of stack safety based on
concepts from language-based security. Stack safety is decomposed
into an integrity property and a confidentiality property for each
of the caller and the callee, as well as a control-flow property.

Our motivating enforcement mechanism,
the ``lazy'' stack safety micro-policies proposed by
Roessler and DeHon~\cite{DBLP:conf/sp/RoesslerD18}, permit functions
to write into one another's frames, but taint the result so that the frame's
owner cannot access it. No existing characterization of stack safety
captures this style of safety. We capture it by defining the properties in
terms of the observable behavior of the system.

The stack interacts with a large number of language features that are often excluded
from discussion of stack safety. Our properties support a system with
both caller- and callee-saved registers, arguments passed on the stack,
tail-call elimination, \ifexceptions exceptions \fi. They are modular by
design, in order to be further extensible to other features.

We validate our properties by using them to distinguish correct implementations
of Roessler and DeHon's micro-policies from incorrect ones
via property-based random testing. Our testing successfully detects violations
in several broken variants, including Roessler and DeHon's original lazy policy.
A fixed version of the policy does pass our tests.

\end{abstract}

\newcommand{\paragraphx}[1]{\emph{#1.}}

\section{Introduction}
\label{sec:intro}

\input{intro-v2}

\section{Key Ideas}
\label{sec:ideas}

\input{ideas-v1}

\section{Properties by Example}
\label{sec:example}

In this section we introduce our security property definitions by means
of small code examples, using a simplified set of security-relevent operations for
or calls, returns, and private allocations.
% In this system a value is a pair of a
%word (the ``payload'') and a tag drawn from some set \(\mathcal{T}\).
%\(\mathcal{V} ::= \mathcal{W} \times \mathcal{T}\),
%for some type  of tags to be elaborated later, with \(|(w,t)| = w\).
Figure \ref{fig:main} gives C code and corresponding compiled 64-bit RISC-V code
for a function {\tt main}, which  
takes an argument {\tt secret} and initializes a local variable {\tt sensitive} to contain
potentially sensitive data. 
Then {\tt main} calls another function {\tt f},
and afterward performs a test on {\tt sensitive} to decide whether
to output {\tt secret}.  Since {\tt sensitive} is initialized to 0,
the test should fail, and {\tt main} should instead output the return value of {\tt f}.
Output is performed by writing to the special global {\tt out},
and we assume that such writes are the only observable events in the system.

The C code is compiled using the standard RISC-V calling conventions~\cite{RISC-V-CC}.
In particular, the first function argument and the function
return value are both passed in {\tt a0}.  
Memory is byte-addressed and the stack grows towards
lower addresses. We assume that {\tt main} begins at address 0 and its callee {\tt f} at address 100.

\begin{figure}
  \begin{subfigure}{\columnwidth}
    {\tt
      volatile int out;

      void main(int secret) \{

      ~ ~ int sensitive = 0;

      ~ ~ int res = f();

      ~ ~ if (sensitive == 42)

      ~ ~ ~ ~ out = secret;

      ~ ~ else

      ~ ~ ~ ~ out = res;

      \}}
  \end{subfigure}
  \begin{subfigure}{\columnwidth}
    \begin{tabular}{r l | l}
      \labeledrow{0:}{addi sp,sp,-20}{\(\mathbf{alloc} ~ (-20,20)\)}
      \labeledrow{4:}{sd ra,12(sp)}{}
      \labeledrow{8:}{sw a0,8(sp)}{}
      \labeledrow{12:}{sw zero,4(sp)}{}
      \labeledrow{16:}{jal f,ra}{\(\mathbf{call} ~ \emplist \)}
      \labeledrow{20:}{sw a0,0(sp)}{}
      \labeledrow{24:}{lw a4,4(sp)}{}
      \labeledrow{28:}{li a5,42}{}
      \labeledrow{32:}{bne a4,a5,L1}{}
      \labeledrow{36:}{lw a0,8(sp)}{}
      \labeledrow{40:}{sw a0,out}{}
      \labeledrow{44:}{j L2:}{}
      \labeledrow{L1, 48:}{lw a0,0(sp)}{}
      \labeledrow{52:}{sw a0,out}{}
      \labeledrow{L2, 56:}{ld ra,12(sp)}{}
      \labeledrow{60:}{addi sp,sp,20}{\(\mathbf{dealloc} ~ (0,20)\)}
      \labeledrow{64:}{jalr ra}{\(\mathbf{return}\)}
    \end{tabular}
  \end{subfigure}
  \begin{subfigure}{\columnwidth}
    \includegraphics[width=\columnwidth]{stacklayout.png}
  \end{subfigure}

\caption{Example: {\tt main}\apt{Needs machine-set diagram.}}
\label{fig:main}
\end{figure}

%Figure \ref{fig:RISCVregs} gives an example division of the RISC-V registers into
%security classes.  APT: Don't think we need this figure.

We now consider how {\tt f} might misbehave and violate desirable
stack safety properties associated with {\tt main}. To put the violations in a
security framework, suppose that {\tt f} is actually an attacker seeking
to leak {\tt secret}. It might do so in a number of ways, shown as snippets of
assembly code in Figure \ref{fig:f}.
%
Leakage is most obviously viewed as a violation of {\tt main}'s {\it confidentiality}.
In Figure \ref{subfig:direct}, {\tt f} takes an offset from the stack
pointer, accesses {\tt secret}, and directly outputs it. But more
subtly, even if somehow prevented from outputting {\tt secret} directly, {\tt f}
can instead return that value so that {\tt main} stores it to {\tt out},
as in Figure \ref{subfig:indirect}.
%
Beyond simply reading {\tt secret}, the attacker might overwrite {\tt sensitive}
with 42, guaranteeing that {\tt main} publishes its own secret unintentionally
(Figure \ref{subfig:integrity}).
Attacks of this kind do not violate {\tt main}'s confidentiality, but
rather its {\it integrity}.
In Figure \ref{subfig:WBCF}, the attacker arranges to return to the
wrong instruction, thereby bypassing the check and publishing {\tt secret} regardless,
violating the program's {\it well-bracketed control flow} (WBCF.)
%
In Figure \ref{subfig:WBCF2}, a different attack violates WBCF, this time
by returning to the correct program counter but with the wrong stack pointer.
\footnote{We pad the last two variants with {\tt nop}s just so that all the
snippets have the same length, which simplifies some later explanations.}

\begin{figure}
  \begin{subfigure}[b]{\columnwidth}
    \vspace{\abovedisplayskip}
    \begin{tabular}{r l | l}
      \labeledrow{100:}{lw a4,8(sp)}{}
      \labeledrow{104:}{sw a4,out}{}
      \labeledrow{108:}{li a0,1}{}
      \labeledrow{112:}{jalr ra}{\(\mathbf{return}\)}
    \end{tabular}
    \caption{Leaking {\tt secret} directly}
    \label{subfig:direct}
  \end{subfigure}
  \begin{subfigure}[b]{\columnwidth}
    \vspace{\abovedisplayskip}
    \begin{tabular}{r l | l}
      \labeledrow{100:}{lw a4,8(sp)}{}
      \labeledrow{104:}{mov a4,a0}{}
      \labeledrow{108:}{sw zero,-4(sp)}{}
      \labeledrow{112:}{jalr ra}{\(\mathbf{return}\)}
    \end{tabular}
    \caption{Leaking {\tt secret} indirectly}
    \label{subfig:indirect}
  \end{subfigure}
  \begin{subfigure}[b]{\columnwidth}
    \vspace{\abovedisplayskip}
    \begin{tabular}{r l | l}
      \labeledrow{100:}{li a5,42}{}
      \labeledrow{104:}{sw a5,4(sp)}{}
      \labeledrow{108:}{li a0,1}{}
      \labeledrow{112:}{jalr ra}{\(\mathbf{return}\)}
    \end{tabular}
    \subcaption{Attacking {\tt sensitive}}
    \label{subfig:integrity}
  \end{subfigure}
  \begin{subfigure}[b]{\columnwidth}
    \vspace{\abovedisplayskip}
    \begin{tabular}{r l | l}
      \labeledrow{100:}{addi ra,ra,16}{}
      \labeledrow{104:}{nop}{}
      \labeledrow{108:}{nop}{}
      \labeledrow{112:}{jalr ra}{\(\mathbf{return}\)}
    \end{tabular}
    \subcaption{Attacking control flow}
    \label{subfig:WBCF}
  \end{subfigure}
  \begin{subfigure}[b]{\columnwidth}
    \vspace{\abovedisplayskip}
    \begin{tabular}{r l | l}
      \labeledrow{100:}{addi sp,sp,8}{}
      \labeledrow{104:}{nop}{}
      \labeledrow{108:}{nop}{}
      \labeledrow{112:}{jalr ra}{\(\mathbf{return}\)}
    \end{tabular}
    \subcaption{Attacking stack pointer integrity}
    \label{subfig:WBCF2}
  \end{subfigure}

  \caption{Example: assembly code alternatives for {\tt f} as an attacker.
  }
  \label{fig:f}
\end{figure}

The security semantics for this program is based
on the security-relevant events noted in the right columns of Figures~\ref{fig:main}
and~\ref{fig:f}, namely execution of instructions that allocate or deallocate space,
make a call, or make a return.

Our security semantics attach a security context to the machine state,
which consists of a view \(V\) and a stack \(\sigma\) of pending activations' views.
Figure \ref{fig:exec1} shows how the security context evolves over the first few
steps of the program.  (The formal details of the security semantics are described in
\cref{sec:machine}, and the context evolution rules are formalized in \cref{fig:basicops}.)
Execution begins at the start of {\tt main}, where the program counter (\(\PCname\)) is zero,
and with the stack pointer (\(\SP\)) at address 1000.
State transitions are numbered and labeled with a list of security operations, written
\(\downarrow \overline{\psi}\) between steps.

The initial view \(V_0\) maps all stack addresses below \(\SP\) to \(\unsealed\) and the remainder of
memory to \(\public\). The sole used argument register, {\tt a0}, is mapped to \(\object\);
other caller-save registers are mapped to \(\unsealed\) and callee-save registers to \(\sealed\). 
Step 1 allocates a word each for {\tt secret}, {\tt sensitive}, and {\tt res}, as well
as two words for the return address. This has the
effect of marking those bytes \(\object\). 
(We use \(V\llbracket\cdot\rrbracket\) to denote updates to \(V\).)
%

\newcommand{\freebox}{\tikz \filldraw[fill=blue] (0,0) rectangle (10px,10px);}
\newcommand{\pubbox}{\tikz \filldraw[fill=lightgray] (0,0) rectangle (10px,10px);}
\newcommand{\objbox}{\tikz \filldraw[fill=yellow] (0,0) rectangle (10px,10px);}
\newcommand{\sealbox}{\tikz \filldraw[fill=red] (0,0) rectangle (10px,10px);}

\begin{figure*}
  \begin{tabular}{|r|r||l|r}
    \cline{1-3}
    \(\PCname\) & \(\SP\) & Context &
    \multirow{3}{*}{\(\underbrace{\dots \freebox \freebox \freebox \freebox \freebox
        \freebox \freebox \freebox \freebox \freebox}_\unsealed
      \! \underbrace{\stackrel{\stackrel{\SP}{\downarrow}}{\pubbox} \!\! \pubbox \pubbox \dots}_\public
      ~ \stackrel{\mathtt{a0}}{\pubbox\pubbox} ~ \stackrel{\mathtt{a1}}{\freebox\freebox}
%      ~ \stackrel{\mathtt{s0}}{\sealbox}
      \)} \\
    \cline{1-3}
    0 & 1000 & \(V_0, \emplist\)
    \\
    \cline{1-3}
    \multicolumn{3}{l}{\multirow{2}{*}{\(1 \Big\downarrow [\mathbf{alloc} ~ (-20,20)]\)}} & \\
    \multicolumn{3}{l}{} &
    \multirow{3}{*}{\(\underbrace{\dots \freebox \freebox \freebox \freebox \freebox}_\unsealed
      \! \underbrace{\stackrel{\stackrel{\SP}{\downarrow}}{\objbox} \!\! \objbox \objbox \objbox \objbox}_\object
      \! \underbrace{\pubbox \pubbox \pubbox \dots}_\public
      ~ \stackrel{\mathtt{a0}}{\pubbox\pubbox} ~ \stackrel{\mathtt{a1}}{\freebox\freebox}
%      ~ \stackrel{\mathtt{s0}}{\sealbox}
      \)}
    \\
    \cline{1-3}
    4 & 980 & \(V_1 = V_0 \llbracket 980..999 \mapsto \object\rrbracket, \emplist\) &
    \\
    \cline{1-3}
    \multicolumn{3}{l}{\multirow{2}{*}{2-4 \(\Big\downarrow \emplist\)}} \\ \multicolumn{3}{l}{} \\
    \cline{1-3}
    16 & 980 & \(V_1, \emplist\) & \\
    \cline{1-3}
    \multicolumn{3}{l}{\multirow{2}{*}{\(5 \Big\downarrow [\mathbf{call} ~ 100 ~ \emplist]\)}} & \\
    \multicolumn{3}{l}{} &
    \multirow{3}{*}{\(\underbrace{\dots \freebox \freebox \freebox \freebox \freebox}_\unsealed
      \! \underbrace{\stackrel{\stackrel{\SP}{\downarrow}}{\sealbox} \!\! \sealbox \sealbox \sealbox \sealbox}_\sealed
      \! \underbrace{\pubbox \pubbox \pubbox \dots}_\public
      ~ \stackrel{\mathtt{a0}}{\freebox\freebox} ~ \stackrel{\mathtt{a1}}{\freebox\freebox}
%      ~ \stackrel{\mathtt{s0}}{\sealbox}
      \)}
    \\
    \cline{1-3}
    100 & 980 & \(V_2 = V_1 \llbracket 980..999 \mapsto \sealed, \mathtt{a0} \mapsto \unsealed\rrbracket,[V_1]\) & \\
    \cline{1-3}
    \multicolumn{3}{l}{\multirow{2}{*}{6-8 \(\Big\downarrow \emplist\)}} \\ \multicolumn{3}{l}{} \\
    \cline{1-3}
    112 & 980 & \(V_2,[V_1]\) \\
    \cline{1-3}
    \multicolumn{3}{l}{\multirow{2}{*}{\(9 \Big\downarrow [\mathbf{return}]\)}} & \\
    \multicolumn{3}{l}{} & \multirow{3}{*}{\(\underbrace{\dots \freebox \freebox \freebox \freebox \freebox}_\unsealed
      \! \underbrace{\stackrel{\stackrel{\SP}{\downarrow}}{\objbox} \!\! \objbox \objbox \objbox \objbox}_\object
      \! \underbrace{\pubbox \pubbox \pubbox \dots}_\public
      ~ \stackrel{\mathtt{a0}}{\pubbox\pubbox} ~ \stackrel{\mathtt{a1}}{\freebox\freebox}
 %     ~ \stackrel{\mathtt{s0}}{\sealbox}
      \)}
    \\
    \cline{1-3}
    20 & 980  & \(V_1, \emplist\) &
    \\
    \cline{1-3}
    \multicolumn{2}{l}{} \\
  \end{tabular}
  \caption{Execution of example up through the return from {\tt f}. In right-hand diagram, addresses increase to the right and
  boxes represent 4-byte words.}
\label{fig:exec1}
\end{figure*}
%
At step 5, the current principal's record is pushed onto the inactive list.
Its return target is the return address of the call,
and the stack pointer target is the stack pointer at the moment of call.
The callee's view is updated from the caller's such that all \(\object\) memory locations
become \(\sealed\). (For now we assume no sharing of memory between activations; data is
passed only through argument registers, which remain active. In the presence of memory
sharing, some memory would remain active, too.)

\apt{needs review}
{\tt f} does not take any arguments; if it did, any registers containing them would be 
mapped to \(\object\), while any non-argument, caller-saved
registers are mapped to \(\unsealed\). All callee-save registers remain \(\sealed\) for all calls.
At step 9, {\tt f} returns, and the topmost inactive view, that of {\tt main}, is restored.

We now show how this security semantics can be used define notions of confidentiality,
integrity, and correct control flow in such a way that many classes of
bad behavior, including the attacks in Figure~\ref{fig:f}, are
detected as security violations.

\paragraph*{Well-bracketed Control Flow}

To begin with, what if {\tt f} returns to an unexpected place (i.e. \(\PCname \neq 20\) or
\(\SP \neq 980\))? We consider this to violate \(\wbcf\). \(\wbcf\) is a relationship between
call steps and their corresponding return steps: just after the return, the program
counter should be at the next instruction following the call,
and the stack pointer should be the same as it was before the call.
Both of these are essential. In Figure \ref{subfig:WBCF}, the attacker adds
16 to the return address and then returns, thus bypassing the {\tt if}-test in the code and outputting
{\tt secret}.
In Figure \ref{subfig:WBCF2}, the attacker returns with \(\SP' = 998\) instead of the
correct \(\SP = 980\). In this scenario, given the layout of {\tt main}'s frame,
\begin{center}
\begin{tabular}{| l | l | l | l | l |}
  \multicolumn{1}{r}{\(\SP \downarrow\)} &
  \multicolumn{2}{r}{\(\SP' \downarrow\)} \\
  \hline
  res & sens & sec & ra & ra \\
  \hline
\end{tabular}
\end{center}

\vspace{\abovedisplayskip}

\noindent
{\tt main}'s attempt to read {\tt sensitive} will instead
read part of the return address, and its attempt to output
{\tt res} will instead output {\tt secret}.

Before the call, the program counter is 16 and the stack pointer is 980.
So we define a predicate on states that should hold just after the return:
\(\ret\ \mach \triangleq \mach[\PCname] = 20 \wedge \mach[\SP] = 980\).
%
We can identify the point just after the return (if a return occurs)
as the first state in which the pending call stack is smaller than it was
just after the call.
WBCF requires that if \(\mach\) is the state at that point, then \(\ret ~ \mach\) holds.
%For nested calls, where the pending stack is initially larger, the same principle
%applies: \(\ret ~ \mach\) must hold the next time the pending stack is the same size or smaller.

% Even absent other
% kinds of data protection, the stack pointer {\it must} be restored
% for the program to behave predictably.

\paragraph*{Stack Integrity}

Like WBCF, stack integrity defines a condition at the call that must hold upon
return. This time the condition applies to all of the memory in the function's 
frame. In Figure \ref{fig:exec1} we see the lifecycle of an allocated frame:
upon allocation, the view labels it \(\object\), and when a call is made, it instead
becomes \(\sealed\). Intuitively, the integrity of {\tt main}
is preserved if, when control returns to it, any \(\sealed\) elements
are identical to when it made the call.
%
Again, we need to know when a caller has been returned to,
and we use the same mechanism of checking the depth of the call stack.
%
In the case of the call from {\tt main} to {\tt f}, the \(\sealed\) elements are the
addresses 980 through 999 and callee-saved registers such as
the stack pointer. Note that callee-saved registers often change
during the call---but if the caller accesses them after the call, it should find them
restored to their prior value.

While it would be simple to define integrity as ``all sealed elements retain their
values after the call,'' this would be stricter than necessary. Suppose that
a callee overwrites some data of its caller, but the caller never accesses that data
(or only does so after re-initializing it.) This would be harmless, with the callee
essentially using the caller's memory as scratch space, but the caller never seeing any change.

For a set of elements \(\components\),
a pair of states \(\mach\) and \(\nach\) are {\em \(\components\)-variants} if
their values an only disagree on elements in \(\components\).
We say that the elements of \(\components\) are \emph{irrelevant}
in \(\mach\) if they can be replaced by arbitrary other values without changing the
observable behavior of the machine. All other elements are \emph{relevant}.

(This story is slightly over-simplified. If an enforcement mechanism maintains
additional state associated with elements, such as tags, we don't want that
state to vary; only the payloads should. Formal definitions of variants and
relevance that incorporate this wrinkle are given in \cref{sec:props}.)

We define \emph{caller integrity} (\(\clri\))  as the property that
every relevant element that is \(\sealed\) under the callee's view is restored
to its original value at the return point.

\begin{figure}
  \includegraphics[width=\columnwidth]{variants.png}
  \caption{Integrity Violation\apt{Needs a machine-drawn version, as do the rest. Use colors consistently. No tags!}}
  \label{fig:variant}
\end{figure}

In our example setting, the observation trace consists of the sequence
of values written to {\tt out}.
The example in Figure \ref{subfig:integrity} modifies the value of {\tt sensitive},
which is \(\sealed\). Figure \ref{fig:variant} shows the state just after the call at step 5,
assuming that {\tt sec} is 5. Similar to WBCF, we define
\(\intProp\) as a predicate on states that holds if
all relevant sealed addresses in \(\mach\) are the same as after step 5.
We require that \(\intProp\) hold on the state following the matching return,
which is reached by step 9. Here {\tt sensitive} has obviously changed, but is it relevant?
Consider a variant state in which {\tt sensitive} has any other value, arbitrarily
choosing 43. As execution continues after the return
from the original state, it passes the {\tt if}-test on {\tt sensitive}, whereas the execution
from the variant does not, resulting in differing outputs. Therefore {\tt sensitive} \emph{is} relevant,
so \(\intProp\) does not hold, and integrity has indeed been violated.

\paragraph*{Caller Confidentiality}

We treat confidentiality as a form of non-interference as well: the confidentiality of a caller
means that its callee's behavior is dependent only on publicly visible data,
not the caller's private state. This also requires that the callee initialize
memory before reading it.
As we saw in the examples, we must consider both the observable events
that the callee produces during the call and the changes that the callee makes to the state that might
affect the caller after the callee returns.

Consider the state \(\mach\) after step 5, whose context is \((V_2,\sigma)\), with the attacker from
Figure \ref{subfig:direct}. We take a variant state over the set of element(s) that are
\(\sealed\) in \(V_2\) (see Figure \ref{fig:variant2}.)
            [TODO: fix figure to avoid varying the entire stack.]
If we take a trace of execution from each state until it returns,
the traces may differ, in this case outputting 5 (the original value of {\tt secret}) and
4 (its value in the variant) respectively. This is a violation of
{\it internal confidentiality} (formalized in \cref{tab:props}, line 3a).

\begin{figure}
  \includegraphics[width=\columnwidth]{variants2.png}
  \caption{Internal Confidentiality Violation}
  \label{fig:variant2}
\end{figure}

But, in Figure \ref{subfig:indirect}, we also saw an attacker that exfiltrated the secret
by reading it and then returning it, in a context where the caller would output the returned
value. Figure \ref{fig:variant3} shows the behavior of the same variants under this attacker,
but in this case, there is no output during the call. Instead the value of {\tt secret} is
extracted and placed in {\tt a0}, the return value register. We wish to identify this as
a confidentiality violation, again by considering variants of the \(\sealed\)
elements in \(V_2\), but capturing the required property is subtle.

To illustrate the issues, note that {\tt f} has also stores a 0 below the stack pointer.
%
\begin{figure}
  \includegraphics[width=\columnwidth]{variants3.png}
  \caption{Return-time Confidentiality Violation}
  \label{fig:variant3}
\end{figure}
%
Now consider three elements: the address \(\SP - 4\), the address \(\SP + 12\),
and the register {\tt a0}. The execution from the right-hand state to its return
has changed the value at \(\SP - 4\), but that value matches that of the
left-hand variant at its return. Therefore, the change does not represent a leak.

The return states disagree on the value of \(\SP + 12\). But in neither
case has that value changed since the original variants. So the difference is inherited from
the original variation, and does not represent a leak either. We do not continue executing the
variant state after return, so these values will not cause the caller to behave differently.

But in the case of {\tt a0}, the value has changed during the call (in both the original
and the variant, although only one of these would be necessary), and its final value
differs between the variants.
Therefore, it must depend on a secret (in fact, the variable {\tt secret}).
Unless {\tt a0} happens to be irrelevant to the caller, this is a violation of what
we term {\it return-time confidentiality} (formalized in \cref{tab:props}, line 3b).

Structurally, return-time confidentiality resembles integrity, but now dealing with
variants. We begin with a state immediately following
a call, \(\mach\). We consider an arbitrary variant state,
\(\nach\), which may vary any element that is \(\sealed\) or \(\unsealed\),
i.e., any element that is not used legitimately to pass arguments. Caller confidentiality
therefore can be thought of as the callee's insensitivity to elements in its initial state
that are not part of the caller-callee interface.

We define a binary relation \(\confProp\) on pairs of states,
which holds on eventual return states \(\mach'\) and \(\nach'\)
if all relevant elements are {\em uncorrupted} relative to \(\mach\) and \(\nach\).
An element is {\em corrupted} if it differs between \(\mach'\) and \(\nach'\),
and it either changed between \(\mach\) and \(\mach'\) or between \(\nach\) and \(\nach'\).

Finally, we define \emph{caller confidentiality} (\(\clrc\)) as the
combination of internal and return-time confidentiality (\cref{tab:props}, line 3).

\paragraph*{The Callee's Perspective}

We presented our initial example from the perspective of the caller, but a callee
may also have privilege that its caller lacks, and which must be protected from the
caller. Consider a function that makes a privileged system call to obtain a secret key,
and uses that key to perform a specific task. An untrustworthy or erroneous caller might
attempt to read the key out of the callee's memory after return, or to influence the callee
to cause it to misuse the key itself!

Where the caller's confidentiality and integrity are concerned with protecting specific,
identifiable state---the caller's stack frame---their callee equivalents are concerned
with enforcing the expected interface between caller and callee. Communication between
the principals should occur only through the state elements that are designated for the
purpose: those which we label \(\public\) and (in the presence of memory sharing) \(\object\).

Applying this intuition using our framework, \(\clec\) turns out to resemble
\(\clri\), extended to every element that is not marked \(\object\) at call-time. The callee's
internal behavior is represented by those elements that change over the course of its
execution, and which are not part of the interface with the caller. At return, those
elements should become irrelevant.

Similarly, in \(\clei\), only elements marked \(\object\) at the call should influence the
behavior of the callee. This is the same principle as \(\clrc\), extended from \(\sealed\)
elements to all non-\(\object\) ones.

\section{Machine and Security Semantics, Formally}
\label{sec:machine}

% APT: I don't think we need this.
%% \begin{figure}
%%   \begin{tabular}{| l | l | l |}
%%     \hline
%%     Set / & Names & Purpose \\
%%     Class & & \\
%%     \hline
%%     \(\mathit{CLR}\) / & {\tt t0} -- {\tt t6} & Caller-saved temps \\
%%     \(\unsealed\) & {\tt a0} -- {\tt a1} & Caller-saved args / return vals \\
%%     & {\tt a2} -- {\tt a7} & Caller-saved args \\
%%     & {\tt ra} & Return Address \\
%%     \hline
%%     \(\mathit{CLE}\) / & {\tt s0} -- {\tt s11} & Callee-saved \\
%%     \(\sealed\) & {\tt sp} & Stack Pointer \\
%%     \hline
%%     \(\mathit{PUBLIC}\) / & {\tt gp} & Global Pointer  \\
%%     \(\public\) & {\tt tp} & Thread Pointer \\
%%     \hline
%%   \end{tabular}
%%   \caption{RISC-V integer register set}
%%   \label{fig:RISCVregs}
%% \end{figure}

The building blocks of a machine are {\em words} and {\em registers}.
Words are ranged over by \(\word\) and, when used as addresses, \(\addr\),
and are drawn from the set \(\WORDS\).
Registers in the set \(\REGS\) are ranged over by \(\reg\), with the stack pointer
given the special name \(\SP\);
some registers may be classified as caller-saved or callee-saved.
Along with the program counter, \(\PCname\), these are referred to as
{\em state elements} \(\component\) in the set \(\COMPONENTS ::= \PCname | \WORDS | \REGS\).

A {\em machine state} \(\mach \in \MACHS\) is a map from state elements to a set \(\mathcal{V}\) of
\emph{values},  with a step function \(\mach \xrightarrow{\bar{\psi},\obs} \mach'\).
Each value \(v\) contains a \emph{payload} word, written \(|v|\).
The details of value structure depend on the specific machine being modelled;
intuitively, the payload represents the part of the value that is relevant to
the behavior of the basic machine, while the rest of the value may contain
information relevant to a hardware enforcement mechanism (such as a tag).
We write \(\mach[\component]\) to denote the value of \(\mach\) at
\(\component\)  and \(\mach[v]\) as shorthand for \(\mach[|v|]\).

Security classes are ranged over by \(l \in \{\public, \object, \sealed, \unsealed\}\).
For some security class \(l\), we write \(l(V)\)
to denote the set of elements \(\component\) such that \(V ~ \component = l\).
The {\it initial view} \(V_0\) maps all stack locations to \(\unsealed\),
all other locations to \(\public\), and registers based on which set they
belong to: \(\sealed\) for callee-saved, \(\unsealed\) for caller-saved, and \(\public\) otherwise.

A {\it context} is a pair of the current activation's view and
a list of views representing the call stack (pending inactive
principals), ranged over by \(\sigma\).

A view \(V\) maps elements to security classes, and a context consists of the
view of the active function together with a stack of inactive views.
The initial context is \(\context_0 = (V_0, \emplist)\).
%
\[\context \in \CONTEXTS ::= \mathit{VIEW \times list ~ VIEW}\]
%
We have described informally how the security context develops as the system performs
security-relevant operations. Formally, we combine each machine state with a context
to create a {\it combined state} \(s = (\mach,\context)\) and a lift the transition
to \(\stepstounder{}\) on combined states, labeled with the same operations.
with each step, the context updates based on the function
\(Op : \MACHS \rightarrow \CONTEXTS \rightarrow \psi \rightarrow \CONTEXTS\).
Note that \(Op\) takes as its first argument the state {\it before} the step.
Since a single step might correspond to multiple operations, we apply
\(Op\) as many times as is needed.

\judgmenttwo{\(\mach \xrightarrow{\overline{\psi},\obs} \mach' \)}
            {\(\mathit{foldl} ~ (Op ~ \mach) ~ \context ~ \overline{\psi} = \context'\)}
            {\((\mach,\context) \stepstounder{\overline{\psi},\obs} (\mach', \context')\)}

The definition of \(Op\) is most convenient to present decomposed into
rules for each operation. We have already seen the intuition behind the rules for
\(\mathbf{alloc}\), \(\mathbf{call}\), and \(\mathbf{ret}\).
For the machine described in the example, the \(Op\) rules would be those
found in \cref{fig:basicops}.

\begin{figure}
    \[\mathit{range} ~ \reg ~ \mathit{off} ~ \mathit{sz} ~ \mach \triangleq
    \{\mach[\reg]+i | \mathit{off} \leq i < \mathit{off+sz}\}\]

  \judgmentbr{\(\components = \mathit{range} ~ \SP ~ \mathit{off} ~ \mathit{sz} ~ \mach \cap
    \{\addr \mid V ~ \addr = \unsealed\}\)}
             {\(V' = V \llbracket \addr \mapsto \sealed \mid \addr \in \components \rrbracket\)}
             {\(Op ~ \mach ~ (\mathbf{alloc} ~ \mathit{off, sz}) ~ (V,\sigma) = (V',\sigma)\)}
    %
    \judgmentbr{\(b = \mach[\SP] + \mathit{off}\)}
               {\(V' = V \llbracket \addr \mapsto \unsealed |
                 b \leq a < b+\mathit{sz} \land V ~ \addr = \object \rrbracket\)}
               {\(Op ~ \mach ~ (\mathbf{dealloc} ~ \mathit{off, sz}) ~ (V,\sigma) = (V',\sigma)\)}
    %
    \judgmentbr{\(V' = V \llbracket \reg \mapsto \unsealed | \reg \in \mathit{CLR} \rrbracket
                 \llbracket \reg \mapsto \public | \reg \in \overline{\reg_{args}} \rrbracket\)}
               {\(V'' = V'\llbracket \addr \mapsto \sealed | V' ~ \addr = \object \rrbracket\)}
               {\(Op ~ \mach ~ (\mathbf{call} ~ \addr_{target} ~ \overline{\reg_{args}})
                 ~ (V,\sigma) = (V'',V::\sigma)\)}
    %
    \judgment{\(\sigma = (V,\addr_{ret},\addr_{sp})::\sigma'\)}
             {\(Op ~ \mach ~ \mathbf{return} ~ (\_, \sigma) = (V, \sigma')\)}
  \caption{Basic Operations}
  \label{fig:basicops}
\end{figure}

\subsection{Events and Traces}
\label{sec:events}

We abstract over the events that can be observed in the system, defining them
only as a set \(\OBSS\) that contains at least the element \(\tau\), the silent
event. Other events might represent certain function calls (i.e., system calls)
or writes to special addresses representing mmapped regions.
A {\em trace} is a nonempty, finite or infinite sequence
of events, ranged over by \(\obsT\).
We use ``\(\notfinished{}{}\)'' to represent ``cons'' for traces, reserving ``::''
for list-cons.

We write the trace of execution from a state up to the first
state below depth \(d\) via the \(\hookrightarrow\) operator, defined coinductively.
When \(d = 0\), the trace will always be infinite. In this case we
omit \(d\) and just write \(\hookrightarrow s\).

\judgment{\(|\sigma| < d\)}
         {\(d \hookrightarrow (\mach,(V,\sigma)) = \tau\)}

\judgmentthree{\((\mach,(V,\sigma)) \stepstounder{} (\mach',\context',\obs)\)}
              {\(|\sigma| \geq d\)}
              {\(d \hookrightarrow (\mach',\context') = \obsT\)}
              {\(d \hookrightarrow (\mach,(V,\sigma)) = \notfinished{\obs}{\obsT}\)}


Two event traces $\obsT_1$ and $\obsT_2$ are {\em similar},
written \(\obsT_1 \eqsim \obsT_2\), if the sequence of non-silent events
is the same. That is, we compare up to deletion of \(\tau\) events.

\begin{minipage}{.4\columnwidth}
  \judgment{}{\(\obsT \eqsim \obsT\)}
\end{minipage}
\begin{minipage}{.4\columnwidth}
  \judgment{\(\obsT_1 \eqsim \obsT_2\)}
           {\(\notfinished{\obs}{\obsT_1} \eqsim \notfinished{\obs}{\obsT_2}\)}
\end{minipage}

\begin{minipage}{.4\columnwidth}
  \judgment{\(\obsT_1 \eqsim \obsT_2\)}
           {\(\notfinished{\tau}{\obsT_1} \eqsim \obsT_2\)}
\end{minipage}
\begin{minipage}{.4\columnwidth}
  \judgment{\(\obsT_1 \eqsim \obsT_2\)}
           {\(\obsT_1 \eqsim \notfinished{\tau}{\obsT_2}\)}
\end{minipage}

\section{Formal properties}
\label{sec:props}

Now we are ready to introduce the formal properties that define correctly enforced
security semantics. First, we must give a few prelimaries: the generation and comparison
of traces, variant states, and ``on-return'' assertions.

For a given system, we assume a \emph{compatibility} equivalence relation \(\sim\) on values.
Values are compatible if their tags (or whatever other data is important to
the machine's security enforcement mechanism) are identical,
even though their payloads may differ.
Two states are variants with respect to a set of elements \(\components\)
if they agree on the value of every element not in \(\components\) and
and have compatible values for every element in \(\components\).
Our notion of non-interference involves comparing the traces of such
\(\components\)-variants. We use this to define sets of irrelevant elements,
and secrets in general.

\definition Machine states \(\mach\) and \(\nach\) are {\em \(\components\)-variants},
written \(\mach \approx_\components \nach\), if, for
all \(\component \not \in \components\), \(\mach[\component] = \nach[\component]\)
and for all \(\component \in \components\), \(\mach[\component] \sim \nach[\component]\).

\definition An element set \(\components\) in state \((\mach,\context)\) contains
irrelevant values, written \((\mach,\context) \parallel \components\), if for all
\(\nach\) such that \(\mach \approx_{\components} \nach\),
\(\hookrightarrow (\mach,\context)  \eqsim \hookrightarrow (\nach,\context)\).

\definition \(\Delta(\mach,\mach')\) is the set of elements \(\component\)
such that \(\mach[\component] \not = \mach'[\component]\).

\definition The {\em corrupted set} \(\bar{\Diamond}(\mach,\mach',\nach,\nach')\)
is the set \((\Delta(\mach,\mach') \cup \Delta(\nach,\nach')) \cap \Delta(\mach',\nach')\).

Conceptually, the corrupted set treats \(\mach\) and \(\nach\) as initial states whose
and \(\mach'\) and \(\nach'\) as their corresponding final states, such that any element
that has changed from its initial value but does not match between the final states
is considered to have propagated some varied data from the original pair.

Our ``on-return'' assertions are defined using a second-order logical operator
\(d \uparrow P\), pronounced ``\(P\) holds on return from depth \(d\),''
where \(P\) is a predicate on machine states. This is a coinductive relation
similar to ``weak until'' in temporal logic---it also holds if the program never
returns from depth \(d\).

\judgmenttwo[Returned]
            {\(|\sigma| < d\)}
            {\(P ~ \mach\)}
            {\((d \uparrow P) ~ (\mach, (V,\sigma))\)}

\judgmenttwobrlong[Step]
                  {\(|\sigma| \geq d\)}
                  {\((d \uparrow P) ~ (\mach', \context')\)}
                  {\((\mach, (V,\sigma)) \stepstounder{\overline{\psi}} (\mach', \context',\obs)\)}
                  {\((d \uparrow P) ~ (\mach, (V,\sigma))\)}

Similarly, we give a binary equivalent for use in confidentiality. We define \(\Uparrow\) so that
\((\mach,\context) ~ (d \Uparrow R) ~ (\mach',\context')\) holds if \(R\) holds on the
first states that return from depth \(d\) after \((\mach,\context)\) and \((\mach',\context')\),
respectively. Once again, \(\Uparrow\) is coinductive.

\judgmentthree[Returned]
              {\(|\sigma_1| < d\)}
              {\(|\sigma_2| < d\)}
              {\(\mach_1 ~ R ~ \mach_2\)}
              {\((\mach_1,(V_1,\sigma_1)) ~ (d \Uparrow R) ~ (\mach_2,(V_2,\sigma_2))\)}

\judgmenttwobrlong[Left]
                  {\(|\sigma_1| \geq d\)}
                  {\((\mach_1,(V_1,\sigma_1)) \stepstounder{\overline{\psi}} (\mach_1',\context_1',\obs)\)}
                  {\((\mach_1',\context_1') ~ (d \Uparrow R) ~ (\mach_2,(V_2,\sigma_2))\)}
                  {\((\mach_1,(V_1,\sigma_1)) ~ (d \Uparrow R) ~ (\mach_2,(V_2,\sigma_2))\)}

\judgmenttwobrlong[Right]
                  {\(|\sigma_2| \geq d\)}
                  {\((\mach_2,(V_2,\sigma_2)) \stepstounder{\overline{\psi}} (\mach_2',\context_2',\obs)\)}
                  {\((\mach_1,(V_1,\sigma_1)) ~ (d \Uparrow R) ~ (\mach_2,\context_2')\)}
                  {\((\mach_1,(V_1,\sigma_1)) ~ (d \Uparrow R) ~ (\mach_2,(V_2,\sigma_2))\)}

Finally, we can define our core properties. They can be found in \cref{tab:props},
arranged to show their commonalities and distinctions. Each definition gives a criterion
quantified over states \(s\) that immediately follow call (or tail-call) steps.
If an execution can reach a state \(s'\) such that \(s' \stepstounder{\overline{\psi}} s\)
where \(\mathbf{call} ~ \addr ~ \overline{\reg} \in \bar{\psi}\), then \(s\) is the target
of a call. Likewise, if \(\mathbf{tailcall} ~ \addr ~ \overline{\reg} \in \bar{\psi}\), then
\(s\) is the target of a tailcall. As a shorthand, we write that each property is defined
by a criterion that must hold ``for all (tail)call targets \(s\).''

\(\wbcf\), \(\clri\), and \(\clec\) are each straightforward: they define predicates that must
hold on return from the call. \(\clrc\) and \(\clei\) both compare the execution of the
call state with that of a variant state, and are concerned with both their internal and
their return-time behavior. So, for some \(\nach\) that is an appropriate variant,
all states must fulfill an ``internal'' clause that their traces are similar,
and a ``return-time'' clause, that any potentially corrupted memory at their returns
is irrelevant.

\begin{table*}[h]
  \setlength{\tabcolsep}{1pt}
  \center
  \begin{tabular}{l r l l l}
    \rowcolor{black!20}
    1
    & \(\wbcf \triangleq\) & \(|\sigma| \uparrow \ret\)
    & \(\textnormal{ where } \ret ~ \mach' \triangleq \)
    \(\mach'[\SP] = \mach[\SP] \land \mach'[\PCname] = \mach[\PCname]+4\)
%    & \(\textnormal{ when } (\mach,(V,\sigma)) \textnormal{ is called}\) \\
    & \(\textnormal{ for all call targets } (\mach,(V,\sigma))\) \\
    %
    \rowcolor{black!10}
    2
    & \(\clri \triangleq\) & \((|\sigma| \uparrow \intProp) ~ (\mach,(V,\sigma))\)
    & \(\textnormal{ where } \intProp ~ \mach' \triangleq 
    \mach' \parallel \sealed(V) \cap \Delta(\mach,\mach')\)
%    & \(\textnormal{ when } (\mach,(V,\sigma)) \textnormal{ is called}\) \\
    & \(\textnormal{ for all call targets } (\mach,(V,\sigma))\) \\
    %
    \rowcolor{black!20}
    3
    & \(\clrc \triangleq\) & \(\forall \nach \textnormal{ s.t. } \mach \approx_{\components} \nach,\)
    & \(\textnormal{ where } \components = \sealed(V)\)
%    & \(\textnormal{ when } (\mach,(V,\sigma)) \textnormal{ is (tail)called}\) \\
    & \(\textnormal{ for all (tail)call targets } (\mach,(V,\sigma))\) \\
    \rowcolor{black!20}
    3a & & \(|\sigma| \hookrightarrow (\mach,(V,\sigma)) \simeq |\sigma| \hookrightarrow (\nach,(V,\sigma))\) & & \\
    \rowcolor{black!20}
    3b & & \(\textnormal{ and } (\mach,(V,\sigma)) ~ (|\sigma| \Uparrow \confProp) ~ (\nach,(V,\sigma))\)
    & \(\textnormal{ where } (\mach' ~ \confProp ~ \nach') \triangleq 
    \mach' \parallel \bar{\Diamond}(\mach,\nach,\mach',\nach')\) & \\
    %
    \rowcolor{black!10}
    4
    & \(\clec \triangleq\) & \((|\sigma| \uparrow \cconfProp) ~ (\mach,(V,\sigma))\)
    & \(\textnormal{ where } \cconfProp ~ \mach' \triangleq
    \mach' \parallel \Delta(\mach,\mach') - \components\)
%    & \(\textnormal{ when } (\mach,(V,\sigma)) \textnormal{ is (tail)called}\) \\
    & \(\textnormal{ for all (tail)call targets } (\mach,(V,\sigma))\) \\
    \rowcolor{black!10}
    & & & \(\textnormal{ where } \components = \public(V) \cup \object(V)\) & \\
    %
    \rowcolor{black!20}
    5
    & \(\clei \triangleq\) & \(\forall \nach \textnormal{ s.t. } \mach \approx_{\components} \nach,\)
    & \(\textnormal{ where } \components = \public(V) \cup \object(V)\)
%    & \(\textnormal{ when } (\mach,(V,\sigma)) \textnormal{ is (tail)called}\) \\
    & \(\textnormal{ for all (tail)call targets } (\mach,(V,\sigma))\) \\
   \rowcolor{black!20}
    5a & & \(|\sigma| \hookrightarrow (\mach,(V,\sigma)) \simeq |\sigma| \hookrightarrow (\nach,(V,\sigma))\) & & \\
    \rowcolor{black!20}
    5b & & \(\textnormal{ and } (\mach,(V,\sigma)) ~ (|\sigma| \Uparrow \cintProp) ~ (\nach,(V,\sigma))\)
    & \(\textnormal{ where } (\mach' ~ \cintProp ~ \nach') \triangleq
    \mach' \parallel \bar{\Diamond}(\mach,\nach,\mach',\nach')\) & \\
  \end{tabular}
  \caption{Properties}
  \label{tab:props}
\end{table*}

\section{Expanding the Machine}

The system we've modeled so far has been very simple, but our properties
support an important dimension of generality: adding features. We now
briefly introduce the features of our primary testing machine.

The full machine defines additional operations, and extends some of the old ones.
We add a field \(\overline{sa}\) to the \(\mathbf{call}\) operation: a set of
triples of a register \(\reg\), a base offset \(\mathit{off}\), and a size \(sz\), denoting
that the value at the offset \(\mathit{off}\) from \(\reg\) is to be passed as an argument.
The new \(\mathbf{tailcall}\) operation has the same fields, but deals with tail-call
optimizations in which the callee will reuse the caller's stack. The \(\mathbf{alloc}\) operation
gains a boolen flag indicating whether the allocation is to be public, accessible to
all functions until deallocated. The rules are given in \cref{fig:advops}; the
rules in \cref{fig:basicops} can be recaptured by instantiating
\(\mathbf{call}\) with \(\overline{sa}\) as the empty set, and \(\mathbf{alloc}\)
with \(\mathbf{f}\).

\subsection{Sharing Stack Memory}
In our examples, we have presented a vision of stack safety in which
the interface between caller and callee is in the registers that pass
arguments and return values. This is frequently not the case in a realistic
setting. Arguments may be passed on the stack due to being spilled, as an implementation
of variadic arguments, or because they are reference objects that inherently have
pass-by-reference semantics. The caller may also take the address of a local object and
pass that as a pointer to its callee.

We refine our call operation to make use of the information that we have about
which memory contain arguments, \(\overline{sa}\). \(\overline{sa}\) is a set of
triples of a register, an offset from the value of that register, and a size.
We first define the helpful set \(\mathit{passed} ~ \overline{sa} ~ \mach\),
then extend the call operation to keep all objects in \(\mathit{passed}\) marked
as \(\object\) and seal everything else (\cref{sfig:stkargs}).

In this mechanism, we can describe an argument being passed by their relative address
with the operation \(\mathbf{call} ~ \dots ~ (\SP, \mathit{off}, \mathit{sz})\).
In the case of pass-by-reference semantics, if the compiler designates register
\(\reg\) as holding the reference, then the operations is
\(\mathbf{call} ~ \dots ~ (\reg, 0, \mathit{sz})\).

In both cases, the immediate callee retains access to the passed object, but future
callees will not---unless the object is passed-by-reference further down the stack.
On the other hand, in the case of a caller explicitly taking the address of an
object and passing it as a pointer, we have no way obvious way to limit the scope
of such sharing. 

Our primary machine treats this scenario as the caller allocating a ``public''
object that can be accessed by anyone until it's deallocated. We extend the
\(\mathbf{alloc}\) operation with a boolean flag, where {\bf t} indicates
that the allocation is public, and {\bf f} is private.
In the likely event that the space for multiple objects is allocated in a single step,
that step can make multiple allocation operations, each labeled appropriately.
Allocating public objects affects the call stack very similarly to private ones,
but instead of labeling them \(\object\) they become \(\public\), so they are
never sealed at a call (\cref{sfig:publicalloc}).

\begin{figure*}
  \begin{subfigure}{0.4\textwidth}
    \[\mathit{range} ~ \reg ~ \mathit{off} ~ \mathit{sz} ~ \mach \triangleq
    \{\mach[\reg]+i | \mathit{off} \leq i < \mathit{off+sz}\}\]
    
    \judgmentbr{\(\components = \mathit{range} ~ \SP ~ \mathit{off} ~ \mathit{sz} ~ \mach \cap
                 \{\addr \mid V ~ \addr = \unsealed\}\)}
               {\(V' = V \llbracket \addr \mapsto \sealed \mid \addr \in \components \rrbracket\)}
               {\(Op ~ \mach ~ (\mathbf{alloc} ~ \mathbf{f} ~ \mathit{off, sz}) ~ (V,\sigma) = (V',\sigma)\)}
             
    \judgmentbr{\(\components = \mathit{range} ~ \SP ~ \mathit{off} ~ \mathit{sz} ~ \mach \cap
                 \{\addr \mid V ~ \addr = \unsealed\}\)}
               {\(V' = V \llbracket \addr \mapsto \public \mid \addr \in \components \rrbracket\)}
               {\(Op ~ \mach ~ (\mathbf{alloc} ~ \mathbf{t} ~ \mathit{off, sz}) ~ (V,\sigma) = (V',\sigma)\)}
    %
    \judgmentbr{\(b = \mach[\SP] + \mathit{off}\)}
               {\(V' = V \llbracket \addr \mapsto \unsealed |
                 b \leq a < b+\mathit{sz} \land V ~ \addr = \object \rrbracket\)}
               {\(Op ~ \mach ~ (\mathbf{dealloc} ~ \mathit{off, sz}) ~ (V,\sigma) = (V',\sigma)\)}

    \caption{Memory Allocation}
    \label{sfig:publicalloc}
  \end{subfigure}
  \begin{subfigure}{0.6\textwidth}
    %
    \[\mathit{passed} ~ \overline{sa} ~ \mach = \bigcup_{(\reg,\mathit{off},\mathit{sz}) \in \overline{sa}}
    \mathit{range} ~ \reg ~ \mathit{off} ~ \mathit{sz} ~ \mach\]
    %
    \judgmentbr{\(V' = V \llbracket \reg \mapsto \unsealed | \reg \in \mathit{CLR} \rrbracket
                 \llbracket \reg \mapsto \public | \reg \in \overline{\reg_{args}} \rrbracket\)}
               {\(V'' = V'\llbracket \addr \mapsto \sealed | V' ~ \addr = \object \land \addr \not \in (\mathit{passed} ~ \overline{sa} ~ \mach) \rrbracket\)}
               {\(Op ~ \mach ~ (\mathbf{call} ~ \addr_{target} ~ \overline{\reg_{args}} ~ \overline{sa})
                 ~ (V,\sigma) = (V'',V::\sigma)\)}
    %
    \judgmentbr{\(V' = V \llbracket \reg \mapsto \unsealed | \reg \in \mathit{CLR} \rrbracket
                 \llbracket \reg \mapsto \public | \reg \in \overline{\reg_{args}} \rrbracket\)}
               {\(V'' = V'\llbracket \addr \mapsto \unsealed | V' ~ \addr = \object \land \addr \not \in (\mathit{passed} ~ \overline{sa} ~ \mach) \rrbracket\)}
               {\(Op ~ \mach ~ (\mathbf{tailcall} ~ \addr_{target} ~ \overline{\reg_{args}} ~ \overline{sa})
                 ~ (V,\sigma) = (V',\sigma)\)}
    %
    \judgment{\(\sigma = (V,\addr_{ret},\addr_{sp})::\sigma'\)}
             {\(Op ~ \mach ~ \mathbf{return} ~ (\_, \sigma) = (V, \sigma')\)}

    \caption{Calls with Argument Passing on the Stack}
    \label{sfig:stkargs}
  \end{subfigure}
  \caption{Operations supporting tailcalls and argument passing on stack.}
  \label{fig:advops}
\end{figure*}

\subsection{Tail Calls}

The operation rule for a tailcall is similar to that for a normal call.
We do not push the caller's view onto the stack,
but replace it outright. This means that a tailcall does not increase the size of
the call stack, and therefore for purposes of our properties, all tailcalls will
be considered to return simultaneously when the eventual {\bf return} operation
pops the top of the stack.

Since the caller will not be returned to, it does not need integrity, though
it should still enjoy confidentiality. We set its frame to \(\unsealed\) rather
than \(\sealed\) to express this. Of course, some objects may be passed as arguments
in place, easily modeled by including them in \(\overline{sa}\). More sophisticated
behaviors may require sequences of {\bf dealloc}, {\bf tailcall}, then {\bf alloc}.

\section{Enforcement}

\paragraph{Depth Isolation}

\paragraph{Lazy Tagging and Clearing}

\subsection{Enforcing \(\clei\) and \(\clec\)}

\section{Validation through Random Testing}
\label{sec:testing}

There are several ways to evaluate whether an enforcement mechanism enforces the above
stack safety properties. Ideally such validation would be done through formal proof over
the semantics of the enforcement-augmented machine.
However, while there are no fundamental barriers to producing such a proof,
it would be considerable work to carry out for a full ISA like RISC-V and
complex enforcement mechanisms like Roessler and DeHon's micro-policies.
We therefore choose to systematically \emph{test} their micro-policies.

We use a Coq specification of the RISC-V architecture~\cite{Bourgeat2021AMF},
and extend it with a runtime monitor implementing a stack safety
micro-policy. We choose the Coq proof assistant as the setting for our implementation
to ensure that our coinductive trace definitions are well-formed, to reason about
them, and to leverage the power of the QuickChick property-based testing framework~\cite{Pierce:SF4}.

To use QuickChick, we build random test-case generators that produce
(1) an initial RISC-V machine state, including the program to be executed;
(2)
  an initial policy state, tagging instructions and the stack regions appropriately
  for the micro-policy (see \cref{subsec:policies})
(3)
  a map from instructions to lists of their operations in the security semantics.

To write such generators we build on the work of
Hri\c{t}cu et al. \cite{TestingNI:ICFP, DBLP:journals/jfp/HritcuLSADHPV16}, which
introduced {\em generation by execution} to produce progams that lead
machines towards interesting behaviors. We extend the technique with a degree
of statefulness, to nudge the generator toward executions that will carry
on without early failstops and thus have a better chance of reaching a
state that presents opportunities for an attack.

We need to extend typical testing schemes further to handle the nested
nature of confidentiality: rather than just generating two
initial machines that are variants of one another and letting them
execute to test for noninterference, we generate a new variant
{\em every time a call is made} and check confidentiality for the
subtrace produced from that variant state until its corresponding
return. As a result, a ``single'' confidentiality test compactly
checks multiple nested calls.

Our primary testing targets are the eager {\em Depth Isolation}
and the {\em Lazy Per-Activation Tagging and Clearing} micro-policies.

\subsection{Mutation Testing}

To ensure the effectiveness of testing against our formal properties, we
use {\em mutation testing}~\cite{JiaH11}. In mutation testing, we inject errors
(mutations) in a program that should cause the property of interest (here,
stack safety) to fail, and ensure that the testing framework can find
them. The bugs we use for our evaluation are either artificially generated
by us (deliberately weakening the micro-policy in ways that we expect
should break its guarantees), or actual bugs that we discovered through
testing our implementation. We elaborate on some such bugs below.

For example, when loading from a stack location, {\em Depth Isolation}
needs to enforce that the tag on the location being read
is $\tagStackDepth{n}$ for some number $n$ and that the tag of the
current $\PCname$ is $\tagPCDepth{n}$ for the same depth $n$. We can relax
that restriction by not checking the depth equality (row {\em
  LOAD\_NO\_CHECK\_DI}).

Similarly, when storing to a stack location, the correct micro-policy
needs to ensure that the tag on the memory location is either
$\tagNoDepth$ or has again the same depth as the current $\PCname$
tag. Relaxing that constraint causes violations to the integrity
property (row {\em STORE\_NO\_CHECK}).

\begin{table}[]
\centering
\begin{tabular}{c|c|c|c}
  Bug & Property Violated & MTTF (s) & Tests \\
  \hline
      {\em LOAD\_NO\_CHECK\_DI}  & Confidentiality & 24.2 & 13.3 \\
      {\em STORE\_NO\_CHECK} & Integrity & 26.9 & 26 \\
      {\em HEADER\_NO\_INIT} & Integrity & 69.5 & 76.3 \\
  \hline
  \hline
      {\em PER\_DEPTH\_TAG} & Obs. Integrity & 189.7 & 8342.5  \\
      {\em LOAD\_NO\_CHECK\_LT}  & Obs. Integrity & 23.5 & 12.0 \\
      {\em LOAD\_NO\_CHECK\_LT}  & Confidentiality & 19.2 & 695.5 \\
      {\em STORE\_NO\_UPDATE} & Obs. Integrity & 70 & 80.6  \\
      {\em STORE\_NO\_UPDATE} & Confidentiality & 4.9 & 88.5 \\
  \hline
\end{tabular}
\vspace*{1em}
\caption{MTTF for finding bugs in erroneous policy enforcement mechanisms}
\vspace*{-2em}
\label{tab:bug-table}
\end{table}

\subsection{Results}

The mean-time-to-failure (MTTF) and average number of tests for various bugs can be found in
Table~\ref{tab:bug-table}, along with the average number of tests
it took to find the failure. Experiments were run in a desktop
machine equipped with i7-4790K CPU @ 4.0GHz with 32GB RAM.

Naturally, testing also revealed a number of errors in our
implementation of the enforcement mechanism (the original was written in C++
and targeted ARM machine code;
%\bcp{right?}\leo{yeah}
we re-implemented it in Coq targeting RISC-V).  These errors range
from trivial typos to ones that require an intriguingly complex setup
to provoke.  The most interesting bug (included in the table as row
{\em HEADER\_NO\_INIT}) was that, on our first try, the blessed call
sequence %/policy combination\apt{??}
did not initialize all locations for the
newly allocated stack frame correctly, but left some of them as
$\tagNoDepth$. This allowed for a potential integrity violation, but
only if a rather complicated sequence of events occured.
The smallest counterexample requires calling a function {\tt f},
which fails to initialize some of its frame,
but writes into an uninitialized location $l$ later, treating \(l\) as outside
the stack. Then {\tt f} calls a further function {\tt g} (which should have
the effect of sealing $l$ for integrity purposes). {\tt g} attempts to write to $l$,
which is allowed because the enforcement mechanism still has
$l$ tagged as $\tagNoDepth$, but violates the integrity property on {\tt f}'s data.
%\sna{I believe what went wrong was that we were off-by-one in {\tt main}'s initialization,
%  and the write from {\tt f} was already a violation.}

As for \(LTC\), the original micro-policy, implemented as {\em PER\_DEPTH\_TAG},
fails in testing, in cases where data is leaked between sequential calls.
To round out our mutation testing we also check {\em LOAD\_NO\_CHECK\_LT},
equivalent to its counterpart in depth isolation,
and a version where stores succeed but fail to propagate the PC tag, {\em STORE\_NO\_UPDATE}.
It turns out that {\em PER\_DEPTH\_TAG} is a comparatively subtle bug,
taking twice as long to catch as the next longest.

Our properties have allowed us to identify an enforcement mechanism as
not really stack safe, and to validate a possible fix.

\section{Related Work}

\sna{Not really sure what goes here anymore.
  We've discussed Cerise and Nick and Andre quite a bit throughout.}

\section{Future Work}
\label{sec:future}

\input{future_work.tex}

\bibliographystyle{IEEEtran}
\bibliography{bcp.bib,local.bib}

\appendix

\subsection{Provenance, Capabilities, and Protecting Objects}
\label{app:ptr}

What if we want to express a finer-grained notion of safety, in which
stack objects are protected unless the function that owns them intentionally
passes a pointer to them? This can be thought of as a {\it capability}-based
notion of security. Capabilities are unforgeable tokens that grant access to
a region of memory, typically corresponding to valid pointers to that region.
So, in order to express such a property, we need our machine to carry some notion
of {\it pointer provenance}---a distinction between a pointer that is intended to
point to a given object, and non-pointer integers as well as pointers to other objects.

One such provenance model is Memarian et al.'s PVI \cite{provenance}, in which pointers are
annotated with the identity of the object they first pointed to. This annotation is
propagated when the pointer is copied and when operations are performed on it---even
integer-only operations.

We can model this as a trio of additional security-relevant operations: one which
declares a register to contain a valid pointer, one which transmits the provenance
of a pointer from one element to another, and one which clears the provenance
(for instance, when a pointer is modified in place in a way that makes it invalid.)

In addition to the normal call stack, our security context will carry a map \(\rho\) from
elements to memory regions, represented as a base and a bound \(\context = (V, \sigma, \rho)\).
Existing operations are extended to keep the value of \(\rho\) the same, and the new operations
work as follows:

\judgmentbr[Promote]
           {\(\psi = \mathbf{promote} ~ \reg_{dst} ~ (\reg_{base},\mathit{off},\mathit{sz})\)}
           {\(\rho' = \rho[\reg_{dst} \mapsto \mathit{range} ~ \reg_{base} ~ \mathit{off} ~ \mathit{sz}]\)}
           {\(Op ~ \mach ~ \psi ~ (V,\sigma,\rho) = (V,\sigma,\rho')\)}

\judgmentbr[Propagate]
           {\(\psi = \mathbf{propagate} ~ \component_{src} ~ \component_{dst}\)}
           {\(\rho' = \rho[\component_{dst} \mapsto \rho[\component_{src}]]\)}
           {\(Op ~ \mach ~ \psi ~ (V,\sigma,\rho) = (V,\sigma,\rho')\)}

\judgment[Clear]
         {\(\psi = \mathbf{clear} ~ \component\)}
         {\(Op ~ \mach ~ \psi ~ (V,\sigma,\rho) = (V,\sigma,\rho[\component \mapsto \emptyset])\)}

We now have a notion of provenance, and must integrate it into the definition of
stack safety. We essentially generalize the above notion of passing: we will consider
a caller to have intentionally passed an object if that object is reachable by
a capability that has been passed to the callee. This includes capabilities passed
indirectly, by being stored in an object that is in turn passed. Formally, we call
this set \(\mathit{capped}\), and define it recursively:
%
\[\begin{split}
& \mathit{capped} ~ \components ~ \rho \triangleq \bigcup_{\component \in \components} \{\component\} \cup \mathit{capped} ~ \components' ~ \rho \textnormal{ where} \\
& \components' = \{\component' |\rho[\component] = (\mathit{base},\mathit{bound})
\land \mathit{base} \leq \component' < \mathit{bound}\} \\
\end{split}\]

We then tweak the call operation to seal only objects that are in \(\mathit{capped}\), or
the previously defined \(\mathit{passed}\).

\judgmentbrbrbr[]
               {\(\psi = \mathbf{call} ~ \addr_{target} ~ \overline{\reg_{args}} ~ \overline{sa}\)}
               {\(V' = V \llbracket \reg \mapsto \unsealed | \reg \in \mathit{CLR} \rrbracket
                 \llbracket \reg \mapsto \public | \reg \in \overline{\reg_{args}} \rrbracket\)}
               {\(\components = \{\addr | V' ~ \addr = \object \land \addr \not \in (\mathit{passed} ~ \overline{sa} ~ \mach) \cup (\mathit{capped} ~ \overline{\reg_{args}} ~ \rho) \}\)}
               {\(V'' = V'\llbracket \components \mapsto \sealed \rrbracket\)}
               {\(Op ~ \mach ~ \psi ~ (V,\sigma,\rho) =
                 (V'',V::\sigma,\rho)\)}

Note that we have a degree of monotonicity here. Once an object is sealed (because its
capability has not been passed to a callee), subsequent nested calls can never unseal it.
On the other hand, an object that is passed via a pointer may be passed on indefinitely.
              
\end{document}
