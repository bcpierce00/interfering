%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[10pt,conference]{ieeetran}%\settopmatter{printfolios=true,printccs=false,printacmref=false}

\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{amsmath,amsthm,amssymb}

\usepackage{xcolor,listings}

\usepackage{multirow}

\usepackage{stmaryrd}

\usepackage[noadjust]{cite}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\input{macros}

\makeatletter
\newcommand{\linebreakand}{%
  \end{@IEEEauthorhalign}
  \hfill\mbox{}\par
  \mbox{}\hfill\begin{@IEEEauthorhalign}
}
\makeatother

\begin{document}

%% Title information
\title{Formalizing Stack Safety as a Security Property}

\author{
  \IEEEauthorblockN{
    Sean Noble Anderson
  }
  \IEEEauthorblockA{
    Portland State University\\
    ander28@pdx.edu\\
  }
  \and
  \IEEEauthorblockN{
    Leonidas Lampropoulos
  }
  \IEEEauthorblockA{
    University of Maryland, College Park\\
    leonidas@umd.edu\\
  }
  \and
  \IEEEauthorblockN{
    Roberto Blanco
  }
  \IEEEauthorblockA{
    Max Planck Institute for Security and Privacy\\
    roberto.blanco@mpi-sp.org\\
  }
  \linebreakand
  \IEEEauthorblockN{
    Benjamin C. Pierce,
  }
  \IEEEauthorblockA{
    University of Pennsylvania\\
    bcpierce@cis.upenn.edu\\
  }
  \and
  \IEEEauthorblockN{
    Andrew Tolmach
  }
  \IEEEauthorblockA{
    Portland State University\\
    tolmach@pdx.edu\\
  }
}



%% Keywords
%% comma separated list
\ifcameraready
\keywords{Stack Safety, Micro-Policies}  %% \keywords are mandatory in final camera-ready submission
\fi

\maketitle

\section{Threat Model, Machines, and Enforcement }

Before introducing our formal model of stack safety, we describe
our machine exemplar, enforcement mechanism, and threat model.

We begin with a RISC-V-like machine enhanced with PIPE, a tag-based reference
monitory. We extend this machine with a {\it security overlay semantics}:
a semantics in which calls, returns, and other operations of interest are condensed
into atomic {\it macro-instructions}, which update an additional security context.
Our properties are defined in terms of the security context at the end of an appropriate
macro-instruction.

The underlying machine is a standard RISC-V ISA as modeled in [MIT-RISCV].
Our overlay semantics provide macro-instructions for the following code features:
\begin{itemize}
\item Function calls and returns, with caller- and callee-saved registers according
  to the RISC-V ABI
\item Arguments passed by reference
\item Exceptions
\item Coroutines and cooperative threading
\item Tail-call Elimination
\end{itemize}

\paragraph*{What is a ``call''?} Some ISAs have a single ``call''
instruction that does all the required manipulation of the program counter
(\(\PCname\)) and stack pointer; others perform a series of instructions
whose constituent opcodes may be used in some places for other purposes.
Our RISC-V machine is the latter, so calls must be explicitly designated
as such by the compiler, by identifying them as macro-instructions.
The same goes for other operations, such as exceptions and coroutine yields.
Macro-instructions connect the enforcement mechanism to the property: we don't
expect the enforcement mechanism to provide any guarantees for code sequences
that resemble calls or returns, but which are not macro-instructions.

Because macro-instructions must be generated by the compiler, they only
carry data that can be known by the compiler at compile-time. For example,
the \(\mathbf{call}\) macro-instruction identifies the register \(r\) containing
the address of the function to be called, as well as a {\it type record} identifying
the registers and addresses in which the callee expects to find arguments,
and a {\it public set}.
Let \(tr \in TR\) be a type record; then \(tr.args\) is a set of those registers
that will be used for arguments, and \(tr.stack\_args\) defines a set of
offsets from the stack pointer that are expected to contain additional
arguments.The public set \(pubs\) defines a similar set of offsets in
the caller that are declared public and not to be protected.

%\paragraph*{Enforcement Model and Properties}

%A machine state consists of the standard addresses and registers, as well as
%additional policy state used by the enforcement mechanism. Our properties
%refer only to addresses and registers; they do not constrain the behavior
%of policy state. We model an execution step as a partial function on states:
%when the machine does not step from a given state, this
%is a {\em failstop}, halting the program before it can perform an
%action that would violate the security property.
%our properties are therefore naturally \emph{termination insensitive.}

\paragraph*{Threat Model}

We trust the compiler has correctly placed macro-instructions according to
the semantics of the source language, but we do not assume that the code
is otherwise reasonable. In particular, while we are agnostic as to the source
language, C is very plausible, and so any source function might contain undefined
behavior resulting in its compilation to arbitrary machine code.

In general, it is impossible to distinguish buggy source code from an attacker;
we assume nothing about the intent of the source code, except that it makes calls
and returns, and guarantee that the caller and callee are protected from one
another.

This is a strong threat model, but hardware and timing attacks are out of scope,
and our properties are termination insensitive as a result of the enforcement mechanism
(below).

\paragraph*{Limitations}

We do not support dynamic code generation or concurrency---we can handle a
limited form of coroutines, but not full-blown preemptive concurrency.
[Say something about Heap Safety]
  
\subsection{The Machine in Detail}
\label{sec:prelim}

The building blocks of the machine are {\em words} and {\em registers}.
Words are 64-bit integers ranged over by \(w\) and, when used as addresses,
\(a\). There are 32 registers, ranged over in general by \(r\),
plus a program counter (\(\PCname\)). The following table divides
the registers into metavariables, some belonging to caller- or callee- sets:

\vspace{\abovedisplayskip}
\begin{tabular}{| l | l | l |}
  \hline
  Set & Names & Purpose \\
  \hline
  CLR\_SV & \(rt_0 - rt_6\) & Caller-saved temps \\
  & \(ra_0 - ra_1\) & Caller-saved args / return vals \\
  & \(ra_2 - ra_7\) & Caller-saved args \\
  \hline
  CLE\_SV & \(rs_0 - rs_7\) & Callee-saved \\
  \hline
  PUBLIC & \(rra\) & Return Address \\
  & \(rsp\) & Stack Pointer \\
  & \(pc\) & Program Counter \\
  \hline
\end{tabular}
\vspace{\abovedisplayskip}

Collectively addresses and registers are {\em state elements} \(\component\)
in the set \(\COMPONENTS ::= \WORDS + \REGS\).
%
A {\em machine state} \(\mach \in \COMPONENTS \rightarrow \WORDS \)
is a mapping from state elements to values. For convenience, we abbreviate
multiple updates \(m[\component_0 \mapsto w][\component_1 \mapsto w]\dots\)
as \(m \llbracket \component \mapsto w | P ~ \component\rrbracket\), where
\(P\) is some predicate that defines the set of elements to update.

Separate from the machine state, we keep track of additional security context
information over the course of the run. This data is not relevant to execution,
it is only used to define the stack safety property. We define a set of
{\it security classes}:
\[sc \in SEC ::= \sealed | \passed | \mathit{public} | \unsealed\]
And of {\it targets}:
\[\begin{split}
tar \in TAR ::= & \mathit{Return} ~ a_1 ~ a_2 \\
| & \mathit{Catch} ~ a_1 ~ a_2 \\
\end{split}\]
A {\it security view} \(V \in \COMPONENTS \rightarrow SEC\) divides the machine
elements in terms of their purpose relative to the active function.
And a security context is a stack of pairs of targets and views:
\[\context \in \CONTEXTS ::= \mathit{list} ~ (TAR \times SEC)\]

The set of instructions, \(I\), contains the RISC-V ISA. There is additionally a set
of macro-instructions \(J\), described in detail in Figure \ref{fig:macros}.
Every macro-instruction \(j \in J\) has a
size \(\mathit{size}(j)\) and can be decomposed into a sequence of fragments
\(j_0 \dots j_{\mathit{size}(J)}\), where \(j_n \in J^*\).
The partial function \(\mathit{decode} : \WORDS \rightharpoonup I + J^*\) may decode a value
into either an instruction or a macro-instruction fragment.

\begin{figure}
  \begin{tabular}{| l | l l |}
    \hline
    Macro & \multicolumn{2}{|l|}{Parameters} \\
    \hline
    \multirow{3}{*}{\(\mathbf{call}\)}
    & \(\reg\) & Register containing destination \\
    & \(tr\) & Type record \\
    & \(pubs\) & Public set \\
    \hline
    \multirow{3}{*}{\(\mathbf{tailcall}\)}
    & \(\reg\) & Register containing destination \\
    & \(tr\) & Type record \\
    & \(pubs\) & Public set \\
    \hline
    \multirow{2}{*}{\(\mathbf{enter}\)}
    & \(tr\) & Type record \\
    & \(n\) & Size of locals \\
    \hline
    \(\mathbf{return}\)
    & \(pubs\) & Public set \\
    \hline
    \(\mathbf{yield}\) & & \\
    \(\mathbf{setex}\) & & \\
    \(\mathbf{throwex}\) & & \\
    \hline
  \end{tabular}
  \caption{Macro-instructions}
  \label{fig:macros}
\end{figure}

Execution is modeled by a partial step function between machine states,
written \(\mach, \context \stepsto \mach', \context'\).
If \(\mach[\PCname]\) decodes to an instruction, then
\(\mach, \context \stepsto \mach', \context\) if \(\mach\) steps to \(\mach'\)
under the RISC-V semantics.
If, for some \(j\), \(\mach[\PCname + i]\) decodes to \(j_i\) for all \(i\) between 0 and
\(\mathit{size}(j)\), then the step is via a special multi-step. We present these steps
as separate step relations: \(\cdot \harpoonunder{j}_M \cdot \in \MACHS \times J \times \MACHS\)
to step the machine state,
and \(\cdot, \cdot \stepstounder{j}_C \cdot \in \MACHS \times \CONTEXTS \times J \times \CONTEXTS\)
for the security context. We then combine them:

\judgmenttwo[]
            {\(m \harpoonunder{j}_M m'\)}
            {\(m',c \stepstounder{j}_C c'\)}
            {\(m,c \stepsto m',c'\)}

\paragraph*{Macro-step machine steps}

Here we give the semantics of the machine side of the macro step for calls and returns.
The machine multi-step for a call (\ref{fig:callmacro}) updates the stack pointer
and program counter, and zeros non-argument, caller-save registers. (This means that
the caller should have saved them before initiating the call.)

\vspace{\abovedisplayskip}
\judgmentbrbr[CallM]
             {\(j = \mathit{decode}^* ~ m ~ m[pc] = \mathbf{call} ~ r ~ tr ~ pubs\)}
             {\(m' = m[rra \mapsto m[pc] + 4]\)}
             {\(m'' = m' \llbracket r \mapsto 0 | r \in CLR\_SV - tr.args \rrbracket\)}
             {\(m \harpoonunder{j}_M m''[pc \mapsto m[r]]\)}
\vspace{\belowdisplayskip}

Then, on enter, the callee stores the stack pointer and allocates new stack space.
[TODO: also have it do the saving of other callee-save, little complicated.]

\vspace{\abovedisplayskip}
\judgmentbrbr[EnterM]
           {\(j = \mathit{decode}^* ~ m ~ m[pc] = \mathit{enter} ~ tr\)}
           {\(m' = m[m[sp] \mapsto m[rra]]\)}
           {\(m'' = m'[sp \mapsto m[sp]+n+1]]\)}
           {\(m \harpoonunder{j}_M m''[pc \mapsto m[pc]+4*\mathit{size}(j)]\)}
\vspace{\belowdisplayskip}

Finally, on return, the program counter is restored from the stack, and the callee's
frame is deallocated.

\vspace{\abovedisplayskip}
\judgmentbr[ReturnM]
             {\(j = \mathit{decode}^* ~ m ~ m[pc] = \mathit{return} ~ n\)}
             {\(m' = m[sp \mapsto m[sp]-n-1]\)}
             {\(m \harpoonunder{j}_M m'[pc \mapsto m'[sp]]\)}
\vspace{\belowdisplayskip}

%For the context step, the macro-instruction additionally identifies which objects
%(contiguous regions defined relative to the stack pointer) have been placed there
%as: arguments that overflowed to the stack (\(sargs\)), which are existing objects
%passed by reference (\(pbrs\)), and which are marked public (\(pubs\)). We use this
%information to construct the callee's security view.
%\[obj \in OBJ ::= \mathbb{Z} \times \mathbb{Z}\]
%\[in\_obj ~ a_{sp} ~ (lo, hi) ~ a \triangleq a_{sp} - lo \leq a < a_{sp} - hi\]
           
%\judgmenttwobrlong[Return]
%                    {\(m' = m[sp \mapsto m[sp] - \mathit{size}(frsize)]\)}
%                    {\(m'' = m \llbracket r \mapsto 0 | r \not \in args \land r \in caller \rrbracket\)}
%                    {\(\mathit{decode}^* ~ m ~ pc = \mathit{return} ~ frsize\)}
%                    {\(m \stepsto_M m'[pc \mapsto f]\)}

%If \(\mathit{decode}\) is undefined on that value, \(\mach \stepsto \mach\). The
%only times \(\stepsto\) is undefined is when there is a policy fault,
%(and the machine ``failstops'') or when it attempts to begin executing a
%macro-instruction out of order. The latter represents a failstop in a lower-level
%policy in the underlying ISA, which guarantees that the macro-instruction
%executes in order.

\paragraph*{Compiling Macro-instructions}

[TODO]

\paragraph*{Machine Traces}
\label{sec:traces}

A {\em machine trace} is a nonempty, finite or infinite sequence
of states, ranged over by \(\MPCT\) and \(\NPCT\).
We use ``\(\notfinished{}{}\)'' to represent ``cons'' for traces, reserving ``::''
for list-cons.

The ``trace-of'' operator, written \(\mpcstatename \hookrightarrow \MPCT\),
coinductively relates an initial state with the trace of states
produced by repeated application of \(\stepstocon\):
%
\vspace{-\bigskipamount}
\begin{center}
\begin{minipage}[t]{.6\columnwidth}
\judgmenttwo{\(\mpcstatename \stepstocon \mpcstatename'\)}
            {\(\mpcstatename' \hookrightarrow \MPCT\)}
            {\(\mpcstatename \hookrightarrow \notfinished{\mpcstatename'}{\MPCT}\)}%
\end{minipage}
\begin{minipage}[t]{.35\columnwidth}
\judgment%[Default]
         {\(\not\exists \mpcstatename'. \mpcstatename \stepstocon \mpcstatename'\)}
         {\(\mpcstatename \hookrightarrow \mpcstatename\)}
\end{minipage}
\end{center}
\vspace{-\smallskipamount}

We project out the machine state of an MC-state with \(\pi_\mach\)
and the context with \(\pi_\context\).
We extract the first entry from a trace with \(\head(\MPCT)\), which is a total
function since traces are non-empty, and the final entry (if one exists) with
\(\last(\MPCT)\), which is partial, since traces may be infinite.

\paragraph*{Until}
The operation \(\PUT ~ f ~ \MPCT\) takes a trace \(\MPCT\)
and a predicate on states \(f \subseteq \MPCS\) and gives the prefix of
\(\MPCT\) ending with the first trace entry on which \(f\) holds.

\vspace{-\medskipamount}
\begin{center}
  \begin{minipage}[b]{.5\columnwidth}
    \judgment{\(f ~ \mpcstatename\)}
             {\(\PUT ~ f ~ (\notfinished{\mpcstatename}{\MPCT}) = \mpcstatename\)}
  \end{minipage}
%
  \begin{minipage}[b]{.3\columnwidth}
    \judgment{}
             {\(\PUT ~ f ~ \mpcstatename = \mpcstatename\)}
%
  \end{minipage}
\end{center}
    \judgmenttwo{\(\neg f ~ \mpcstatename\)}{\(\PUT ~ f ~ \MPCT = \MPCT'\)}
                {\(\PUT ~ f ~ (\notfinished{\mpcstatename}{\MPCT}) = \notfinished{\mpcstatename}{\MPCT'}\)}

If the resulting trace is a strict prefix of the parameter, then the
predicate must hold on its final entry. If the predicate never holds, then
\(\PUT\) is the identity function.

We will frequently take a prefix of the trace from an initial state up
through the first state where some condition holds on the machine state.
This can easily be implemented using \(\PUT\), and we provide special notation
for convenience.
%
If \(f\) is a predicate on machine states, we define \(\mpcstatename
\hookrightarrow \MPCT | f\) (pronounced ``\(\MPCT\) is the prefix of
running \(\mpcstatename\) up to \(f\)'') thus:
%
\begin{center}
\judgmenttwo{\(\mpcstatename \hookrightarrow \MPCT'\)}
            {\(\PUT ~ f ~ \MPCT' = \MPCT\)}
            {\(\mpcstatename \hookrightarrow \MPCT | f\)}
\end{center}

\paragraph*{Context Segments}

In particular, we wish to formulate properties around consecutive subtraces
in which the context obeys a given predicate. This will commonly be used to extract
individual calls from a trace by taking subtraces in which the stack is
at or above a given depth. If \(f\) is again a predicate on states, then
we define \(\mpcstatename \hookrightarrow \MPCT \langle f \rangle\) (pronounced
``\(\mpcstatename\) segmented by \(f\) yields a sub-trace \(\MPCT\)'') thus:
\ifspace{\bcp{Throughout, we could save space and improve beauty by removing some of the
vertical space between inference rules.}\fi

\begin{center}
  \judgmenttwo[]
              {\(f ~ \mpcstatename\)}
              {\(\mpcstatename \hookrightarrow \MPCT | \neg f\)}
              {\(\mpcstatename \hookrightarrow \MPCT \langle f \rangle\)}
  \judgmentthree[]
                {\(f ~ \mpcstatename\)}
                {\(\mpcstatename \hookrightarrow \MPCT | \neg f\)}
                {\(\last(\MPCT) \hookrightarrow \MPCT' \langle f \rangle\)}
                {\(\mpcstatename \hookrightarrow \MPCT' \langle f \rangle\)}
  \judgmentthree[]
                {\(\neg f ~ \mpcstatename\)}
                {\(\mpcstatename \hookrightarrow \MPCT | f\)}
                {\(\last(\MPCT) \hookrightarrow \MPCT' \langle f \rangle\)}
                {\(\mpcstatename \hookrightarrow \MPCT' \langle f \rangle\)}
\end{center}

\paragraph*{Reachability}

We often want to quantify over all traces from any initial state so that our
properties apply to the system as a whole. We say that a state \(\mpcstatename'\)
is {\em reachable} if, for some initial state \(\mpcstatename = \mach,\context_0\)
where \(\mach\) is well-formed, \(\mpcstatename \hookrightarrow \MPCT\)
and \(\MPCT\) contains \(\mpcstatename'\).
A {\it reachable segment} \(\MPCT \langle f \rangle\) is a subtrace
such that from some similarly well-formed initial state \(\mpcstatename\),
\(\mpcstatename \hookrightarrow \MPCT \langle f \rangle\).

\section{Stack Safety, Formally}
\label{sec:lse}

Now we can give our definition of stack safety. Each macro-instruction defines a
context step; in turn, the context at the point of a call or return defines a trace
property each for integrity, confidentiality, and well-bracketed control flow.
The context updates involved in calls and returns are given in \ref{fig:callcontexts}.
First, we define a function, {\it update view}, that defines the view of a callee.
Addresses that, offset from stack pointer, are in public regions are marked
\(\mathit{public}\). Those that are being passed on the stack are marked
\(\mathit{passed}\). [When we add pass-by-reference arguments, we wil use
\(V\)]

To update the context, we pair the updated view with the return target of the
call: the 

\begin{figure*}
\[\begin{split}
& \mathit{update\_view} ~ V ~ a_{sp} ~ tr ~ pubs \triangleq
 \lambda \component .
\begin{cases}
  \mathit{public} & \textnormal{if } \component \in \WORDS \textnormal{ and }
  (a_{sp} - \component) \in pubs \\
%  \passed & \textnormal{else if } \component \in \WORDS \textnormal{ and }
%  in\_obj ~ a_{sp} ~ pbr ~ \component \textnormal{ for some } pbr \textnormal{ in } pbrs \\
  \passed & \textnormal{else if } \component \in \WORDS \textnormal{ and }
  (a_{sp} - \component) \in tr.sargs \\
  \sealed & \textnormal{else if } \component \in \WORDS \textnormal{ and } \component < a_{sp} \\
  \mathit{public} & \textnormal{else if } \component \in \REGS \textnormal{ and }
  \component \in tr.args \textnormal{ or } \component \in \mathit{PUBLIC} \\
  \unsealed & \textnormal{otherwise} \\
\end{cases} \\
\end{split}\]

\judgmenttwobrlong[CallCCons]
           {\(V' = \mathit{update\_view} ~ V ~ m[sp] ~ tr ~ pubs\)}
           {\(j = \mathbf{call} ~ r ~ tr\)}
           {\(\context' = (\mathit{Return} ~ (m[pc] + 4) ~ m[sp], V')::(tar,V)::\context\)}
           {\(m, (tar,V)::\context \stepstounder{j}_C \context'\)}

\judgmenttwobrlong[CallCNil]
           {\(V' = \mathit{update\_view} ~ (\lambda \component . \unsealed) ~ m[sp] ~ tr ~ pubs\)}
           {\(j = \mathbf{call} ~ r ~ tr ~ pubs\)}
           {\(\context' = (\mathit{Return} ~ (m[pc] + 4) ~ m[sp], V')::[]\)}
           {\(m, [] \stepstounder{j}_C \context'\)}
                             
\judgment[]
         {\(j = \mathbf{enter} ~ tr ~ n\)}
         {\(m,c \stepstounder{j}_M c\)}

\judgmentbr[ReturnCCons]
           {\(\)}
           {\(j = \mathbf{return} ~ pubs\)}
           {\(m, V::tars \stepstounder{j}_C ((m[pc] + 4, m[sp]), V')::tars\)}

\judgmentbr[ReturnCNil]
           {\(V' = \lambda \component . \textnormal{if } \component = \PCname \textnormal{ then }
             \unsealed)\)}
           {\(\mathit{decode}^* ~ m ~ pc = \mathit{call} ~ f ~ args ~ sargs ~ pubs\)}
           {\(m, [] \stepstounder{j}_C ((m[pc] + 4, m[sp]),V')::[]\)}

\caption{Call, enter, and return macro-instructions}
\label{fig:callcontexts}
\end{figure*}

We now state our properties.
The first is {\em stepwise stack integrity}, where ``stepwise'' means that the property is
quantified over each step of execution from any initial state. The criterion for integrity
is simple: sealed elements do not change.

\definition
The \emph{protected set} of a context, \(\prot(\domMap,\_)\), is the
set of elements \(\component\) such that \(\domMap ~ \component = \sealed{\depth}\)
for some depth \(\depth\).

\definition
A system enjoys \textit{\textbf{stepwise stack integrity}} if, for any reachable state
\(\mach,\context\) such that \(\mach,\context \stepstocon \mach',\context'\),
and any element \(\component \in \prot(\context)\),
\(\mach'[\component] = \mach[\component]\).

Next we consider {\em stepwise stack confidentiality}. Recall that our properties are
nested: we will quantify over subtraces that represent whole calls. For each
subtrace, we quantify over {\em variants} of its initial state. Then we require
that the original, {\em primary} traces move in {\em lockstep} with the variant.

\definition The \emph{call set} \(\MPCT^*\) of a machine is
\[\begin{aligned}
\bigcup_{\depth \in \mathbb{Z}} \{(\MPCT, \neg f_\depth) | \MPCT\langle f_\depth \rangle
\text{ is a reachable segment}\} \hspace{1em} \\
\text{where } f_\depth ~ (\mach,(\domMap,\rts)) \triangleq |\rts| \geq \depth \\
\end{aligned}\]

\noindent
This is the set of all possible calls that can be reached from any well-formed initial state.

We term \(\neg f_\depth\) the {\em break condition} \(\brk\), a predicate on
states that holds on \(\MPCT\)'s final state, {\em unless it terminated prematurely due to a failstop}.

\definition Machine states \(\mach\) and \(\nach\) are {\em \(\components\)-variants},
written \(\mach \approx_\components \nach\), if, for
all \(\component \not \in \components\), \(\mach[\component] = \nach[\component]\).

\definition The \emph{difference} of two machine states \(\mach\) and \(\mach'\), written \(\Delta(\mach,\mach')\),
is the set of elements \(\component\)
such that \(\mach[\component] \not = \mach'[\component]\).

\definition Two pairs of states \((\mach,\mach')\) and \((\nach,\nach')\)
 {\em change together}, written \((\mach,\mach') \diamond (\nach,\nach')\), if, for all elements \(\component\) in
\(\Delta(\mach,\mach') \cup \Delta(\nach,\nach')\),
\(\mach'[\component] = \nach'[\component]\).

\definition A pair of traces \(\machT\) and \(\nachT\) are {\em in lockstep},
written \(\machT \doteq \nachT\),
if their adjacent pairs of states change together.  We define this as a coinductive relation:

\smallskip
\begin{minipage}[b]{.2\columnwidth}
\judgment{}
         {\(\mpcstatename \doteq \npcstatename\)}
\end{minipage}
\begin{minipage}[b]{.75\columnwidth}
\judgmenttwo{\(\mach, \pi_\mach(\head(\machT)) \diamond \nach, \pi_\mach(\head(\nachT))\)}
            {\(\machT \doteq \nachT\)}
            {\(\notfinished{(\mach,\underscore)}{\machT} \doteq \notfinished{(\nach,\underscore)}{\nachT}\)}
\end{minipage}

\definition
The \emph{secret set} of a context, written \(\secret(\domMap,\rts)\), is the
set of elements \(\component\) such that \(\domMap ~ \component \not = \outside\).

\definition
A system enjoys \textbf{\textit{stepwise stack confidentiality}} if,
for any \((\MPCT,\brk) \in \MPCT^*\) with \(\head(\MPCT) = (\mach,\context\)),
any \(\nach\) such that \(\mach \approx_{\mathit{secret}(\context)} \nach\), and any trace
%\(\NPCT\) such that \(\nach,\pol,\domMap \hookrightarrow \NPCT | \brk\),
\(\NPCT\) such that \((\nach,\context) \hookrightarrow \NPCT | \brk\),
\(\MPCT \doteq \NPCT\) holds.

In short, if we consider a variant of the stack at the start of a call,
the resulting trace remains in lockstep with the original trace
until either both return together or one failstops.
Note that \(\MPCT\) may contain nested calls; these must also respect the secrecy
of the elements in \(\components\), and in addition their subtraces are also in
\(\MPCT^*\), and therefore confidentiality must hold on them separately.

Finally, WBCF is a \ifspace simple \fi property of the behavior of returns.
\definition
A system enjoys \textit{\textbf{well-bracketed control flow}} when, for every reachable state
\(\mpcstatename\) where \(\pi_\context(\mpcstatename) = (\underscore,\rts)\), and
\(\mpcstatename \stepsto \mpcstatename'\) where \(\pi_\context(\mpcstatename') = (\underscore,\rts')\),
if \(|\rts'| < |\rts|\), then \(|\rts'| = |\rts|-1\).

\medskip
\section{Case Study: Micro-Policies}
\label{sec:enforcement}

We next explore how an \ifspace existing \fi enforcement mechanism called {\em
  Depth Isolation}~\cite{DBLP:conf/sp/RoesslerD18} implements
the formal stack safety property described in the previous
section, and why its optimized form, {\em Lazy Tagging and Clearing}, does not.
We validate these claims using property-based random testing in \cref{sec:testing}.

\paragraph*{Conservative Stack Safety Enforcement Mechanism}
%
The enforcement policy of Roessler and DeHon \cite{DBLP:conf/sp/RoesslerD18} relies
on a programmable, tag-based reference monitor that runs alongside the
program,
allowing fine-grained manipulation of metadata tags to encode so-called
\emph{micro-policies}~\cite{pump_oakland2015}.
Every value in
memory and registers (including the $\PCname$)
is enriched with an abstract metadata tag, which can represent
arbitrary information about the value. A micro-policy is then defined as a
set of tags and a
collection of software-defined rules.
On each machine step, the relevant rule is applied to the tags on
the instruction's inputs ($\PCname$, registers, memory) and on the
\ifspace instruction \fi opcode\ifspace itself\fi, producing
one of two outcomes: either the instruction is permitted to execute (and
generates tags for the result of the operation and the new $\PCname$), or
the machine fail-stops with a policy violation.
Existing work \cite{TestingNI:ICFP,pump_oakland2015, DBLP:conf/sp/RoesslerD18}
%\bcp{additional citations: the noninterference paper, Nick and Andre's papers, ...}
has shown that a wide range of
micro-policies can be defined using this scheme.
Efficient execution of these micro-policies relies on hardware acceleration,
such as the PUMP architecture~\cite{pump:asplos2015}.

Tags in the PIPE system are not accessible to application code, being separated
from their associated values at the hardware level. So they are not modeled
as state elements, and therefore our properties make no claims about
their values.

The micro-policy we describe here is a variation
on the {\em Depth Isolation} policy presented by
Roessler and DeHon\cite{DBLP:conf/sp/RoesslerD18}.
The Depth Isolation micro-policy maintains tags of the form $\tagStackDepth{n}$ for
each stack location belonging to the stack frame at activation depth
$\depth$, or the tag $\tagNoDepth$ for stack locations that are currently
unused (but could be used in the future).
%
The $\PCname$ is tagged similarly as $\tagPCDepth{\depth}$.
%
Initially, the entire stack is considered unused (and therefore tagged
$\tagNoDepth$), and the {\PCname} has tag $\tagPCDepth{0}$.
%
During normal execution, the micro-policy rules only permit load and
store operations when the target memory is tagged {\em with the same
 depth} as the current {\PCname} tag, and store operations also when the
target memory is $\tagNoDepth$.

Interesting changes to the tags occur where the program switches from
a caller to a callee or vice-versa:

\begin{itemize}

\item From caller to callee: when the machine executes a call,
  %, when the machine executes an instruction marked as a call in
  % the call map.
  the current
  $\tagPCDepth{\depth}$ tag is incremented to $\tagPCDepth{(\depth + 1)}$, and the function
  entry sequence initializes  all locations of the new function frame with
  tag $\tagStackDepth{(\depth + 1)}$.

\item From callee back to caller: the callee clears its frame, and at
  the actual return instruction,
  the $\PCname$ tag is decremented.
\end{itemize}

To implement this discipline, blessed instruction sequences are designated
to appear at the entry and exit of each function,
which manipulate tags as just described in addition to performing the
usual calling convention tasks of saving/restoring the return address to/from
the stack and adjusting the stack pointer. With the aid of an additional tag on
the $\rsp$ register, these sequences also serve to enforce
well-bracketed control flow.
The micro-policy guarantees atomic execution of these sequences
using a combination of tags on the instructions
and an additional tag on the $\PCname$.

There remains the question of how to ensure that the sequences are
invoked at the right places\ifspace from the perspective of the stack safety
property\fi. For a program to enjoy stack safety
(with respect to a particular set of call annotations), all we require is that
the entry sequence immediately follows any instruction marked as a call
in the call map. This is achieved by giving these instructions (another) special tag,
and it is easy to check statically that this has been done correctly.
If the code fails to initiate an exit
sequence at a point where the stack safety property expects a return,
the micro-policy will incorrectly behave as if execution
is continuing in the callee, but since the callee never has stronger access
rights than the caller, this is harmless.

\medskip
\paragraph*{Lazy Alternative}

The conservative policy described above is rather slow in
some important practical cases. Roessler and DeHon\cite{DBLP:conf/sp/RoesslerD18} observe
that most of the performance overhead incurred
stems from the need to set stack activation tags as a frame is created
and reset them as it is destructed;  this
is particularly costly for frames that contain large uninitialized arrays.
To mitigate those costs, they eliminate the costly frame initialization pass.

The most optimized version of the micro-policy, {\em Lazy Tagging and Clearing},
does not initialize stack frames on entry \emph{or} clear them on exit,
and it permits all writes to the stack, even when the $\PCname$ tag
does not match the memory tag; the \(\PCname\) tag is always propagated
to the written location. Reads from the stack \emph{do} require $\PCname$
tag and memory tag to match. Thus, even if a callee illicitly writes to
a private location in its caller, the caller will eventually detect this
if it ever tries to read from that location.

This \emph{lazy policy} admits a more efficient implementation, but
deliberately allows temporary violations of stack integrity.
The natural question then is: how do we characterize the
protections provided by these policies once stepwise stack safety is broken?
How does a harmful violation that must be caught later differ from a
harmless one?

\section{Observable Stack Safety}
\label{sec:lazy}

We answer these questions by introducing a notion of observations to our model.
This will also be useful when, for example,
a compiler wants to move data, overwrite its original location,
and ultimately restore it before the change becomes visible, as in
``callee-saves'' calling conventioons.
These examples call for an abstract mechanism to characterize behaviors that are externally
\emph{observable}.

We abstract over an
observation type \(\obs \in \OBSS\), containing at minimum the silent observation
\(\tau\). Our machine step function now takes a state and returns a state and an observation,
which is carried over into the policy and context step functions.

\paragraph*{Observations-Of}

This operator, written \(\obsof\), takes a machine trace and
gives the trace of observations of each step in
the trace. It uses a coinductive helper \(\mathit{obsfor}\) that relates an
initial observation, a machine-trace, and an observation trace; the helper is
then invoked with an initial \(\tau\).

  \judgmentthree{\(\mpcstatename \stepstocon[\obs'] \mpcstatename'\)}
                {\(\mpcstatename' \hookrightarrow \MPCT\)}
                {\(\mathit{obsfor} ~ \obs' ~ \MPCT = \obsT\)}
                {\(\mathit{obsfor} ~ \obs ~ \notfinished{\mpcstatename}{\MPCT} = \notfinished{\obs}{\obsT}\)}

\begin{minipage}[b]{.4\columnwidth}
  \judgment{}
           {\(\mathit{obsfor} ~ \obs ~ \mpcstatename = \obs\)}
\end{minipage}
\begin{minipage}[b]{.4\columnwidth}
\judgment{\(\mathit{obsfor} ~ \tau ~ \MPCT = \obsT\)}
         {\(\obsof(\MPCT) = \obsT\)}
\end{minipage}

\paragraph*{Observational Similarity}

We say that two observation traces $\obsT_1$ and $\obsT_2$ are {\em similar}
from the perspective of an external observer, written \(\obsT_1 \eqsim
\obsT_2\), if the sequence of non-silent observations is the same. That is, we
compare up to deletion of \(\tau\) observations, coinductively:

\begin{minipage}{.4\columnwidth}
  \judgment{}{\(\obsT \eqsim \obsT\)}
\end{minipage}
\begin{minipage}{.4\columnwidth}
  \judgment{\(\obsT_1 \eqsim \obsT_2\)}
           {\(\notfinished{\tau}{\obsT_1} \eqsim \obsT_2\)}
\end{minipage}

\begin{minipage}{.4\columnwidth}
  \judgment{\(\obsT_1 \eqsim \obsT_2\)}
           {\(\obsT_1 \eqsim \notfinished{\tau}{\obsT_2}\)}
\end{minipage}
\begin{minipage}{.4\columnwidth}
  \judgment{\(\obsT_1 \eqsim \obsT_2\)}
           {\(\notfinished{\obs}{\obsT_1} \eqsim \notfinished{\obs}{\obsT_2}\)}
\end{minipage}

\sna{Necessary? }
Note that an infinite silent trace is a
prefix of (and similar to) any other trace. While this might seem
surprising at first, it makes sense in a timing-insensitive context:
an external observer looking at two machine runs cannot (computably)
distinguish between a machine that steps forever and a machine that
steps for a long time before producing some output.

\paragraph*{Observational Stack Safety}

We now sketch observational versions of both integrity and confidentiality.
Integrity is already straightforward, simply weakening the condition that must hold
after the return---instead of preventing dangerous writes from being read, we
prevent them from being leaked.

\definition
\textbf{\em Observational integrity} means that for any \((\MPCT,\brk) \in \MPCT^*\)
where \(\head(\MPCT) = (\mach,\context\)) and \(\last(\MPCT) = (\mach',\context')\),
the following holds. Let \(\components = \prot(\context) \cap \Delta(\mach, \mach')\)
be the set of protected elements that changed during
the call,
and let \((\mach',\context') \hookrightarrow \MPCT'\).
Then for any \(\nach\) such that
\(\mach' \approx_{\components'} \nach\), and its induced trace
\((\nach,\context') \hookrightarrow \NPCT\), \(\obsof(\MPCT') \simeq \obsof(\NPCT)\).

\medskip

For confidentiality, we must capture the intuition that
secrets do not escape during a call {\em and} are not leaked during a return.
This require us to be able to quantify over elements that fail to preserve
the change-together relation~\(\diamond\).

\definition Let \(\mach,\mach'\) and \(\nach,\nach'\)
be pairs of states. Their {\em unsafe set}, written
\(\bar{\Diamond}(\mach,\mach',\nach,\nach')\), is the set of all elements
\(\component \in \Delta(\mach,\mach') \cup \Delta(\nach,\nach')\) such that
\(\mach'[\component] \not = \nach'[\component]\).

\definition
A system enjoys \textbf{\em observational confidentiality} if, for all
\((\MPCT,\brk) \in \MPCT^*\) with \(\head(\MPCT) = (\mach,\context)\) and
\(\components = \secret(\context)\), the following holds.
%
For any \(\nach\) such that \(\mach \approx_\components \nach\) and
\(\nach \hookrightarrow \NPCT | \brk(\MPCT)\),
\(\MPCT\) and \(\NPCT\) respect three conditions:

\begin{itemize}
\item They are observationally equivalent, \(\obsof(\MPCT) = \obsof(\NPCT)\),
  meaning that no secrets leak during the call
\item \(\brk ~ (\last(\MPCT)) \leftrightarrow \brk ~
(\last(\NPCT))\), i.e. if one call returns, so does the other
\item Assuming both calls return, let \(\last(\MPCT) = (\mach',\context')\)
  and \(\pi_\mach(\last(\NPCT)) = \nach'\),
  let \(\components' = \components \cap \bar{\Diamond}(\mach,\mach',\nach,\nach')\),
  and let \(\nach''\) be a state such that \(\mach' \approx_\components \nach''\).
  Then if \((\mach',\context') \hookrightarrow \MPCT'\) and
  \((\nach',\context') \hookrightarrow \NPCT'\), it must be
  that \(\obsof(\MPCT') \simeq \obsof(\NPCT')\)
\end{itemize}

This last condition is the most interesting: we identify the elements that
contain leaked information on either side of the first pair of variant traces.
This becomes the basis for the second variation, as all of these values
must be protected from leaking for the remainder of the program.

These two properties give us
{\em Observable Stack Safety}. This is a weaker property
than the stepwise one, and also much more extensional.
We can think of the stepwise properties as instantiating
the observation model with a view of the entire state---one end of a
spectrum that can become arbitrarily permissive.
Thus, if we had to choose a single property to represent stack safety,
it would be the observational one.

\medskip
\paragraph*{Connection to Policies}

Observable properties allow us to defer enforcement until a property
violation would become visible. Now we can identify when lazy policies
miss such violations. It turns out that {\em Lazy Tagging and Clearing},
as written, falls short of observational stack safety.
If, at depth \(d\), a callee \(A\) writes into its caller's
frame, then returns, and later another callee \(B\) at depth \(d\) reads the same
address and prints it, \(A\) has violated integrity in a way that later becomes visible,
and \(B\) has likewise violated confidentiality!

{\em Lazy Tagging and Clearing} can be repaired if, instead of tagging each function
activation with its depth in the stack, we generate a fresh activation
identifier on each call, which prevents a program from exploiting stale
tags from previous activations.
(A related mechanism was explored in the
Static Authorities policy of Roessler and DeHon \cite{DBLP:conf/sp/RoesslerD18}, which
associates a unique \emph{static} identifier to each function, which is shared
by all activations---but that policy allows leaks between
instances of the same function.) We validate this repaired micro-policy in
\cref{sec:testing}.

\medskip
\paragraph*{Callee-saves Registers}
\label{sec:callee}

Another application of observational properties is characterizing a ``callee-saves''
calling convention. Intuitively, a caller expects a callee-saves register to be unchanged on
return, but it may change during the call, as long as it is restored. We similarly expect a callee-saves
register to be secret from the callee, except when it is copied to the stack. Both scenarios
reflect observational rather than stepwise stack safety.

We model this by adding information to Call annotations defining which registers will be {\em saved}
and which are {\em unsaved}. The stack pointer and the register containing the return address
should never be saved. We then extend the set of domains with these values, for the first time associating
(non-{\em outside}) domains to registers as well as addresses. On each call, we save precisely those
registers given by the annotation, and the rest are unsaved; {\em saved} registers are treated as part
of the protected and secret sets for purposes of \textbf{\em Observational stack integrity} and
\textbf{\em Observational stack confidentiality}, respectively. For full formal definitions, see
Appendix \ref{app:calleesave}.


\medskip
\paragraph*{Parameters Passed on the Stack}
%
Up to this point we have ignored function arguments, by assuming that they are placed
in registers (which are implicitly shared by all functions).
We now show how to implement two kinds of protected
sharing of stack contents: passing by value on the stack and passing by reference.
Here we give an example and high level discussion; the formalization can be found in Appendix \ref{app:argpass}.

Figure~\ref{fig:passing} shows a sample trace of a program that passes
variables by reference. In this example, written in C++ notation,
{\tt f} takes a single argument by reference (the diagram displays it in magenta). The function
{\tt main} calls {\tt f}, passing a reference to {\tt x}, then clears {\tt x} and calls
{\tt f} again, passing a reference to {\tt y}.
We would expect that the first call to {\tt f} can modify
{\tt x}, but not the second. Unfortunately {\tt f} has hidden away our reference and modifies
{\tt x} in the second call. (Incidentally, this is perfectly compilable C++,
although its behavior is officially undefined.)

To avoid cluttering the picture at the assembly level, we revert to assuming that the
argument {\tt a} is passed in a register, namely {\tt \%ra}.
The question is how the local variables {\tt x} and {\tt y} themselves
should be labelled in order for the property to correctly classify an integrity violation.
Our notion of domains is extended to include \(\passed{\depth,\depth'}\),
recording two depths for reasons explained below.
At the initial call, the address of {\tt x} is marked as passed, and {\tt f} is free to write to it. Then upon
return, {\tt main}'s frame is unsealed. At the second call it is the address of {\tt y} that is marked as passed,
and when {\tt f} instead tries to write to {\tt x}, it violates integrity.


When passing by reference, it is possible to repeatedly pass the same reference further
and further down the stack. Note, however, that this sharing of the reference must be over
an unbroken chain of calls. So it suffices for the domain to track two depths for each passed
cell: the original owner, and the highest depth it has been passed to. The policy considers
it to be accessible anywhere between the two.

Our approach provides only limited support for handling fully first-class pointers into
stack frames, e.g., pointers obtained by taking the address of a local variable.
Unlike with pass-by-reference, there is no obvious way to model the intended
sharing behavior of such pointers in terms of stack frame activation patterns.
In general we expect such a pointer to behave similarly to heap pointers, 
except that its lifespan is connected to that of the frame that contains
it. In order to give a satisfactory property, then, we should tie it to a broader
heap safety property.

An alternative is to treat every address-taken variable in the
same way as a passed argument, with the modification 
that it remains accessible at \emph{all} stack depths above the caller.
Callees would be permitted
to access the location without having been explicitly given a pointer
to it. This would prevent most violations of temporal safety, but stale pointers
could still be used in certain corner cases.

\medskip

\paragraph*{Coroutines}

Our final extension to the model adds coroutines. We assume a very simple model with
a fixed number of coroutines, each with its own stack.
Stack identifiers are drawn from a set \(\STACKS\), and there is a static partial map
\(\stackof\) from addresses to stack ids.  Annotations and code maps are unchanged from
the subroutine model.
%\[\ann \in \ANNS ::= \callmap(P \subseteq \MACHS \times \COMPONENTS)\]
%\[\codemap \in \CODEMAPS ::= \addr \in \WORDS \rightharpoonup \ann \in \ANNS\]

The first major difference in this model is the domains. Stack domains are now nested inside
top-level domains, \(\topDom \in \TOPDOMS ::= \outside + \instack{\stackid}{\stackDom}\),
associated with stack identifiers.
Our context now consists of a domain map, a map from stack identifiers to return target stacks,
an additional map of targets for yields, and a stack identifier of the active stack.
A yield target map \(\yts\) is a map from stack identifiers to targets.
In a standard system an initial yield target map will map each stack identifier to the
set of all states with their stack pointer at the stack base, and include any restrictions
on entry points. Just as a return target tells us that we have really returned, a yield
target tells us that we have really yielded. When yielding from state \(\mach\),
\(\ycon ~ \mach \in \MACHS\) gives us the yield target for coming back to the yielding
coroutine.
%
\[\begin{array}{lr}
\multicolumn{2}{l}{(\domMap, \rtm, \yts, \stackid) \in \CONTEXTS ::=} \\
& (\COMPONENTS \rightarrow \TOPDOMS) \times
(\STACKS \rightarrow \listT(\target)) \times 
(\STACKS \rightarrow \target) \times \STACKS
\end{array}\]

The initial domain map maps each stack address in stack \(\stackid\) to
\(\instack{\stackid}{\unsealed}\), the initial return map maps all stack identifiers to empty
return stacks, the initial yield targets are defined as above, and the initial stack id matches the initial
coroutine. Together these form the initial context.

In our context update rules, calls and returns work the same as in the subroutine models,
with domain updates restricted to the top-level domain corresponding to the active stack,
and likewise using the return target stacks. We will omit these rules and focus on the new yield rule.

\begin{tabular}{l}
  {\sc Yield} \\
  \judgmenttwobr[]
                {\(\mach \stepsto \mach'\)}
                {\(\stackid \not = \stackid' = \stackof ~ (\mach'[\rsp])\)}
                {\(\yts ~ \stackid'\)}
                {\(\yts' = \yts[\stackid \mapsto \ycon ~ \mach]\)}
                {\(\mach,(\domMap,\rts,\yts,\stackid) \stepsto_C \domMap,\rts,\yts',\stackid'\)} \\
\end{tabular}

First, we determine which coroutine we are yielding to by
checking which stack the stack pointer of the next state is pointing to. Then we can only yield
if the next state is a valid yield target for that stack, and we update the yield target for
the current stack, ensuring that when the system yields back we expect the current coroutine
to continue from where it left off. So, it is possible for a coroutine to claim to yield
but not actually change the active stack, with similar effects to when a callee fails
to return properly. Now we can define both stack safety and coroutine safety under this model.

Stack integrity and confidentiality apply in the coroutine model, based on straightforward
projections of each stack's domains, etc. and the machinery of the passing model. We will give
the coroutine-specific properties.

\definition The \emph{yield set} \(\MPCT^\wedge\) of a system is
\[\begin{aligned}
\bigcup_{\stackid \in \STACKS} \hspace{-.5em} \{(\MPCT, \neg f_\stackid) | \MPCT\langle f_\stackid \rangle
\text{ is a reachable segment}\} \hspace{1em} \\
\text{where } f_\stackid ~ (\underscore,\underscore,(\underscore,\underscore,\underscore,\stackid')) \triangleq \stackid \not = \stackid' \\
\end{aligned}\]

\noindent
Here, we are capturing the entire span that the system spends {\em away} from a given
coroutine.

\definition
Let both \(\prot_Y(\domMap,\rtm,\yts,\stackid)\) and \(\secret_Y(\domMap,\rtm,\yts,\stackid)\) be the set of elements \(\component\) such that
\(\domMap ~ \component = \instack{\stackid'}{\underscore}\) where \(\stackid \not = \stackid`\).

\definition
We define \textbf{\em stepwise coroutine integrity} in the same way as stepwise stack integrity,
substituting the above \(\CONTEXTS\) type, initial context and update
function, and \(\prot_Y\) for their equivalents. Likewise
\textbf{\em observational coroutine integrity} is defined
in terms of their simple equivalents using \(\MPCT^\wedge\) in place of \(\MPCT^*\).

\definition
We define \textbf{\em stepwise coroutine confidentiality} in the same way as stepwise stack
integrity, substituting the above definitions. Likewise
\textbf{\em observational coroutine confidentiality} is defined in terms of observational
stack confidentiality.

\medskip

\paragraph*{Exceptions}

Exceptions are another useful form of control flow that disobeys the typical call and return pattern.
We can extend our model easily to handle integrity and confidentiality in the presence of exceptions.
In a typical exception model, the code point that ``catches'' a thrown exception is indicated by a {\tt setjump}
instruction or equivalent, which is later jumped to by a {\tt longjump}. We treat {\tt setjump} as placing
a special return target on the target stack, which then behaves like a normal return in terms of our properties.
A full treatment is given in Appendix \ref{app:exceptions}.

\section{Validation through Random Testing}
\label{sec:testing}

There are several ways to evaluate whether an enforcement mechanism enforces
stack safety properties. Ideally such validation would be done through formal proof over
the semantics of the enforcement-augmented machine.
However, while there are no fundamental barriers to producing such a proof,
it would be considerable work to carry out for a full ISA like RISC-V and
complex enforcement mechanism like the Depth Isolation micro-policy.
We therefore choose to validate the micro-policy of \cref{sec:enforcement} by 
systematically \emph{testing} that it satisfies our properties.
This focus on testing is better aligned with our immediate
goal of evaluating real enforcement mechanisms for real machine architectures.
Formal proof remains future work.

We validate the micro-policy of the previous section by
systematically testing that it satisfies eager stack integrity and
confidentiality. We use a Coq specification of the RISC-V
architecture~\cite{Bourgeat2021AMF},
and extend it with a runtime monitor implementing a stack safety
micro-policy. We chose the Coq proof assistant as the setting for our implementation
to ensure that our coinductive trace definitions are well-formed, to reason about
them, and to leverage the power of the QuickChick property-based testing framework~\cite{Pierce:SF4}.

To use QuickChick, we build random test-case generators that produce
% \begin{enumerate}
% \item
(1) an initial RISC-V machine state, including most notably
  the program to be executed;
  % \item
(2)
  an initial policy state, tagging instructions corresponding to
  blessed call or return sequences appropriately, while marking
  all potential stack locations as $\tagNoDepth$; and
% \item
(3)
 a code map identifying the locations of calls.
% \end{enumerate}

To write such generators we build on the work of
Hri\c{t}cu et al. \cite{TestingNI:ICFP, DBLP:journals/jfp/HritcuLSADHPV16}, which
introduced {\em generation by execution} to produce progams that lead
machines towards interesting behaviors. We extend the technique by tracking
control flow information so that programs will usually---but not always---return to their call sites.

%\paragraph*{Generators}
%
% Generation by
%execution receives as an input a partially instantiated machine state
%and attempts to generate an instruction (or a sequence of instructions
%such as a blessed sequence) that makes sense locally (e.g., jumps go
%to a potentially valid code location and loads read from a
%potentially valid stack location). Then we step the machine and repeat
%the process until we generate or execute some target number of
%instructions, or reach a point where the machine cannot step
%any more.
%
%We extend this technique to keep track of the control flow behavior of
%the program being generated: each time a call or return sequence is
%generated, we ensure that the appropriate policy tags and code
%annotations are set for the entry or return points.% At the same time,
%%we allow the generation to sometimes relax those constraints,
%%introducing potentially ill-formed flows: this causes our programs
%%to failstop when executed in conjunction with the policy monitor,
%%but also allows for revealing errors in our setup.\apt{??}
%
We need to extend typical testing schemes further to handle the nested
nature of confidentiality: rather than just generating two
initial machines that are variants of one another and letting them
execute to test for noninterference, we generate a new variant
{\em every time a call is made} and check confidentiality for the
subtrace produced from that variant state until its corresponding
return. As a result, a ``single'' confidentiality test compactly
checks multiple nested calls.

Our primary testing targets are the eager {\em Depth Isolation}
and the {\em Lazy Per-Activation Tagging and Clearing} micro-policies.
We test the former against stepwise integrity and confidentiality, and
the latter against their observational counterparts.

To ensure the effectiveness of testing against our formal properties, we
use {\em mutation testing}~\cite{JiaH11}. In mutation testing, we inject errors
(mutations) in a program that should cause the property of interest (here,
stack safety) to fail, and ensure that the testing framework can find
them. The bugs we use for our evaluation are either artificially generated
by us (deliberately weakening the micro-policy in ways that we expect
should break its guarantees), or actual bugs that we discovered through
testing our implementation. We elaborate on some such bugs below.

For example, when loading from a stack location, {\em Depth Isolation}
needs to enforce that the tag on the location being read
is $\tagStackDepth{n}$ for some number $n$ and that the tag of the
current $\PCname$ is $\tagPCDepth{n}$ for the same depth $n$. We can relax
that restriction by not checking the depth equality (row {\em
  LOAD\_NO\_CHECK\_DI}).

Similarly, when storing to a stack location, the correct micro-policy
needs to ensure that the tag on the memory location is either
$\tagNoDepth$ or has again the same depth as the current $\PCname$
tag. Relaxing that constraint causes violations to the integrity
property (row {\em STORE\_NO\_CHECK}).

\begin{table}[]
\centering
\begin{tabular}{c|c|c|c}
  Bug & Property Violated & MTTF (s) & Tests \\
  \hline
      {\em LOAD\_NO\_CHECK\_DI}  & Confidentiality & 24.2 & 13.3 \\
      {\em STORE\_NO\_CHECK} & Integrity & 26.9 & 26 \\
      {\em HEADER\_NO\_INIT} & Integrity & 69.5 & 76.3 \\
  \hline
  \hline
      {\em PER\_DEPTH\_TAG} & Obs. Integrity & 189.7 & 8342.5  \\
      {\em LOAD\_NO\_CHECK\_LT}  & Obs. Integrity & 23.5 & 12.0 \\
      {\em LOAD\_NO\_CHECK\_LT}  & Confidentiality & 19.2 & 695.5 \\
      {\em STORE\_NO\_UPDATE} & Obs. Integrity & 70 & 80.6  \\
      {\em STORE\_NO\_UPDATE} & Confidentiality & 4.9 & 88.5 \\
  \hline
\end{tabular}
\vspace*{1em}
\caption{MTTF for finding bugs in erroneous policy enforcement mechanisms}
\vspace*{-2em}
\label{tab:bug-table}
\end{table}

The mean-time-to-failure (MTTF) and average number of tests for various bugs can be found in
Table~\ref{tab:bug-table}, along with the average number of tests
it took to find the failure. Experiments were run in a desktop
machine equipped with i7-4790K CPU @ 4.0GHz with 32GB RAM.

Naturally, testing also revealed a number of errors in our
implementation of the enforcement mechanism (the original was written in C++
and targeted ARM machine code;
%\bcp{right?}\leo{yeah}
we re-implemented it in Coq targeting RISC-V).  These errors range
from trivial typos to ones that require an intriguingly complex setup
to provoke.  The most interesting bug (included in the table as row
{\em HEADER\_NO\_INIT}) was that, on our first try, the blessed call
sequence %/policy combination\apt{??}
did not initialize all locations for the
newly allocated stack frame correctly, but left some of them as
$\tagNoDepth$. This allowed for a potential integrity violation, but
only if a rather complicated sequence of events occured.
The smallest counterexample requires calling a function {\tt f},
which fails to initialize some of its frame during the blessed sequence,
but writes into an uninitialized location $l$ later, treating \(l\) as outside
the stack. Then {\tt f} calls a further function {\tt g} (which should have
the effect of sealing $l$ for integrity purposes). {\tt g} attempts to write to $l$,
which is allowed because the enforcement mechanism still has
$l$ tagged as $\tagNoDepth$, but violates the integrity property on {\tt f}'s data.
%\sna{I believe what went wrong was that we were off-by-one in {\tt main}'s initialization,
%  and the write from {\tt f} was already a violation.}

As for lazy micro-policies and observational properties,
the original {\em Lazy Tagging and Clearing} micro-policy, implemented as {\em PER\_DEPTH\_TAG},
fails in testing, in cases where data is leaked between sequential calls.
To round out our mutation testing we also check {\em LOAD\_NO\_CHECK\_LT},
equivalent to its counterpart in depth isolation,
and a version where stores succeed but fail to propagate the PC tag, {\em STORE\_NO\_UPDATE}.
It turns out that {\em PER\_DEPTH\_TAG} is a comparatively subtle bug,
taking twice as long to catch as the next longest.

Our properties have allowed us to identify an enforcement mechanism as
not really stack safe, and to validate a possible fix.
Unfortunately, Lazy Per-activation Tagging and Clearing
puts severe pressure on the tag cache, so it may not be usable in practice.
However, we conjecture that no lazy scheme can be fully stack safe
without using unique per-activation identifiers.

\section{Related Work}
\label{sec:relwork}

\paragraphx{Formal Stack Safety on Capability Machines}
%
To our knowledge, the only line of work to date that has attempted
a positive and formal characterization of stack safety
is that of Skorstengaard et al. \cite{SkorstengaardSTKJFP}. Their
StkTokens system enforces stack safety on hardware equipped with
memory capabilities, similar to those used in the Cheri system~\cite{Woodruff+14,Chisnall+15}, but
with additional support for linear capabilities.
They define Stack safety as the conjunction of local state encapsulation (LSE) and
well-bracketed control flow (WBCF).
Informally, LSE means that the current activation can only access its own frame,
and WBCF means that the topmost frame can only return to
the immediately adjacent frame below. Formally, these properties are defined
with reference to a capability machine with a built-in call stack and call and return
instructions; this machine is proven fully abstract with respect to a more
concrete capability machine, an approach termed ``fully abstract overlay semantics.''
We improve upon Skorstengaard et al. \cite{SkorstengaardSTKJFP} in two significant ways:

i) Our definition captures the intuition that {\em
  every} caller should be protected from its callees.  By contrast,
  Skorstengaard et al. \cite{SkorstengaardSTKJFP} describe a class of ``unreasonable'' components
  that are not protected, because they are capable of compromising
  their own security. Consider a function that, when called with the wrong
  inputs, behaves unreasonably. Skorstengaard et al. \cite{SkorstengaardSTKJFP} would not consider this a
  {\em reasonable component} (as defined in their section 4.3.3), as a reasonable
  component is always reasonable. In our setting, individual
  well-behaved activations of the buggy function would be protected.

ii) Skorstengaard et al. \cite{SkorstengaardSTKJFP}'s fully
  abstract overlay semantics rely on the definition of a ``stack-safe-by-construction''
  abstract machine that is closely tied to the underlying machine architecture.
  While the approach can no doubt be ported to other architectures and enforcement
  schemes, each such port will require a new abstract machine definition whose
  safety-by-construction must be argued afresh.
  Since we abstract over most of the machine state as well as the sealing and return conventions, and
  can support further enhancements such as coroutines,
  our properties apply directly to a range of architectures, code features, and enforcement mechanisms.

Skorstengaard et al. \cite{SkorstengaardSTKJFP} propose a useful list of five criteria for judging
candidate stack safety properties.
%% : they should be (1) intuitive; (2)
%% useful for reasoning; (3) reusable in secure compiler chains; (4)
%% arguably ``complete'' with respect to informal notions of stack
%% safety; and (5) potentially scalable to richer settings such as
%% dynamic code generation or multithreading.
%
In terms of (1) {\em intuitiveness}, we contend that our property
definitions are at least as
intuitive as theirs, though phrased in rather different terms.
We use the language of formal security
properties to apply well-established concepts \ifspace and formal techniques \fi
of noninterference, and we phrase our properties in terms of
traces of memory and register states, rather than an
ad-hoc abstract machine.
Which approach is ``better'' is probably a matter of taste, but ours
has \ifspace at least \fi the merit of explicitly relating stack safety to existing
notions of security.
%
Demonstrating (2) {\em usefulness} of the safety criterion
for carrying out formal proofs (about individual programs) for our proposal
remains future work; concretely, we
hope to apply our properties to justifying a low-level program logic.
%
(3) StkTokens is specifically set up to address {\em reusability} in secure
compilation chains, while this is not a goal of our work.\bcp{Can we explain
what it means??}
%
(4) Regarding {\em comprehensiveness} in capturing programmers' informal
understanding of stack safety, we believe that our support
for a dynamically changing notion of ``adversary,'' as outlined in point (i) above,
captures an even better definition of safety than LSE; moreover, our observational
properties are richer and\bcp{cut "richar and"??} more extensional, and thus
applicable to a broader range of enforcement mechanisms and code features.
%
(5) Finally, regarding {\em broad applicability}, we have demonstrated that
\bcp{unlike StkTokens}
our approach extends to
coroutines, a first step towards multithreading. Dynamic code generation is
more challenging, but StkTokens does not yet handle this either.

We would add one more criterion: reusability across machine models and
enforcement mechanisms. StkTokens has been used to validatate
one machine/enforcement mechanism---a linear-capability machine---via formal
proof. We have used ours to obtain a weaker (testing-based) validation of
two different mechanisms on a single machine; we hope to target a capability machine
next as future work.

\paragraphx{Protecting the Stack with Micro-Policies}
%
\apt{Could probably condense/omit this.}
Roessler and DeHon \cite{DBLP:conf/sp/RoesslerD18}
study the protection of stack data through three families of
micro-policies that tag stack objects with a pair of frame and object identifiers
used to validate accesses: {\em Return Address Protection} (which
prevents an adversary from overwriting designated return addresses), {\em Static
Authorities} (which only allows the code of a function to access the stack frames
of its own dynamic instances), and {\em Depth Isolation}
(\cref{sec:enforcement}). All these policies strike various balances between
precision and performance, evaluated through benchmarks that demonstrate
limited performance overhead. In addition to the baseline ``eager'' policies,
they propose a number of lazy optimizations, notably {\em Lazy Tagging} and
{\em Lazy
Clearing} (\cref{sec:lazy}).

We evaluate {\em Depth Isolation} and {\em Lazy Tagging and Clearing}
against our properties, finding that the former does
indeed enforce stepwise stack safety and therefore observable stack
safety. We find that the latter does not actually enforce
stack safety, and we proposed a fix.

\paragraphx{Heap Safety as a Security Property}
%
Azevedo de Amorim et al.~\cite{DBLP:conf/post/AmorimHP18} show that 
heap safety may be framed as a security property using
the language of noninterference. Their paper was a significant inspiration
for the present work, and we believe that the two safety conditions should
combine smoothly.

\section{Future Work}
\label{sec:future}

From here, we see two natural ways to extend the work. \apt{what about addressing some of the limitations?}
First, we should thoroughly evaluate
other enforcement mechanisms, especially Cheri-based capability
systems. Second, we can further demonstrate
the functionality of our definitions by using them to prove
the correctness of a programming logic with strengthened rules around calls and returns.

\paragraphx{Stack Safety in the Cheri Ecosystem}
%
There are several proposals around the use of Cheri capabilities to enforce stack safety,
including mechanisms that use the standard Cheri hardware (which includes local
capabilities) \cite{SkorstengaardLocal},
and others that propose entirely new types of capabilities, such as linear
\cite{SkorstengaardSTK}, uninitialized \cite{Georges+21}, lifetime
\cite{Tsampas+19}, and monotonic \cite{GeorgesComplete} capabilities.
Of these, uninitialized capabilities seem particularly promising---they naturally enforce
write-before-read behavior and therefore will enable confidentiality without the need
to clear large swaths of the stack. We plan to implement a model of the stack safety
system described by Georges et al. \cite{Georges+21} and test it against our properties using
QuickChick.

\paragraphx{A Program Logic for Stacks}
%
Stack integrity suggests a reasoning principle in which knowledge about a
caller's local data can be carried across a call site. We aim to develop
this idea into a low-level separation logic with a ``call rule'' that
preserves propositions whose domains are sealed across a call, while
allowing those propositions proven about the behavior of the callee to apply
to the accessible stack.
%
It is easy to imagine that such a rule could be proven sound in a system
with lockstep stack safety. More challenging would be to ask what kind of
proof rule would be appropriate for a system that obeys only our
observational properties.

%% Acknowledgments
%\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
%  This material is based upon work supported by the
%  \grantsponsor{GS100000001}{National Science
%    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
%  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
%  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
%  conclusions or recommendations expressed in this material are those
%  of the author and do not necessarily reflect the views of the
%  National Science Foundation.
%\end{acks}


%% Bibliography
\bibliographystyle{IEEEtran}
\bibliography{bcp.bib,local.bib}

\pagebreak

%% Appendix
\appendices
\section{Formalization of Callee-saves Registers}
\label{app:calleesave}

In order to support callee-saves registers, we extend {\sc Call} annotations to
carry information about which registers are to be saved and which are used for arguments,
etc. This takes the form of a ``saving function'' \(S\) that maps registers to domains \(\saved\) and
\(\unsaved\). These also extend \(\STKDOMS\).

\[\begin{split}
\codemap \in \CODEMAPS ::= & \WORDS \rightharpoonup \callmap(S)\\
\mbox{\rm{where}} ~ & S \in \REGS \rightarrow (\unsaved + \saved) \\
\end{split}\]

\[\begin{split}
\stackDom \in \STKDOMS ::= & \outside + \unsealed + \sealed{\depth} \\
& + \unsaved + \saved \\
\end{split}\]

This property reuses most of the structure of the core property. Here we will highlight
the definitions that have changed. Namely, the {\sc Call} rule for \(\stepsto_C\) now
applies the saving function to determine which registers are saved. The remaining rules
remain unchanged. Note that this means that at any given time, a register will be marked
\(\saved\) or \(\unsaved\) depending on the most recent call chronologically (i.e., it is
not nested like \(\sealed{\underscore}\)). This is because the protected and secret sets will be based
only on the entry state of the call, and those are all that affect observational properties.

\begin{tabular}{l}
  {\sc Call} \\
  \judgmenttwobrlong[]
                    {\(\codemap ~ (\mach ~ \PCname) = \callmap(S)\)}
                    {\(\components = \{\component | \sealcon ~ \mach ~ \component\}\)}
                    {\(\domMap' = \domMap[\components \mapsto \sealed{|\rts|}][\reg \mapsto S(\reg) ~ | ~ r \in \REGS]\)}
                    {\(\mach,(\domMap,\rts) \stepsto_C \domMap',(\retcon ~ \mach)::\rts\)} \\
\end{tabular}

\definition Let the protected set of a context, \(\prot_S(\domMap,\rts)\),
be the set of elements \(\component\) such that either \(\domMap ~ \component = \sealed{\underscore}\)
or \(\domMap ~ \component = \saved\).

\definition Let the secret set of a context, written \(\secret_S(\domMap,\rts)\),
be the set of elements \(\component\) such that
\(\domMap ~ \component = \sealed{\underscore}\), \(\domMap ~ \component = \unsealed\), or
\(\domMap ~ \component = \saved\).

\definition
%
\textbf{\em Observational stack integrity} with callee-saves registers substitutes the above
\(\CONTEXTS\) type and update function, and \(\prot_S\), for its equivalent in the simple model.
%
\textbf{\em Observational stack confidentiality} additionally substitutes \(\secret_S\).

\section{Formalization of variable passing.}
\label{app:argpass}

We add extra information to our call
annotations to reflect that they may now pass variables on the stack, and that the locations
of those variables may be dynamic (as in the case of pass-by-reference).
A call annotation now includes a predicate relating machine states to the elements
that should be passed, expressed as offsets from the stack pointer.
\[\codemap \in \CODEMAPS ::= \WORDS \rightharpoonup \callmap(P)~\mbox{\rm where}~P \subseteq \WORDS\]
We extend the set of domains to include passed elements,
which are labeled with the range of depths of the caller that has passed them.
\[\begin{split}
\stackDom \in \STKDOMS ::= & \outside + \unsealed\\
& + \sealed{\depth} + \passed{\depth,\depth'}
\end{split}\]

We straightforwardly describe how the sealing convention and passing predicate combine to
update a domain map at a call from depth \(\depth\), written as functions \(\mathit{push}\)
and \(\mathit{pop}\) and written here as inference rules.

\judgmentthree[]
              {\(\domMap ~ \component = \unsealed\)}
              {\(\sealcon ~ \mach[\component]\)}
              {\(\component - (\mach ~ \rsp) \not \in P\)}
              {\((\mathit{push} ~ \domMap ~ \sealcon ~ P ~ \mach ~ \depth) \component = \sealed{\depth}\)}
\judgmentthree[]
              {\(\domMap ~ \component = \unsealed\)}
              {\(\sealcon ~ \mach[\component]\)}
              {\(\component - (\mach ~ \rsp) \in P\)}
              {\((\mathit{push} ~ \domMap ~ \sealcon ~ P ~ \mach ~ \depth) \component = \passed{\depth,\depth+1}\)}
\judgmentthree[]
              {\(\domMap ~ \component = \passed{\depth',\depth}\)}
              {\(\sealcon ~ \mach[\component]\)}
              {\(\component - (\mach ~ \rsp) \in P\)}
              {\((\mathit{push} ~ \domMap ~ \sealcon ~ P ~ \mach ~ \depth) \component = \passed{\depth',\depth+1}\)}
\judgment[]
         {}
         {\((\mathit{push} ~ \domMap ~ \sealcon ~ P ~ \mach ~ \depth) \component = \domMap ~ \component\)}

\judgment[]
         {\(\domMap ~ \component = \sealed{\depth}\)}
         {\((\mathit{pop} ~ \domMap ~ \depth) \component = \domMap ~ \component\)}
\judgment[]
         {\(\domMap ~ \component = \passed{\depth-1,\depth}\)}
         {\((\mathit{pop} ~ \domMap ~ \depth) \component = \domMap ~ \component\)}
\judgmenttwo[]
           {\(\domMap ~ \component = \passed{\depth',\depth}\)}
           {\(\depth' < \depth\)}
           {\((\mathit{pop} ~ \domMap ~ \depth) \component = \domMap ~ \component\)}
\judgment[]
         {}
         {\((\mathit{pop} ~ \domMap ~ \depth) \component = \domMap ~ \component\)}

These are applied to update the context at calls and returns, respectively.

\begin{tabular}{l}
  {\sc Call} \\
  \judgmentbr[]
              {\(\codemap ~ (\mach ~ \PCname) = \callmap(P)\)}
              {\(\domMap' = \mathit{push} ~ \domMap ~ \sealcon ~ P ~ \mach ~ |\rts|\)}
              {\(\mach,(\domMap,\rts) \stepsto_C \domMap',(\retcon ~ \mach)::\rts\)} \\
\end{tabular}
              
\vspace*{-1ex}
\begin{tabular}{l}
  {\sc ReturnFound} \\
  \judgmenttwo[]
              {\(\mach \stepsto \mach' \in \target\)}
              {\(\domMap' = \mathit{pop} ~ \domMap ~ |\rts|\)}
              {\(\mach,(\domMap,\target::\rts) \stepsto_C \domMap',\rts\)} \\
\end{tabular}

\vspace*{-1ex}
\begin{tabular}{l}
  {\sc ReturnRec} \\
  \judgmenttwo[]
              {\(\mach,(\domMap,\rts) \stepsto_C \domMap',\rts'\)}
              {\(\domMap'' = \mathit{pop} ~ \domMap' ~ |\rts|\)}
              {\(\mach,(\domMap,\underscore::\rts) \stepsto_C \domMap'',\rts'\)} \\
\end{tabular}

\definition The \emph{protected set} of a context, \(\prot_P(\domMap,\rts)\),
is the set of elements \(\component\) such that either \(\domMap ~ \component = \sealed{\underscore}\)
or \(\domMap ~ \component = \passed{\depth,\depth'}\) and \(|\rts| < \depth\) or
\(|\rts| > \depth'\).

\definition The \emph{secret set} of a context, written \(\secret_P(\domMap,\rts)\),
is the set of elements \(\component\) such that
\(\domMap ~ \component = \sealed{\underscore}\), \(\domMap ~ \component = \unsealed\), or
\(\domMap ~ \component = \passed{\depth,\depth'}\)
where \(|\rts| < \depth\) or \(|\rts| > \depth'\).

\definition
For each of the \textbf{\em stepwise} and \textbf{\em observational} versions of
\textbf{\em stack integrity} in the simple model, the equivalent property in the
passing model substitutes the above \(\CONTEXTS\) type and update
function, and \(\prot_P\), for their equivalents in the simple model.

For both the \textbf{\em stepwise} and \textbf{\em observational} versions of \textbf{\em stack confidentiality} in
the original model, the passing model equivalents additionally substitute \(\secret_P\).

\section{Formalization of Exceptions}
\label{app:exceptions}

Our core formalism already models control flow patterns in which a return skips over one or more callers to
reach a point further down the call stack. This is essentially the behavior of an exception; we need only add an
annotation representing the {\tt setjump} operation or equivalent to enable a ``return'' to an arbitrary point
not associated with a call. We add an annotation, {\sc SetJump}, and define a target label as either a call-return
or an exception, \(\mathit{TL} ::= \text{\sc CR} + \text{\sc EX}\), which annotates targets in the return stack.
\[(\domMap,\rts) = \context \in \CONTEXTS ::= (\COMPONENTS \rightarrow \STKDOMS) \times \listT (\mathit{TL} \times \target) \]

We add a rule to handle {\sc SetJump} annotations, and modify the {\sc Call} rule to insert {\sc CR} labels into the
return stack.

\vspace*{1em}
\begin{tabular}{l}
  {\sc SetJump} \\
\judgment[]
         {\(\codemap ~ (\mach ~ \PCname) = {\sc SetJump}\)}
         {\(\mach,(\domMap,\rts) \stepsto_C \domMap',(\text{\sc EX}, \retcon ~ \mach)::\rts\)}
\end{tabular}

\begin{tabular}{l}
  {\sc Call} \\
  \judgmenttwobrlong[]
                    {\(\codemap ~ (\mach ~ \PCname) = \callmap\)}
                    {\(\components = \{\component | \sealcon ~ \mach[\component]\}\)}
                    {\(\domMap' = \domMap[\components \mapsto \sealed{|\rts|}]\)}
                    {\(\mach,(\domMap,\rts) \stepsto_C \domMap',(\text{\sc CR}, \retcon ~ \mach)::\rts\)} \\
\end{tabular}

The return rules operate identically to the core model, regardless of the target labels.

\definition
We define \textbf{\em stepwise stack integrity}, \textbf{\em stepwise stack confidentiality},
\textbf{\em observational stack integrity}, \textbf{\em observational stack confidentiality},
in the same way as in the core model, substituting the above \(\CONTEXTS\) type and update
function for their original.

\definition
A system enjoys \textit{\textbf{well-bracketed control flow}} with exceptions when, for every reachable state
\(\mpcstatename\) where \(\pi_\context(\mpcstatename) = (\underscore,\rts)\), and
\(\mpcstatename \stepsto \mpcstatename'\) where \(\pi_\context(\mpcstatename') = (\underscore,\rts')\),
if \(|\rts'| < |\rts|\), then either \(|\rts'| = |\rts|-1\) or \(\rts = \underscore +\!\!+ (\text{\sc EX},\underscore)::\rts'\).

\end{document}
