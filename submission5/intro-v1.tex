\rb{\textbf{The call stack and its security.} Maybe a few opening words to set
  the stage and bring two things to the front: (1) functions and subroutines as
  fundamental building blocks of any kind of structured programming; and (2) the
  stack as the natural abstraction to manage these in a computer. And also maybe
  a little bit more about the width, the gravity and the \emph{foundational
  nature} of attacks on the stack, which the sentence below touches on
  summarily.}
%
The call stack is a perennial target for low-level attacks, leading to
dire consequences from leakage and corruption of private stack data
to control-flow hijacking.
%
\rb{We can mention things like e.g. the most recent CWE Top 25 Most Dangerous
    Software Weaknesses from MITRE, cf.
    \url{https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html}, where
    e.g. \#1 (Out-of-bounds Write), \#5 (Out-of-bounds Read) and \#7 (Use After
    Free), that is a good number of the most important and prevalent
    vulnerability types are closely related to the stack. These will show up in
    other popular rankings as well.}
%
To foil such attacks, a menagerie of
software and hardware protections have been proposed,
%
including stack canaries~\cite{Cowan+98},
bounds checking~\cite{NagarakatteZMZ09,NagarakatteZMZ10,DeviettiBMZ08},
split stacks~\cite{Kuznetsov+14},
shadow stacks~\cite{Dang+15,Shanbhogue+19},
capabilities~\cite{Woodruff+14,Chisnall+15,SkorstengaardLocal,SkorstengaardSTKJFP,Georges+21},
and hardware tagging~\cite{DBLP:conf/sp/RoesslerD18}.
  \ifaftersubmission\apt{Mostly from
  nick; there could be more}\bcp{Yes, going back to MIT days---we should
  include several more of these, if only to give readers the impression that
this is a well-studied mechanism (so formalizing its protections is
useful).}
\fi
%
\rb{Did we want to add even more techniques? Is this selection broad enough?
  Anyway reference that we'll be looking at these more closely later.}

The protections offered by such mechanisms are commonly described by giving
concrete examples of attacks that they can prevent---corruption of return
addresses, buffer overflows, use of uninitialized variables, etc.---leaving
a more formal characterization to the reader's intuition.
%
\rb{Begins to anticipate subsequent discussion. This is even something of an
  understatement: some papers (esp. newer ones?), make concrete claims, though
  they remain informal. Arguably, none have a truly formal characterization in
  mind (with the qualified exception of \cite{SkorstengaardSTKJFP}): this is one
  of the novelties of this work!}
%
Previous attempts
to produce a formal characterization do so using a {\it fully abstract overlay semantics},
a style of correct-by-construction machine \cite{SkorstengaardSTKJFP}.
But this approach is not suitable for the {\em lazy} enforcement mechanism
of Roessler and DeHon, in which stores are not checked, and illegal stores are
only caught when their location is later read. We aim to provide a stack-safety
property suitable for testing lazy enforcement.
%
\rb{Need to discuss overlay semantics, but also note that it is very intensional
  and very specific, as the authors acknowledge. I'd introduce this a bit more
  gradually. Also, if phrased this way, it sounds like its main drawback is a
  lack of generality, to which we should contrast a more general approach, not
  just one that is specialized to a specific policy, i.e. lazy micro-policies
  (I'd try to present these more gradually as well).}

We propose a novel characterization of stack safety using the formal tools of language-based
security~\cite{sabelfeld2003language}, decomposing stack safety into
the {\em integrity} and {\em confidentiality} of the callerâ€™s local state
and the callee's behavior during the callee's execution, plus the control flow protection
of {\em well-bracketed control flow}~\cite{SkorstengaardSTKJFP} (\(\wbcf\)).
\ifexceptions
We also extend WBCF to a setting with exceptions,
in which there may be multiple points at which a callee can ``return.''
\fi
%
\rb{Connect this to the shortcomings of previous work. I'd give at least a quick
  explanation of what the various properties roughly entail in practice (e.g.,
  secrecy of private data, etc.). The comment about the single extension of
  exceptions seems disconnected from the rest.}

This gives us a total of five core properties: \(\wbcf\)
caller integrity (\(\clri\)), caller confidentiality (\(\clrc\)),
callee integrity (\(\clei\)), and callee confidentiality (\(\clec\)).

To demonstrate the utility of our formal characterization, we use these
properties to validate and improve an existing enforcement mechanism, the
{\em stack safety micro-policies} of Roessler and DeHon~\cite{DBLP:conf/sp/RoesslerD18}, re-implemented
in the Coq proof assistant on top of a \rb{formal} RISC-V specification.  We
use QuickChick~\cite{Denes:VSL2014,Pierce:SF4}, a property-based testing
tool for Coq, to generate random programs and check
that Roessler and DeHon's micro-policies correctly detect the ones that
attempt to violate one of our properties. Furthermore, we
check that the testing framework is able to generate counterexamples
that violate our properties but are \emph{not} halted by incorrect
variants of the enforcement mechanisms, including ones that we accidentally created
while implementating the micro-policy and ones that we
intentionally crafted to increase our confidence in the effectiveness
of our testing.
%
\rb{This and the following paragraph could start more generally (we need to
  answer the question of why these experiments, what is their interest), and
  probably motivate the use of PBT (experiment results below show there's
  benefit in them!) and, somewhere at least, talk about other points in the
  spectrum.}

We find that Roessler and DeHon's \emph{Lazy Tagging and Clearing}
violates the temporal aspect of confidentiality in
cases where data can leak across repeated calls to the same callee,
and also violates integrity if the leak uses the caller's frame. We
propose a variant of {\em Lazy Tagging and Clearing} that testably enforces
confidentiality, albeit at some performance cost.
%
\rb{Anything to add from personal communications? More details later? Shows
  these things are very hard to get right -- like the latest work on Cerise,
  also motivated by this very work.}

\subsection{Motivation}

Security mechanisms designed to prevent a certain attack can be brittle---successfully
eliminating the attack as it exists at the time of publication, but leaving room for attackers
to find new, similar attacks. To mitigate this risk, mechanisms should aim to enforce formal
properties of correct behavior that can be proven or tested. Such properties become the
specification against which enforcement can be validated; even enforcement mechanisms that do
not fulfill the property benefit from the ability to articulate {\it why} they fail.
%
\rb{Good stuff! There is some overlap between this discussion and the opening
  motivation, maybe we could restructure things a bit so that those threads are
  unified?}

Stack safety is challenging to specify in full generality, because the stack is fundamentally
an architecture-specific construct. (Contrast Acevedo de Amorim et al.'s \cite{} work on heap safety,
which is broadly consistent across architectures and language semantics, and therefore amenable
to a very general approach.)
The desired behavior of the stack varies based on ISA, calling convention,
and the features of whichever programming language originated the code.
For instance, the current state-of-the-art stack-safety specification from Georges et al.
\cite{Georges22:TempsDesCerises} supposes a machine with only straightforward call-and-return
control flow, and therefore defines {\it Well-bracketed Control Flow} (WBCF) under the assumption that
a callee should always return to its caller. But, in the presence of tail-call elimination, a
return from a callee to a distant ancestor is perfectly reasonable. Any addition of new features
must be accompanied by tweaks to the model.
%
\rb{This point is extremely important!}

We are not attempting to create a universal definition of stack safety for all systems.
Rather, we define the stack safety of a single, fairly realistic system, decomposed into
(1) a lightweight model of the system and its security-relevant features, from which we
derive the integrity, confidentiality, and control-flow requirements of each call and
return, (2) the application of that model to a particular target system, and (3)
the formal criteria for integrity, confidentiality, and control flow
to obey the requirements. We consider the criteria in (3) to represent universal definitions
that are parameterized by (1).
%
\rb{Sharpen, contrast the universal definitions (or a framework of parametric
  definitions, say) with the concrete instance we study, again with its interest
  properly motivated.}

We treat stack safety as multiple properties, rather than one multi-faceted property, because
not all enforcement mechanisms attempt to implement all aspects of stack safety. Some focus
exclusively on control flow, some enforce integrity but not confidentiality, and many
focus on the caller over the callee.
%
\rb{Also sharpen after extended discussion?}

\paragraph*{Permissiveness, Laziness, and Tagged Architectures}

Security properties tend to be conservative, identifying violations that would be
harmless in practice. But enforcement mechanisms make trade-offs in the name of performance
and of compatibility with existing codebases. In a crucial motivating example for this work,
Roessler and DeHon \cite{} present a collection of tag-based enforcement mechanisms
using PIPE \cite{???}, a tagged hardware reference monitor. In monitors such as PIPE and
STAR \cite{???}, every value in memory and registers is paired with a {\em metadata tag}.
A set of software-defined rules, termed a micro-policy, determines the tags for operation
results based on the tags of their inputs---or, if the input tags are in a dangerous
combination, it may halt the machine (a ``failstop.'')

Roessler and DeHon find that the intuitive way to enforce stack safety in this setting
is inefficient when allocating and clearing stack frames, because each word must be initialized
with a tag corresponding to the (depth of the) current function activation. They propose
{\em Lazy Tagging and Clearing}, in which tags are not initialized at allocation, but only
when a function writes to memory. This means that writes cannot be prevented, necessarily
violating existing models of stack safety. Instead the micro-policy enforces that memory be
read by the same fuction that wrote it. The owner of the data will never see the changes,
so it is secure in the sense that the attacker is unsuccessful at changing program behavior
(except, perhaps, by causing a fault.) We elaborate that sense, and test whether the
micro-policy fulfills it.

This key motivation leads us to present integrity and confidentiality as predicates on (pairs of)
machine states that make claims about the future observable behavior of execution from those states.
That is not to say that our properties are specialized for lazy micro-policies. It also supports
normal ``eager'' micro-policies, and should support other enforcement mechanisms. In fact, \(\clri\)
and \(\clrc\) are even weaker than necessary to support Roessler and Dehon's micro-policy,
while \(\clec\) and \(\clei\) are stronger properties that they do not attempt to enforce.
%
\rb{Does this discussion (at least in part) belong in the general background
  section, some even in key ideas? It still feels a little out of order to me,
  and occasionally too detailed for the introduction?}

\rb{\textbf{A menagerie of protection mechanisms.}
%
We have made explicit the key point that there is \emph{not} a single stack
abstraction. This paves the way for a \emph{general} idea of stack protection
that is widely applicable with high-level concepts that remain unchanged (and I
think it's particularly important to at least introduce these more immutable
parts early on). The fact that this general ``framework'' requires low-level or
specific specializations is a predictable consequence of the protean nature of
the call stack.
%
\\
%
Let us return to a selection of representative policies in our menagerie and
consider how they fit into the framework. At the highest level, we can classify
all those techniques into two large groups, software-based and hardware-based.
Traditionally, most practical protections are implemented in software, so we
start by considering this first group.
%
\\
%
We can make two general observations about these software based techniques.
Firstly, (as we will see: discussion? technical details?) these techniques are
\emph{less modular} than their hardware counterparts. That is, the
countermeasures are tightly coupled with the program code they protect, and
consequently more effort is required to disentangle the program from the
protections, and to understand the impact of the latter on the former. This is
true of any systematic attempt to study the security of stack protection
policies, including their adaptation to our framework. (Owing to this added
complexity, software policies will not be the cleanest or most elegant exemplars
of use of the framework, its salient features and practical utility; this partly
motivates the focus on hardware policies.)
%
\\
%
(The above remark holds \emph{at least in a ``single-level model''} that
considers assembly language/machine code programs. In general, (low-level)
protections are introduced by a compiler or similar tool. One could consider a
multi-level extension of the framework pairing models of high-level programs and
the security transformations performed by a (stack-secure) compiler.)
%
\\
%
Secondly, the guarantees generally offered by software-based policies are
\emph{less absolute}, being defined more or less informally and usually
providing few definite guarantees of absence of \emph{general} classes of
errors. (The following discussion elaborates on this. It is conceivable that an
extended and more sophisticated framework could add \emph{probabilistic
reasoning} capabilities to capture and reason about the effects of less strict
protection mechanisms. This would be another orthogonal development to what is
presented here. In this paper, we are interested in assessing the complete
\emph{absence} of broad classes of vulnerabilities --- modulo any modeling gaps
or defects. In passing, this would extend the security properties to e.g. larger
system verification efforts.)
%
\\
%
One by one, consider the following specimens of software protection mechanisms
(quick explanations inlined?):
%
\\
%
\begin{itemize}
%
\item \emph{Stack canaries}. The purpose of canaries is to \emph{increase} the
  difficulty of some attacks on the stack, usually (always?) buffer overflows.
  They can never provide any absolute security guarantees and therefore do not
  satisfy any of our properties (some of the properties, e.g. confidentiality,
  are completely out of scope.) Although tedious, we could we could model this
  mechanism in our framework with the appropriate adaptations --- and
  unsurprisingly, testing would find property violations, which we already know
  are there: the results of this effort would be unsurprising and not as useful
  or instructive as other experiments.
%
\item \emph{Bounds checking}. This is fundamentally a high-level technique, even
  more obviously so than stack canaries (which could still detect violations
  caused by external code). Bounds checking only applies to code that has been
  instrumented by the ``secure compiler'' (i.e., to whole programs); it does not
  impose any constraints on adversarial code. The attacker model is therefore
  rather weak. (Certain variants, like SoftBound, are good targets for lifting
  our framework to the source level by e.g. using a C-language semantics and
  using Tagged C for security modeling; the lifted versions of our properties
  would likely hold under the expected assumptions. HardBound is probably an
  interesting transitional case because it uses capability-like hardware
  primitives for enforcement; it could be close to ongoing and future work to
  verify stack safety on capability machines, e.g. based on Cerise -- discuss
  together?)
%
\item \emph{Shadow stacks}. Like stack canaries, shadow stacks are
  ``probabilistic techniques'' in that they ``restrict the flexibility available
  in creating gadget chains'' (Shanbhogue et al.). This technique is solely
  concerned with control-flow integrity, and so closely related to our
  well-bracketed control flow. Nevertheless, and again, it is only an
  approximate technique, and our testing framework would be able to find the
  expected attacks against our security property.
%
\item \emph{Split stacks}. The security claims of split stacks are stronger than
  those of most software countermeasures, i.e., they are meant to guarantee
  their titular code-pointer integrity. They explicitly offer no protections on
  stack data (i.e., integrity and confidentiality), and so restrict themselves
  to well-bracketed control flow. (This is probably closer to our framework than
  most other software techniques, and it seems like it would be easier to model
  as well. However, this is again work based on high-level languages and would
  benefit from a higher level of abstraction.)
%
\item \ldots
%
\end{itemize}
%
Opposed to the above group of software techniques we have hardware-based
protection policies (more in background/technical preliminaries?). Although
programs must effectively leverage the protection mechanisms offered by the
hardware, the distinction between those protections and the program logic itself
is much cleaner: it is fairly simple to separate the use of the security
features in the hardware (and their effects in program code) from regular
program code. They also tend to aspire to offer complete protection against
entire classes of attacks. Both aspects make this family of techniques a better
fit for illustrating and showcasing our techniques.
%
\\
%
Why favor micro-policies? Their design is more flexible and arguably more
general than capability machines (of course, they pay a performance price for
this). This generality and ease of programming make them good candidates for an
exploration the design space of stack protection policies and proof of concept
implementations. On the practical side, there is a number of existing policies
available to examine (not just lazy policies!) --- and we find how they satisfy
our properties, how they do not, and errors in some of them, and see how to
correct them. Lazy enforcement is particularly novel, but not the only
possibility. This additional breadth is beneficial for the proof of concept
stage.
%
\\
%
Regarding capability machines, we know that most designs based on capability
machines do not satisfy our properties (or do so incurring significant costs),
and that fixes are not trivial and involve new types of capabilities (in a
sense, are they any more ``realistic?'' Only the latest Cerise paper would seem
to satisfy our properties, is directly influenced by previous versions of this
work, and is a reasonable target for ongoing/further study -- but this is not
easy, and even the author(s) estimate it would be a significant amount of work,
especially full proofs (references, communications, etc.).
%
\\
%
\ldots
%
}

\subsection{Contributions}

In sum, we offer the following contributions:

\begin{itemize}
\item We formalize permissive stack confidentiality and integrity properties,
  which are parameterized over a notion of external
  observation, and are violated only if accessing secrets or overwriting
  data causes a visible change in system behavior.
\item We instantiate these definitions with a realistic
  system with features such as argument passing
  on the stack, callee-saves registers, and tail-call elimination.
  Our model is modular enough that adding these features is straightforward.
\item Our formalization of well-bracketed control flow in the presence of tail-call
  elimination \ifexceptions and exceptions \fi is a novelty over existing models.
\item We use property-based random testing to validate the relationship between
  our properties and micro-policies.
\end{itemize}

Our artifact contains Coq formalizations of our properties for illustrative purposes
as well as their testing implementation. There are no proofs---we use primarily Coq for the
QuickChick library and to ensure that the formalizations are unambiguous.
%
\rb{Will have another look after the full pass.}

\paragraph*{Limitations}

%Our concurrency model is fairly
%simplistic, assuming a fixed number of threads each with its own dedicated processor.
We model memory-safe stack objects, but not a heap. Regions outside of
stacks can be used however the compiler likes, including as a heap, but no protection is
built in and our properties assume that if a pointer to a stack object is stored there,
it is permanently compromised.

Our properties are termination insensitive: in order to support enforcement mechanisms
that failstop rather than execute dangerous code, the properties must treat failstops
as invisible to the attacker. We extend this insensitivity to all errors for simplicity.
This is consistent with our treatment of properties that specify the state after a return,
in that a callee that diverges for any reason will never reach the return, and will fulfill
the property vacuously.
%
\rb{Limitations in the introduction or later? Orthogonality of the heap, morally
  similar interesting setups on the stack? Termination sensitivity and
  capability machine semantics?}
