\subsection{The Call Stack and Its Security}

Computer programming relies on functions (subroutines, procedures, methods, etc.)
as a foundational abstraction. Functions are units of computation that
can call one another to realize larger computations.
%
At a low level, a function activation comprises its own data, as
well as information about its \emph{caller} function, to which it must return.
The \emph{(call) stack} is the fundamental data structure charged with realizing
this abstraction. From a security perspective, attacks on the stack are attacks
on the fundamental functional abstraction itself, and are therefore every bit as
pervasive.

Indeed, the call stack is a perennial target for low-level attacks.
%
The most recent release of the authoritative CWE Top 25
Most Dangerous Software Weaknesses
list\footnote{\url{https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html}}
shows general classes of vulnerabilities closely related to the stack \rb{(though not exclusively)}
consistently at and near the top, e.g., \#1 (CWE-787, Out-of-bounds Write), \#5 (CWE-125, Out-of-bounds Read) or \#7 (CWE-416, Use After Free).
%
Moreover, many other types of faults involve some kind of control or data flow
using data stored in the stack \rb{cf. Eternal war in memory, Google/Microsoft
  memory safety statistics, etc.}.

The variety in attacks on the stack is mirrored by the 
software and hardware protections that aim to prevent them,
%
including stack canaries~\cite{Cowan+98},
bounds checking~\cite{NagarakatteZMZ09,NagarakatteZMZ10,DeviettiBMZ08},
split stacks~\cite{Kuznetsov+14},
shadow stacks~\cite{Dang+15,Shanbhogue+19},
capabilities~\cite{Woodruff+14,Chisnall+15,SkorstengaardLocal,SkorstengaardSTKJFP,Georges+21},
and hardware tagging~\cite{DBLP:conf/sp/RoesslerD18}---we discuss these in more
detail in \cref{XXX}. Few of these articulate any formal property that they aim to enforce,
with the exception of Skorstengaard and Georges. Some are fundamentally ill-suited for
formalization, as they aim to impede attackers but could not provide universal protection.

In this work, we propose such a property, built from first principles
in the hopes that it will be widely applicable, and demonstrate that it supports
an enforcement mechanism that does not yet have one.
We use the formal tools of language-based
security~\cite{sabelfeld2003language}, decomposing stack safety into
the {\em integrity} and {\em confidentiality} of the callerâ€™s local state
and the callee's behavior during the callee's execution, plus the control-flow protection
of {\em well-bracketed control flow}~\cite{SkorstengaardSTKJFP} (\(\wbcf\)).
\ifexceptions
We also extend WBCF to a setting with exceptions,
in which there may be multiple points at which a callee can ``return.''
\fi

Our target for validation is the ``Lazy Tagging and Clearing'' \(LTC\) micropolicy of Roessler
and DeHon \cite{DBLP:conf/sp/RoesslerD18}. \(LTC\) is peculiar in that function activations
may write into one another's stack framess, as long as the data cannot be accessed afterward.
It is therefore too weak to be characterized by the state-of-the-art properties from
Georges et al. We give a characterization that does apply to it, and expand the features that
it supports.

\paragraph{Towards a Formal Property for Stack Safety}

Security mechanisms can be brittle, successfully eliminating one attack while leaving room for
other, similar attacks. To avoid this, we seek formal properties of safe behavior that can be proven
or tested. Such properties become the specification against which enforcement can be validated;
even enforcement mechanisms that do not fulfill a property benefit from the ability to articulate
\emph{why} they fail.

But most such properties are described at the level of a high-level programming language.
The stack as an abstraction exists below the level of
any language that uses it, and at the level of the ABI, the specification of a well-behaved
stack is minimal. It is not concerned with such questions as whether a caller's
frame should be readable or writable to its callee, leaving those concerns
to be determined by a high-level language built atop the stack.
(Contrast Azevedo de Amorim et al.'s \cite{DBLP:conf/post/AmorimHP18} work on heap safety,
which is broadly consistent across language semantics, and therefore
amenable to a very general approach.)

For instance, the current state-of-the-art stack-safety specification from Georges et al.
\cite{Georges22:TempsDesCerises} supposes a machine with only straightforward call-and-return
control flow, and therefore defines {\it Well-bracketed Control Flow} (WBCF) under the assumption that
a callee should always return to its caller. But, in the presence of tail-call elimination, a
return from a callee to a distant ancestor is perfectly reasonable.

We are not attempting to create a universal definition of stack safety for all systems.
Rather, we define the stack safety of a single, fairly realistic system, decomposed into
(1) a lightweight model of the system and its security-relevant features, from which we
derive the integrity, confidentiality, and control-flow requirements of each call and
return, (2) the application of that model to a particular target system, and (3)
the formal criteria for integrity, confidentiality, and control flow
to obey the requirements. This decomposition can be thought of as a step toward
a universal definition, in that the definitions in (3) capture fundamental
notions of security that can then be applied flexibly to other systems by varying
the model in (1) and (2).
%
We treat stack safety as multiple properties, rather than one multi-faceted property, because
not all enforcement mechanisms attempt to implement all aspects of stack safety (see \cref{???}.)
%
This gives us a total of five core properties: \(\wbcf\),
caller integrity (\(\clri\)), caller confidentiality (\(\clrc\)),
callee integrity (\(\clei\)), and callee confidentiality (\(\clec\)), defined formally
in \cref{sec:props}.

We demonstrate that our properties are general in that they apply easily to systems with various
features, and that they support ``al la carte'' enforcement based on the security needs of the
system.

To validate our formal characterization, we use these
properties to test and improve an existing enforcement mechanism, the
{\em stack safety micro-policies} of Roessler and DeHon~\cite{DBLP:conf/sp/RoesslerD18}, re-implemented
in the Coq proof assistant on top of a \rb{formal} RISC-V specification.  We
use QuickChick~\cite{Denes:VSL2014,Pierce:SF4}, a property-based testing
tool for Coq, to generate random programs and check
that Roessler and DeHon's micro-policies correctly detect the ones that
attempt to violate one of our properties. Furthermore, we
check that the testing framework is able to generate counterexamples
that violate our properties but are \emph{not} halted by incorrect
variants of the enforcement mechanisms, including ones that we accidentally created
while implementating the micro-policy and ones that we
intentionally crafted to increase our confidence in the effectiveness
of our testing.
%
\rb{This and the following paragraph could start more generally (we need to
  answer the question of why these experiments, what is their interest), and
  probably motivate the use of PBT (experiment results below show there's
  benefit in them!) and, somewhere at least, talk about other points in the
  spectrum.}

We find that Roessler and DeHon's \emph{Lazy Tagging and Clearing}
violates the temporal aspect of confidentiality in
cases where data can leak across repeated calls to the same callee,
and also violates integrity if the leak uses the caller's frame. We
propose a variant of {\em Lazy Tagging and Clearing} that testably enforces
confidentiality, albeit at some performance cost.
%
\rb{Anything to add from personal communications? More details later? Shows
  these things are very hard to get right -- like the latest work on Cerise,
  also motivated by this very work.
\rb{(+SNA) At the very least, these models are subtle and getting them right,
  and describing them unambiguously, is hard without a framework like this.}
}

\subsection{Contributions}

In sum, we offer the following contributions:

\begin{itemize}
\item We formalize permissive stack confidentiality and integrity properties,
  which are parameterized over a notion of external
  observation, and are violated only if accessing secrets or overwriting
  data causes a visible change in system behavior.
\item We instantiate these definitions with a realistic
  system with features such as argument passing
  on the stack, callee-saves registers, and tail-call elimination.
  Our model is modular enough that adding these features is straightforward.
\item Our formalization of well-bracketed control flow in the presence of tail-call
  elimination \ifexceptions and exceptions \fi is a novelty over existing models.
\item We use property-based random testing to validate the relationship between
  our properties and micro-policies.
\end{itemize}

Our artifact contains Coq formalizations of our properties for illustrative purposes
as well as their testing implementation. There are no proofs---we use primarily Coq for the
QuickChick library and to ensure that the formalizations are unambiguous.

\subsection{Related Work: The Stack Safety Menagerie}

\apt{This section was a nice summary of enforcement approaches, but I am not
  yet seeing why it justifies so much paper real estate, especially if we only 
  actually apply our property definitions to (lazy) micropolicies. And in any case,
  it makes for a huge delay before getting to our work and contributions.}
\sna{I've tried out moving it here. To my mind, its main purpose is to justify
  our claims about the wide variation in stack-safety enforcement, and therefore
  to help argue that our properties not necessarily being universal is
  not a flaw.}

The protections offered by stack protection mechanisms are commonly described by giving
concrete examples of attacks that they can prevent---corruption of return
addresses, buffer overflows, use of uninitialized variables, etc.---leaving
a more formal characterization to the reader's intuition.
%
To make these notions more precise, we review a selection of specimens from the
menagerie and begin to consider the difficulties involved in specifying and
verifying the protections they offer.
%
For an assessment of these methods in the context of our stack security
framework, see \cref{XXX}.

At the highest level, we can classify techniques into two large groups depending
on whether their protection is furnished at the software or the hardware level.
Up to date, most proposals, including all commonly deployed practical
protections, are implemented in software, so we start by considering exemplars
from this first group.

\subsubsection{Software Techniques}

\paragraph{Stack Canaries}
%
Canaries are special values inserted by the caller at certain points of the
stack and checked for corruption on return, primarily for protection against
some classes of control-flow hijacking (i.e., seeking to overwrite the caller's
return address through a buffer overflow that would also overwrite the canary
detectably).
%
Observe that this is a \emph{hardening} technique that increases the difficulty
of some control-flow attacks on the stack, but can never provide any absolute
guarantees on control flow integrity; neither does it do anything to protect
function data stored in the stack.
%
Also interestingly, a successful attack is not detected the moment it takes
place, instead action is \emph{deferred} until the attacker returns control to
the caller.

\paragraph{Shadow Stacks}
%
A shadow stack is a mirror image of the control-relevant parts of the stack,
maintained by the program to attempt to detect attempts to hijack its control
flow. They are similar in purpose and can be seen as related to stack canaries.
Like canaries, they offer hardened but not guaranteed, deferred protection
against control-flow attacks, ``restrict the flexibility available in creating
gadget chains'' \cite{Shanbhogue+19}, and do not cover the data-relevant regions
of the stack.
%
\rb{Could probably find other variants (e.g. SmashGuard, on hardware?), but this
  seems to be the basic idea. Some of those require OS support, etc.}

\paragraph{Bounds Checking}
%
Under a bounds checking discipline, all the pointers in a program are extended
with some disjoint metadata, and these are combined to gate memory accesses,
usually with the objective of enforcing some form of \emph{memory
safety} \rb{(relate this to the basic high-level concepts and types of attacks
we want to consider: control flow, some integrity and confidentiality?)}.
%
Compared to stack canaries and shadow stacks, bounds checking is eminently
a \emph{high-level} technique, designed with a particular programming language
in mind and implemented through a \emph{secure compiler} \cite{} that performs
the necessary code transformations. Also unlike those techniques (which make few
assumptions on callee code), it offers little to no protection
against \emph{adversarial low-level} code that is not constrained to obey the
bounds checking discipline.
%
\rb{Some related work, e.g. HardBound, is inspired by this but more closely
  related to hardware capabilities.}

\sna{Would HardBound warrant a section in the hardware techniques section,
  for hardware-accelerated bounds checking (that is not capability-based)?}

\paragraph{Split Stacks}
%
Code-pointer integrity seeks to prevent control-flow hijacking attacks by
splitting the program memory, including the stack, into a regular region and a
safe region; objects that require protection are placed in the latter and
all accesses to them protected by static or dynamic checks.
%
Like shadow stacks, bounds checking is a high-level technique designed to
protect code written in a high-level language, but it is designed to
offer protection under a stronger threat model that also considers the presence
of untrusted code. As with most other software-based methods, it purports to
protect exclusively the control-relevant parts of the stack, making no claims
about its data-relevant parts.

\subsubsection{Hardware Techniques}

In addition to the many software-based techniques developed to provide greater
degrees of protection to the stack, often incurring a significant performance penalty,
some proposals have turned to specialized hardware features to offset those
costs and attempt to offer greater levels of protection.

We focus in particular on two families of hardware mechanisms: capability machines
and tag-based reference monitors. Both types of system move beyond simply
offering hardware acceleration for software-based techniques, offering hardware
primitives for both memory and control-flow enforcement that can offer a degree
of protection even with minimal cooperation from the code.
%
\rb{Something about how realistic/practical these alternatives are? Are we
  selecting partly based on prototypes, etc.?}

\paragraph{Capabilities}
%
\rb{(There is plenty of variety here, should we focus on the Cerise-and-friends
  (CHERI-adjacent) work exclusively?)}

\sna{If we have good examples of other capability systems, we should absolutely
  talk about them. No need to privilege CHERI.}
%
Capability machines can represent and manipulate
unforgeable tokens of authority over specific regions of
memory using a combination of dedicated out-of-band memory and
specialized ISA instructions.
%
The most prominent contemporary representative of this long line of work is
CHERI \cite{}, a modern architecture designed to provide efficient fine-grained
memory protection and compartmentalization.
%
Previous work has uses these principles in simplified models to implement
\emph{secure calling conventions} for the call
stack \cite{}. Those conventions can be seen as combining the
protections of bounds-checking with software-based methods of control-flow protection.
%
They are closely related \rb{too strong?} to this work; we discuss them in more
detail in \cref{XXX}.
%

\paragraph{Micro-Policies}
%
\rb{(This partly overlaps with the technical preliminaries, try to offer a quick
  synthesis here.)}
%
Micro-policy machines are a family of tagged architectures that decorate
addressable memory and registers with arbitrary metadata tags, and extend the
processor with a programmable hardware monitor that uses custom rules on
metadata tags to implement many different kinds of security policies.
%
This flexibility can be harnessed to implement a wide array of stack protection policies with relative ease, covering and going beyond the capabilities \rb{word choice?} of the various software-based techniques \cite{} \rb{as demonstrated by}.
%
These policies comprise very general forms of \emph{lazy enforcement}, which can tolerate
potential but harmless violations \rb{the system programmer's motto: ``trust me,
  I know what I'm doing''} while still detecting them if and when their effects
become observable. 
%
Micro-policies are one of the centerpieces of our technical development; we
present them in more detail in \cref{XXX}.

\paragraph{Summary}

We begin to see that the security of the call stack and its contents is not
clearly defined. Different protection mechanisms aim to protect the stack
in fundamentally different ways, each offering a \emph{unique}, \emph{implicit}
specification of the meaning of ``stack safety.'' These specifications
may be more or less compatible with the needs of a given high-level language.
Moreover, different protections operate under different threat models, further
complicating their comparison and the assessment of the safeguards they
effectively offer their clients---the programs themselves.
It would be far preferable to have a \emph{standard}, \emph{explicit} specification.
Only a handful of works have offered any explicit specification.
