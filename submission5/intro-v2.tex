\subsection{The Call Stack and Its Security}

\rb{A.K.A. motivation}

Computer programming at any scale relies on \emph{functions} (variously known as
subroutines, procedures, methods, etc.) as a \emph{foundational abstraction} to
structure programs into building blocks representing units of computation that
can \emph{call} one another to create larger computations.
%
At a low level, a function call comprises its own data (private or shared), as
well as information about its \emph{caller} and \emph{callee} functions. The
runtime must keep track of the local contexts of all active function activations
at any given time; the \emph{fundamental data structure} charged with realizing
this abstraction is the \emph{(call) stack}.
%
\rb{This should be well known, so no need for illustration?}

The correct execution on a program---and its security---is contingent on all of
its functions properly implementing this abstraction by means of a careful use
of the call stack. Be it accidental or intentional, incorrect management of the
stack is at the root of a myriad of faults whose effects range from (rarely)
innocuous to (usually) catastrophic.
%
From a security perspective, attacks on the stack (say, from a malicious
function that chooses to abuse its access to the contents of this data
structure) are as fundamental, varied and pervasive as the functional
abstraction itself.
%
\rb{Begins to prefigure the idea of multiple stack implementations.}

%% \rb{\textbf{The call stack and its security.} Maybe a few opening words to set
%%   the stage and bring two things to the front: (1) functions and subroutines as
%%   fundamental building blocks of any kind of structured programming; and (2) the
%%   stack as the natural abstraction to manage these in a computer. And also maybe
%%   a little bit more about the width, the gravity and the \emph{foundational
%%   nature} of attacks on the stack, which the sentence below touches on
%%   summarily.
%% \rb{(+SNA) Connection to functions (and adversarial code?). Attacks on the stack
%%   are also attacks on this fundamental abstraction (functions, subroutines,
%%   procedures, methods, however you call them)}
%% }

Indeed, the call stack is a perennial target for low-level attacks, leading to
dire consequences, from leakage and corruption of private stack data
to control-flow hijacking.
%
Even a cursory glance at the most recent release of the authoritative CWE Top 25
Most Dangerous Software Weaknesses
list\footnote{\url{https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html}}
shows general classes of vulnerabilities closely related to the stack \rb{(though not exclusively)}
consistently at and near the top, e.g., \#1 (CWE-787, Out-of-bounds Write), \#5 (CWE-125, Out-of-bounds Read), \#7 (CWE-416, Use
After Free) or \#11 (CWE-476, NULL Pointer Dereference).
%
Moreover, many other types of faults involve some kind of control or data flow
using data stored in the stack \rb{cf. Eternal war in memory, Google/Microsoft
memory safety statistics, etc.}.
%
To foil such attacks, a menagerie of
software and hardware protections have been proposed,
%
including stack canaries~\cite{Cowan+98},
bounds checking~\cite{NagarakatteZMZ09,NagarakatteZMZ10,DeviettiBMZ08},
split stacks~\cite{Kuznetsov+14},
shadow stacks~\cite{Dang+15,Shanbhogue+19},
capabilities~\cite{Woodruff+14,Chisnall+15,SkorstengaardLocal,SkorstengaardSTKJFP,Georges+21},
and hardware tagging~\cite{DBLP:conf/sp/RoesslerD18}---we discuss these in more
detail in \cref{XXX}.
  \ifaftersubmission\apt{Mostly from
  nick; there could be more}\bcp{Yes, going back to MIT days---we should
  include several more of these, if only to give readers the impression that
this is a well-studied mechanism (so formalizing its protections is
useful).}
\fi
%
\rb{Broad enough? Do we want to add more techniques?}
%
Yet despite this wealth of potential solutions, the stack remains a central
security concern---why?

Security mechanisms designed to prevent a certain attack can be brittle---successfully
eliminating the attack as it exists at the time of publication, but leaving room for attackers
to find new, similar attacks.
%
%% \rb{And so the cat-and-mouse game continues.}
%
To mitigate this risk, \rb{we claim that} mechanisms should aim to enforce \emph{formal
properties} of correct \rb{safe?} behavior that can be proven or tested. Such properties become the
\emph{specification} against which enforcement can be validated; even enforcement mechanisms that do
not fulfill a property benefit from the ability to articulate \emph{why} they fail.
%
%% \rb{Good stuff! There is some overlap between this discussion and the opening
%%   motivation, maybe we could restructure things a bit so that those threads are
%%   unified?}
%
This is the problem we begin to address in this paper \rb{or a few more such
  connecting words}.

\subsection{A Menagerie of Stack Protection Mechanisms}

\rb{A.K.A. related work (part 1?). I wonder if this goes before or after a first
  look at the idea of the properties.}

The protections offered by stack protection mechanisms are commonly described by giving
concrete examples of attacks that they can prevent---corruption of return
addresses, buffer overflows, use of uninitialized variables, etc.---leaving
a more formal characterization to the reader's intuition.
%
To make these notions more precise, we review a selection of specimens from the
menagerie and begin to consider the difficulties involved in specifying and
verifying the protection they offer.
%
For an assessment of these methods in the context of our stack security
framework, see \cref{XXX} below.

\subsubsection{Software Techniques}

At the highest level, we can classify techniques into two large groups depending
on whether their protection is furnished at the software or the hardware level.
Up to date, most proposals, including all commonly deployed practical
protections, are implemented in software, so we start by considering exemplars
from this first group.

\paragraph{Stack Canaries}
%
Canaries are special values inserted by the caller at certain points of the
stack and checked for corruption on return, primarily for protection against
some classes of control-flow hijacking (i.e., seeking to overwrite the caller's
return address through a buffer overflow that would also overwrite the canary
detectably).
%
Observe that this is a \emph{hardening} technique that increases the difficulty
of some control-flow attacks on the stack, but can never provide any absolute
guarantees on control flow integrity; neither does it do anything to protect
function data stored in the stack.
%
Also interestingly, a successful attack is not detected the moment it takes
place, instead action is \emph{deferred} until the attacker returns control to
the caller.

\paragraph{Shadow Stacks}
%
A shadow stack is a mirror image of the control-relevant parts of the stack,
maintained by the program to attempt to detect attempts to hijack its control
flow. They are similar in purpose and can be seen as related to stack canaries.
Like canaries, they offer hardened but not guaranteed, deferred protection
against control-flow attacks, ``restrict the flexibility available in creating
gadget chains'' \cite{Shanbhogue+19}, and do not cover the data-relevant regions
of the stack.
%
\rb{Could probably find other variants (e.g. SmashGuard, on hardware?), but this
  seems to be the basic idea. Some of those require OS support, etc.}

\paragraph{Bounds Checking}
%
Under a bounds checking discipline, all the pointers in a program are extended
with some disjoint metadata, and these are combined to gate memory accesses,
usually with the objective of enforcing some form of \emph{memory
safety} \rb{(relate this to the basic high-level concepts and types of attacks
we want to consider: control flow, some integrity and confidentiality?)}.
%
Compared to stack canaries and shadow stacks, bounds checking is eminently
a \emph{high-level} technique, designed with a particular programming language
in mind and implemented through a \emph{secure compiler} \cite{} that performs
the necessary code transformations. Also unlike those techniques (which make few
assumptions on callee code), it offers little to no protection
against \emph{adversarial low-level} code that is not constrained to obey the
bounds checking discipline.
%
\rb{Some related work, e.g. HardBound, is inspired by this but more closely
  related to hardware capabilities.}

\paragraph{Split Stacks}
%
Code-pointer integrity seeks to prevent control-flow hijacking attacks by
splitting the program memory, including the stack, into a regular region and a
safe region; those objects that require protection are located in the latter and
all accesses protected by static or dynamic checks.
%
Like shadow stacks, bounds checking is a high-level technique designed to
protect code written in a high-level language, but, unlike them, it is meant to
offer protection under a stronger threat model that also considers the presence
of untrusted code. Similar to most software-based methods, it purports to
protect exclusively the control-relevant parts of the stack, making no claims
about its data-relevant parts.

\subsubsection{Hardware Techniques}

In addition to many the software-based techniques developed to provide greater
degrees of protection to the stack, often at a significant cost in performance,
some proposals have turned to specialized hardware features to offset those
penalties and attempt to offer greater levels of protection.
%
\rb{Something about how realistic/practical these alternatives are? Are we
  selecting partly based on prototypes, etc.?}

\paragraph{Capabilities}
%
\rb{(There is plenty of variety here, should we focus on the Cerise-and-friends
  (CHERI-adjacent) work exclusively?)}
%
Capability machines can represent and manipulate their homonymous
capabilities---unforgeable tokens of authority over specific regions of
memory---using a combination of dedicated out-of-band memory and a collection of
specialized ISA instructions.
%
The most prominent contemporary representative of this long line of work is
CHERI \cite{}, a modern architecture designed to provide efficient fine-grained
memory protection and compartmentalization.
%
Previous work has demonstrated the use of these general principles \rb{in
  simplified models} to implement \emph{secure calling conventions} for the call
stack \cite{}. Those conventions can be seen as combining the advantages and
protections of various families of software-based methods.
%
They are closely related \rb{too strong?} to this work; we discuss them in more
detail in \cref{XXX}.
%
\rb{HardBound is also related to this}

\paragraph{Micro-Policies}
%
\rb{(This partly overlaps with the technical preliminaries, try to offer a quick
  synthesis here.)}
%
Micro-policy machines are a family of tagged architectures that decorate
addressable memory and registers with arbitrary metadata tags, and extend the
processor with a programmable hardware monitor that uses custom rules on
metadata tags to implement security policies of various types.
%
This flexibility can be harnessed to implement a wide array of stack protection policies with relative ease, covering and going beyond the capabilities \rb{word?} of the various software-based techniques \cite{} \rb{as demonstrated by}.
%
They comprise very general forms of \emph{lazy enforcement}, which can tolerate
potential but harmless violations \rb{the system programmer's motto: ``trust me,
  I know what I'm doing''} while still detecting them if and when their effects
become tangible.
%
Micro-policies are one of the centerpieces of our technical development; we
present them in more detail in \cref{XXX}.

\subsection{A Language-Based View of Stack Safety}

As we begin to intuit, the security of the call stack and its contents can be
viewed through many different lenses. Each of these points of view results in a
\emph{unique specification} of the meaning of \emph{stack safety} for a
particular protection mechanism---mostly an informal specification if one is
produced, and almost always left implicit to some degree.
%
Moreover, different protections operate under different threat models, further
complicating their comparison and the assessment of the safeguards they
effectively offer their clients---the programs themselves.
%
On the face of it, it seems perplexing that there is not a \emph{standard
specification} (or set of specifications) for such a fundamental problem.
Instead of reverse engineering an specific enforcement mechanism obtain a
(necessarily approximate) specification, we turn the problem around on its head
and seek more general solutions from first principles.
%
\rb{(Problems/notes: ``backward specs'' not the most useful to their clients,
  not designed with their security needs in mind---goes in the direction of
  program logics---; to reason about security in complex systems an explicit and
  clear spec is preferable; many of the informal specs are at least
  superficially similar and overlapping; hopefully all of them can be understood
  from a small number of fundamental concepts)}

We propose a novel characterization of stack safety using the formal tools of language-based
security~\cite{sabelfeld2003language}, decomposing stack safety into
the {\em integrity} and {\em confidentiality} of the caller’s local state
and the callee's behavior during the callee's execution, plus the control-flow protection
of {\em well-bracketed control flow}~\cite{SkorstengaardSTKJFP} (\(\wbcf\)).
\ifexceptions
We also extend WBCF to a setting with exceptions,
in which there may be multiple points at which a callee can ``return.''
\fi
%
We treat stack safety as multiple properties, rather than one multi-faceted property, because
not all enforcement mechanisms attempt to implement all aspects of stack safety. Some focus
exclusively on control flow, some enforce integrity but not confidentiality, and many
focus on the caller over the callee.
%
\rb{Return to this after extended discussion?}
%
This gives us a total of five core properties: \(\wbcf\),
caller integrity (\(\clri\)), caller confidentiality (\(\clrc\)),
callee integrity (\(\clei\)), and callee confidentiality (\(\clec\)).
%
\rb{Forward references?}

We are not attempting to create a universal definition of stack safety for all systems.
Rather, we define the stack safety of a single, fairly realistic system, decomposed into
(1) a lightweight model of the system and its security-relevant features, from which we
derive the integrity, confidentiality, and control-flow requirements of each call and
return, (2) the application of that model to a particular target system, and (3)
the formal criteria for integrity, confidentiality, and control flow
to obey the requirements. We consider the criteria in (3) to represent universal definitions
that are parameterized by (1).
%
\rb{FIXME: Contrast some universal definitions (or a parametric framework) with
  the concrete instance we study, again with its interest properly motivated.
  (Coming in key ideas?) No ``gold standard''?}

Stack safety is challenging to specify in full generality, because the stack is fundamentally
an architecture-specific construct. (Contrast Azevedo de Amorim et al.'s \cite{DBLP:conf/post/AmorimHP18} work on heap safety,
which is broadly consistent across architectures and language semantics, and therefore amenable
to a very general approach.)
The desired behavior of the stack varies based on ISA, calling convention,
and the features of whichever programming language originated the code.
%
\rb{(Extremely important!)}
%
For instance, the current state-of-the-art stack-safety specification from Georges et al.
\cite{Georges22:TempsDesCerises} supposes a machine with only straightforward call-and-return
control flow, and therefore defines {\it Well-bracketed Control Flow} (WBCF) under the assumption that
a callee should always return to its caller. But, in the presence of tail-call elimination, a
return from a callee to a distant ancestor is perfectly reasonable. Any addition of new features
must be accompanied by tweaks to the model.
%
\rb{(Make this second point later?)}

To demonstrate the utility of our formal characterization, we use these
properties to validate and improve an existing enforcement mechanism, the
{\em stack safety micro-policies} of Roessler and DeHon~\cite{DBLP:conf/sp/RoesslerD18}, re-implemented
in the Coq proof assistant on top of a \rb{formal} RISC-V specification.  We
use QuickChick~\cite{Denes:VSL2014,Pierce:SF4}, a property-based testing
tool for Coq, to generate random programs and check
that Roessler and DeHon's micro-policies correctly detect the ones that
attempt to violate one of our properties. Furthermore, we
check that the testing framework is able to generate counterexamples
that violate our properties but are \emph{not} halted by incorrect
variants of the enforcement mechanisms, including ones that we accidentally created
while implementating the micro-policy and ones that we
intentionally crafted to increase our confidence in the effectiveness
of our testing.
%
\rb{This and the following paragraph could start more generally (we need to
  answer the question of why these experiments, what is their interest), and
  probably motivate the use of PBT (experiment results below show there's
  benefit in them!) and, somewhere at least, talk about other points in the
  spectrum.}

We find that Roessler and DeHon's \emph{Lazy Tagging and Clearing}
violates the temporal aspect of confidentiality in
cases where data can leak across repeated calls to the same callee,
and also violates integrity if the leak uses the caller's frame. We
propose a variant of {\em Lazy Tagging and Clearing} that testably enforces
confidentiality, albeit at some performance cost.
%
\rb{Anything to add from personal communications? More details later? Shows
  these things are very hard to get right -- like the latest work on Cerise,
  also motivated by this very work.
\rb{(+SNA) At the very least, these models are subtle and getting them right,
  and describing them unambiguously, is hard without a framework like this.}
}

\subsection{Contributions}

In sum, we offer the following contributions:

\begin{itemize}
\item We formalize permissive stack confidentiality and integrity properties,
  which are parameterized over a notion of external
  observation, and are violated only if accessing secrets or overwriting
  data causes a visible change in system behavior.
\item We instantiate these definitions with a realistic
  system with features such as argument passing
  on the stack, callee-saves registers, and tail-call elimination.
  Our model is modular enough that adding these features is straightforward.
\item Our formalization of well-bracketed control flow in the presence of tail-call
  elimination \ifexceptions and exceptions \fi is a novelty over existing models.
\item We use property-based random testing to validate the relationship between
  our properties and micro-policies.
\end{itemize}

Our artifact contains Coq formalizations of our properties for illustrative purposes
as well as their testing implementation. There are no proofs---we use primarily Coq for the
QuickChick library and to ensure that the formalizations are unambiguous.
%
\rb{Will have another look after the full pass.}

\rb{*** KEY IDEAS FROM HERE? ***}

\paragraph*{Permissiveness, Laziness, and Tagged Architectures}

Security properties tend to be conservative, identifying violations that would be
harmless in practice. But enforcement mechanisms make trade-offs in the name of performance
and of compatibility with existing codebases. In a crucial motivating example for this work,
Roessler and DeHon \cite{} present a collection of tag-based enforcement mechanisms
using PIPE \cite{???}, a tagged hardware reference monitor. In monitors such as PIPE and
STAR \cite{???}, every value in memory and registers is paired with a {\em metadata tag}.
A set of software-defined rules, termed a micro-policy, determines the tags for operation
results based on the tags of their inputs---or, if the input tags are in a dangerous
combination, it may halt the machine (a ``failstop.'')

Roessler and DeHon find that the intuitive way to enforce stack safety in this setting
is inefficient when allocating and clearing stack frames, because each word must be initialized
with a tag corresponding to the (depth of the) current function activation. They propose
{\em Lazy Tagging and Clearing}, in which tags are not initialized at allocation, but only
when a function writes to memory. This means that writes cannot be prevented, necessarily
violating existing models of stack safety. Instead the micro-policy enforces that memory be
read by the same fuction that wrote it. The owner of the data will never see the changes,
so it is secure in the sense that the attacker is unsuccessful at changing program behavior
(except, perhaps, by causing a fault.) We elaborate that sense, and test whether the
micro-policy fulfills it.

This key motivation leads us to present integrity and confidentiality as predicates on (pairs of)
machine states that make claims about the future observable behavior of execution from those states.
That is not to say that our properties are specialized for lazy micro-policies. It also supports
normal ``eager'' micro-policies, and should support other enforcement mechanisms. In fact, \(\clri\)
and \(\clrc\) are even weaker than necessary to support Roessler and Dehon's micro-policy,
while \(\clec\) and \(\clei\) are stronger properties that they do not attempt to enforce.
%
\rb{Does this discussion (at least in part) belong in the general background
  section, some even in key ideas? It still feels a little out of order to me,
  and occasionally too detailed for the introduction?}

\rb{Begins to anticipate subsequent discussion. This is even something of an
  understatement: some papers (esp. newer ones?), make concrete claims, though
  they remain informal. Arguably, none have a truly formal characterization in
  mind (with the qualified exception of \cite{SkorstengaardSTKJFP}): this is one
  of the novelties of this work!
\rb{(+SNA) Indeed, this point needs to be made carefully. We claim to go further
  than previous work, without showing a fully general framework (which would be
  highly parametric, etc.). Tie to the idea of micro-policies as a good place to
  start because of their flexibility, elegance, enabling a wide of interesting
  experiments, etc.
\rb{Basically, none reach the point of being an independent (and executable) specification}
}
}
%
Previous attempts
to produce a formal characterization do so using a {\it fully abstract overlay semantics},
a style of correct-by-construction machine \cite{SkorstengaardSTKJFP}.
But this approach is not suitable for the {\em lazy} enforcement mechanism
of Roessler and DeHon, in which stores are not checked, and illegal stores are
only caught when their location is later read. We aim to provide a stack-safety
property suitable for testing lazy enforcement.
%
\rb{Need to discuss overlay semantics, but also note that it is very intensional
  and very specific, as the authors acknowledge. I'd introduce this a bit more
  gradually. Also, if phrased this way, it sounds like its main drawback is a
  lack of generality, to which we should contrast a more general approach, not
  just one that is specialized to a specific policy, i.e. lazy micro-policies
  (I'd try to present these more gradually as well).}

\newcommand*{\rot}[1]{\hbox to1em{\hss\rotatebox[origin=br]{-60}{#1}}}
\newcommand*{\tabyes}{\CIRCLE\xspace}
\newcommand*{\tabno}{\Circle\xspace}
\newcommand*{\tabjein}{\RIGHTcircle\xspace}

\begin{table}
\begin{threeparttable}
  \begin{tabular}{l | c c c c | c c c | c}
    \toprule
    \multicolumn{1}{l |}{Mechanism}
    & \multicolumn{4}{l |}{Features}
    & \multicolumn{3}{l |}{Properties}
    & %% Formal criteria
    \\
    \midrule
    %% Technique
    \multicolumn{1}{c}{}
    & \rot{Strict enforcement}
    & \rot{Deferred checking}
    & \rot{Low-level code support}
    & \multicolumn{1}{c}{\rot{Partial program support}}
    & \rot{Well-bracketed control flow}
    & \rot{Data integrity}
    & \multicolumn{1}{c}{\rot{Data confidentiality}}
    & \rot{Formal criteria}
    \\
    \midrule
    Stack canaries  & \tabno   & \tabjein & \tabyes  & \tabyes  & \tabyes  & \tabno   & \tabno   &          \\
    Shadow stacks   & \tabno   & \tabjein &          & \tabyes  & \tabyes  & \tabno   & \tabno   &          \\
    Bounds checking & \tabyes  & \tabno   & \tabno   & \tabno   & \tabyes  &          &          &          \\
    Split stacks    & \tabyes  & \tabno   & \tabno   & \tabyes  & \tabyes  & \tabno   & \tabno   &          \\
    \midrule
    Capabilities    &          & \tabno   &          & \tabyes  &          &          &          & \tabjein \\
    Micro-policies  & \tabyes  & \tabyes  & \tabyes  & \tabyes  & \tabyes  & \tabyes  & \tabyes  & \tabyes  \\
    \bottomrule
  \end{tabular}
  \caption{Comparison of Stack Protection Mechanisms}
  \begin{tablenotes}
  \item \tabyes indicates a protection mechanism possesses the feature
  \item \tabno indicates the mechanism lacks the feature
  \item \tabjein indicates partial or incomplete support
  \item \rb{Complete and check columns, describe. Capitalize?}
  \item \rb{Order? Split int/conf? Deferred/lazy at the end of features}
  \item \rb{2+ lines for capabilities, before and after using our draft?}
  \end{tablenotes}
  \label{tab:relwork}
\end{threeparttable}
\end{table}

\rb{\textbf{A menagerie of protection mechanisms.}
%
We have made explicit the key point that there is \emph{not} a single stack
abstraction. This paves the way for a \emph{general} idea of stack protection
that is widely applicable with high-level concepts that remain unchanged (and I
think it's particularly important to at least introduce these more immutable
parts early on). The fact that this general ``framework'' requires low-level or
specific specializations is a predictable consequence of the protean nature of
the call stack.
%
\\
%
Let us return to a selection of representative policies in our menagerie and
consider how they fit into the framework. At the highest level, we can classify
all those techniques into two large groups, software-based and hardware-based.
Traditionally, most practical protections are implemented in software, so we
start by considering this first group.
%
\\
%
We can make two general observations about these software based techniques.
Firstly, (as we will see: discussion? technical details?) these techniques are
\emph{less modular} than their hardware counterparts. That is, the
countermeasures are tightly coupled with the program code they protect, and
consequently more effort is required to disentangle the program from the
protections, and to understand the impact of the latter on the former. This is
true of any systematic attempt to study the security of stack protection
policies, including their adaptation to our framework. (Owing to this added
complexity, software policies will not be the cleanest or most elegant exemplars
of use of the framework, its salient features and practical utility; this partly
motivates the focus on hardware policies.)
%
\\
%
(The above remark holds \emph{at least in a ``single-level model''} that
considers assembly language/machine code programs. In general, (low-level)
protections are introduced by a compiler or similar tool. One could consider a
multi-level extension of the framework pairing models of high-level programs and
the security transformations performed by a (stack-secure) compiler.)
%
\\
%
Secondly, the guarantees generally offered by software-based policies are
\emph{less absolute}, being defined more or less informally and usually
providing few definite guarantees of absence of \emph{general} classes of
errors. (The following discussion elaborates on this. It is conceivable that an
extended and more sophisticated framework could add \emph{probabilistic
reasoning} capabilities to capture and reason about the effects of less strict
protection mechanisms. This would be another orthogonal development to what is
presented here. In this paper, we are interested in assessing the complete
\emph{absence} of broad classes of vulnerabilities --- modulo any modeling gaps
or defects. In passing, this would extend the security properties to e.g. larger
system verification efforts.)
%
\\
%
One by one, consider the following specimens of software protection mechanisms
(quick explanations inlined?):
%
\\
%
\begin{itemize}
%
\item \emph{Stack canaries}. The purpose of canaries is to \emph{increase} the
  difficulty of some attacks on the stack, usually (always?) buffer overflows.
  They can never provide any absolute security guarantees and therefore do not
  satisfy any of our properties (some of the properties, e.g. confidentiality,
  are completely out of scope.) Although tedious, we could we could model this
  mechanism in our framework with the appropriate adaptations --- and
  unsurprisingly, testing would find property violations, which we already know
  are there: the results of this effort would be unsurprising and not as useful
  or instructive as other experiments.
  \rb{(+SNA) They are kind of lazy, aren't they?}
%
\item \emph{Bounds checking}. This is fundamentally a high-level technique, even
  more obviously so than stack canaries (which could still detect violations
  caused by external code). Bounds checking only applies to code that has been
  instrumented by the ``secure compiler'' (i.e., to whole programs); it does not
  impose any constraints on adversarial code. The attacker model is therefore
  rather weak. (Certain variants, like SoftBound, are good targets for lifting
  our framework to the source level by e.g. using a C-language semantics and
  using Tagged C for security modeling; the lifted versions of our properties
  would likely hold under the expected assumptions. HardBound is probably an
  interesting transitional case because it uses capability-like hardware
  primitives for enforcement; it could be close to ongoing and future work to
  verify stack safety on capability machines, e.g. based on Cerise -- discuss
  together?)
%
\item \emph{Shadow stacks}. Like stack canaries, shadow stacks are
  ``probabilistic techniques'' in that they ``restrict the flexibility available
  in creating gadget chains'' (Shanbhogue et al.). This technique is solely
  concerned with control-flow integrity, and so closely related to our
  well-bracketed control flow. Nevertheless, and again, it is only an
  approximate technique, and our testing framework would be able to find the
  expected attacks against our security property.
%
\item \emph{Split stacks}. The security claims of split stacks are stronger than
  those of most software countermeasures, i.e., they are meant to guarantee
  their titular code-pointer integrity. They explicitly offer no protections on
  stack data (i.e., integrity and confidentiality), and so restrict themselves
  to well-bracketed control flow. (This is probably closer to our framework than
  most other software techniques, and it seems like it would be easier to model
  as well. However, this is again work based on high-level languages and would
  benefit from a higher level of abstraction.)
%
\item \ldots
%
\end{itemize}
%
Opposed to the above group of software techniques we have hardware-based
protection policies (more in background/technical preliminaries?). Although
programs must effectively leverage the protection mechanisms offered by the
hardware, the distinction between those protections and the program logic itself
is much cleaner: it is fairly simple to separate the use of the security
features in the hardware (and their effects in program code) from regular
program code. They also tend to aspire to offer complete protection against
entire classes of attacks. Both aspects make this family of techniques a better
fit for illustrating and showcasing our techniques.
%
\\
%
CHERI and lightweight formal methods?
%
Questionably that they are strictly more realistic in the sense that it is very
costly or requires special sophisticated/experimental types of capability not
available/perhaps not very feasible to implement.
%
Problems of adapting this work to capability machines: security semantics tightly
coupled to regular machine semantics and to a complex calling convention, with
more complex side conditions...
%
\\
%
Why favor micro-policies? Their design is more flexible and arguably more
general than capability machines (of course, they pay a performance price for
this). This generality and ease of programming make them good candidates for an
exploration the design space of stack protection policies and proof of concept
implementations. On the practical side, there is a number of existing policies
available to examine (not just lazy policies!) --- and we find how they satisfy
our properties, how they do not, and errors in some of them, and see how to
correct them. Lazy enforcement is particularly novel, but not the only
possibility. This additional breadth is beneficial for the proof of concept
stage.
%
\\
%
Regarding capability machines, we know that most designs based on capability
machines do not satisfy our properties (or do so incurring significant costs),
and that fixes are not trivial and involve new types of capabilities (in a
sense, are they any more ``realistic?'' Only the latest Cerise paper would seem
to satisfy our properties, is directly influenced by previous versions of this
work, and is a reasonable target for ongoing/further study -- but this is not
easy, and even the author(s) estimate it would be a significant amount of work,
especially full proofs (references, communications, etc.).
\rb{(+SNA) Discuss the degree in which the various papers satisfy the
  properties\ldots and the degrees to which they \emph{aim to}. E.g. originally
  they don't talk about confidentiality. Do they have callee integrity? Maybe
  they aren't thinking about it? (This kind of discussion is a good motivation
  for the formal properties. Also related to the hierarchy. And: how to convey
  that the latest paper draws inspiration directly from this work?}
%
\\
%
\ldots
%
}
\rb{(+SNA) Any interesting tables comparing specimens in the menagerie?}
\rb{(+SNA) A general multi-level extension of the framework would need to model
  multiple source languages. Among other things, the stack is the meeting place
  of all sorts of different language abstractions! One of the advantages of the
  single-level model is that it lets us be agnostic about the language. (On the
  other hand, it is likely that a single source and target mediated by the
  compiler suffice to model many existing techniques, coming e.g. from systems
  programming and C-like languages.}

\paragraph*{Limitations}

%Our concurrency model is fairly
%simplistic, assuming a fixed number of threads each with its own dedicated processor.
We model memory-safe stack objects, but not a heap. Regions outside of
stacks can be used however the compiler likes, including as a heap, but no protection is
built in and our properties assume that if a pointer to a stack object is stored there,
it is permanently compromised.

Our properties are termination insensitive: in order to support enforcement mechanisms
that failstop rather than execute dangerous code, the properties must treat failstops
as invisible to the attacker. We extend this insensitivity to all errors for simplicity.
This is consistent with our treatment of properties that specify the state after a return,
in that a callee that diverges for any reason will never reach the return, and will fulfill
the property vacuously.
%
\rb{Limitations in the introduction or later? Orthogonality of the heap, morally
  similar interesting setups on the stack? Termination sensitivity and
  capability machine semantics?}

%%%

\rb{Connect this (novel characterization?) to the shortcomings of previous work (later!). I'd give at least a quick
  explanation of what the various properties roughly entail in practice (e.g.,
  secrecy of private data, etc.). The comment about the single extension of
  exceptions (still in intro) seems disconnected from the rest.}
