\subsection{The Call Stack and Its Security}

Computer programming relies on functions (or subroutines, procedures, methods, etc.)
as a foundational abstraction. Functions are units of computation that
can call one another to realize larger computations.
%
At a low level, a function activation comprises its own data, as
well as information about its \emph{caller} function, to which it must return.
The \emph{(call) stack} is the fundamental data structure charged with realizing
this abstraction. From a security perspective, attacks on the stack are really attacks
on the fundamental functional abstraction itself, and are therefore every bit as
pervasive.

Indeed, the call stack is a perennial target for low-level attacks.
%
The most recent release of the authoritative CWE Top 25
Most Dangerous Software Weaknesses
list\footnote{\url{https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html}}
shows general classes of vulnerabilities closely related to the stack
%% \rb{(though not exclusively)}
consistently at and near the top, e.g., \#1 (CWE-787, Out-of-bounds Write), \#5 (CWE-125, Out-of-bounds Read) or \#7 (CWE-416, Use After Free).
%
Moreover, many other types of faults involve some kind of control or data flow
using data stored in the stack \cite{DBLP:conf/raid/VeendCB12,
  DBLP:conf/sp/SzekeresPWS13,
  DBLP:conf/sp/HuSACSL16}.\footnote{\url{https://github.com/Microsoft/MSRC-Security-Research/blob/master/presentations/2019_02_BlueHatIL/}}\footnote{\url{https://www.chromium.org/Home/chromium-security/memory-safety/}}

The variety in attacks on the stack is mirrored by the 
software and hardware protections that aim to prevent them,
%
including stack canaries~\cite{Cowan+98},
bounds checking~\cite{NagarakatteZMZ09,NagarakatteZMZ10,DeviettiBMZ08},
split stacks~\cite{Kuznetsov+14},
shadow stacks~\cite{Dang+15,Shanbhogue+19},
capabilities~\cite{Woodruff+14,Chisnall+15,SkorstengaardLocal,SkorstengaardSTKJFP,Georges22:TempsDesCerises},
and hardware tagging~\cite{DBLP:conf/sp/RoesslerD18}.

Of these mechanisms, many are fundamentally ill-suited for offering formal guarantees,
as they aim to impede attackers but cannot provide universal protection. Stack canaries,
for instance, aim to reduce the ability of attackers to find gadgets, not to categorically
rule out attacks. Others may be amenable to formalization but do not offer it.
The Cerise work of Skorstengaard et al. \cite{SkorstengaardSTKJFP} and
Georges et al. \cite{Georges22:TempsDesCerises} is so far the sole line of work
to offer (various) stack safety formalizations.

Meanwhile, Roessler and DeHon \cite{DBLP:conf/sp/RoesslerD18} present an array of tag-based
micro-policies for stack safety, at least some of which should be amenable to making
formal guarantees. Among these is their ``Lazy Tagging and Clearing'' \(LTC\) micropolicy,
which is is peculiar in that function activations may write into one another's stack frames,
as long as the data cannot be accessed afterward. As a result, \(LTC\) definitely would not
fulfill a tag-based adaptation Georges et al.'s state-of-the-art property.
\rb{(Do we explain why anywhere?)}
Roessler and DeHon themselves do not claim that it intends to enforce stack safety,
only an approximation.

We disagree. \(LTC\) does not always protect individual addresses on the stack, but it aims
to prevent one function activation from interfering with another's behavior---to protect
the functional abstraction. We argue that a formal characterization of \(LTC\)'s protections
should fall under the umbrella of stack safety.

In this work, we propose such a characterization, built from first principles
in the hopes that it will be broadly applicable, and demonstrate
that it can distinguish between correct and flawed versions of Roessler and DeHon's
micro-policies. We use the formal tools of language-based
security~\cite{sabelfeld2003language}, decomposing stack safety into a family of
properties describing
the {\em integrity} and {\em confidentiality} of the callerâ€™s local state
and the callee's behavior during the callee's execution, plus the control-flow protection
of {\em well-bracketed control flow}~\cite{SkorstengaardSTKJFP} (\(\wbcf\)).

The structure of our properties enables them to be easily extended to systems with
sophisticated features such as callee-save registers, argument-passing on the stack,
and tailcall-elimination. We likewise extend \(LTC\) to protect these features, and
test the extended micro-policy. We find that, apart from the extensions, \(LTC\)
is flawed in a way that undermines integrity and confidentiality, and we correct
this flaw.

\paragraph{Towards a Formal Property for Stack Safety}

%Security mechanisms can be brittle, successfully eliminating one attack while leaving room for
%other, similar attacks. To avoid this, we seek formal properties of safe behavior that can be proven
%or tested. Such properties become the specification against which enforcement can be validated;
%even enforcement mechanisms that do not fulfill a property benefit from the ability to articulate
%\emph{why} they fail.

Most security properties are described at the level of a high-level programming language,
and translated to the target-level via a secure compiler. Stack safety cannot
be defined in this way, as the abstraction is completely transparent in most source languages.
(Contrast Azevedo de Amorim et al.'s \cite{DBLP:conf/post/AmorimHP18} work on heap safety,
which is broadly consistent across language semantics, and therefore
amenable to a very general high-level approach.)
But it is not satisfying as a low-level property; at the level of the ABI, the
specification of a well-behaved stack is minimal. It is not concerned with such
questions as whether a caller's frame should be readable or writable to its callee,
leaving those concerns to be determined by a high-level language built atop the stack.

For instance, the current state-of-the-art stack-safety specification from Georges et al.
\cite{Georges22:TempsDesCerises} supposes a machine with only straightforward call-and-return
control flow, and therefore defines {\em Well-bracketed Control Flow} (WBCF) under the assumption that
a callee should always return to its caller. But, in the presence of tail-call elimination, a
return from a callee to a distant ancestor is perfectly reasonable. Related, their predecessor
Skorstengaard et al. \cite{SkorstengaardSTKJFP} made no mention of confidentiality, even though
their enforcement mechanism did protect the confidentiality of the caller (not the callee.)

These two cases represent two dimensions of generality that make stack safety difficult to
define as a single, universal property: what constitutes safe behavior may differ between
systems that support different features, and different types of security may be more or less
desirable depending on context.

We are not attempting to present a universal definition of stack safety for all systems.
Rather, we define the stack safety of a single, fairly realistic system (one with common
features such as memory arguments and tailcall elimination), decomposed into
(1) a lightweight model of the system and its security-relevant features, from which we
derive the integrity, confidentiality, and control-flow requirements of each call and
return, (2) the application of that model to a particular target system, and (3)
the formal criteria for integrity, confidentiality, and control flow
to obey the requirements. This decomposition can be thought of as a step toward
a universal definition, in that the definitions in (3) capture fundamental
notions of security that can then be applied flexibly to other systems by varying
the model in (1) and (2).

To address the second class of generality, we present a total of five core properties:
\(\wbcf\), caller integrity (\(\clri\)), caller confidentiality (\(\clrc\)),
callee integrity (\(\clei\)), and callee confidentiality (\(\clec\)). These are defined
formally in \cref{sec:props}. They are related to one another as seen in
\cref{fig:propertydiagram}: \(\clei\) subsumes \(\clrc\) and \(\clec\) subsumes
\(\clri\), but otherwise the properties are orthogonal. We further define two
important combinations of properties: full stack safety \(\textnormal{\sc FSS}\),
and caller safety \(\textnormal{\sc ClrS}\). Of these, most existing concepts of
stack safety correspond to either \(\wbcf\) or \(\textnormal{\sc ClrS}\), which are
concerned with the basic guarantees that the caller recieves during the call, while
\(\textnormal{\sc FSS}\) is a natural extension that enforces a higher-level concept
of a correct interface between caller and callee. \sna{Blah. Needs work.}

To validate our formal characterization, we use these
properties to test and improve an existing enforcement mechanism, the
{\em stack safety micro-policies} of Roessler and DeHon~\cite{DBLP:conf/sp/RoesslerD18}, re-implemented
in the Coq proof assistant on top of a \rb{formal} RISC-V specification.  We
use QuickChick~\cite{Denes:VSL2014,Pierce:SF4}, a property-based testing
tool for Coq, to generate random programs and check
that Roessler and DeHon's micro-policies correctly detect the ones that
attempt to violate one of our properties. Furthermore, we
check that the testing framework is able to generate counterexamples
that violate our properties but are \emph{not} halted by incorrect
variants of the enforcement mechanisms, including ones that we accidentally created
while implementating the micro-policy and ones that we
intentionally crafted to increase our confidence in the effectiveness
of our testing.
%
\rb{This and the following paragraph could start more generally (we need to
  answer the question of why these experiments, what is their interest), and
  probably motivate the use of PBT (experiment results below show there's
  benefit in them!) and, somewhere at least, talk about other points in the
  spectrum.}

We find that Roessler and DeHon's \emph{Lazy Tagging and Clearing}
violates the temporal aspect of confidentiality in
cases where data can leak across repeated calls to the same callee,
and also violates integrity if the leak uses the caller's frame. We
propose a variant of {\em Lazy Tagging and Clearing} that testably enforces
confidentiality, albeit at some performance cost.
%
\rb{Anything to add from personal communications? More details later? Shows
  these things are very hard to get right -- like the latest work on Cerise,
  also motivated by this very work.
\rb{(+SNA) At the very least, these models are subtle and getting them right,
  and describing them unambiguously, is hard without a framework like this.}
}

\subsection{Contributions}

In sum, we offer the following contributions:

\begin{itemize}
\item We formalize permissive stack confidentiality and integrity properties,
  which are parameterized over a notion of external
  observation, and are violated only if accessing secrets or overwriting
  data causes a visible change in system behavior.
\item We instantiate these definitions with a realistic
  system with features such as argument passing
  on the stack, callee-saves registers, and tail-call elimination.
  Our model is modular enough that adding these features is straightforward.
\item Our formalization of well-bracketed control flow in the presence of tail-call
  elimination \ifexceptions and exceptions \fi is a novelty over existing models.
\item We use property-based random testing to validate the relationship between
  our properties and micro-policies.
\end{itemize}

Our artifact contains Coq formalizations of our properties for illustrative purposes
as well as their testing implementation. There are no proofs---we use primarily Coq for the
QuickChick library and to ensure that the formalizations are unambiguous.
