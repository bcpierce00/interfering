\subsection{The Call Stack and Its Security}

\rb{A.K.A. motivation}

Computer programming at any scale relies on \emph{functions} (variously known as
subroutines, procedures, methods, etc.) as a \emph{foundational abstraction} to
structure programs into building blocks representing units of computation that
can \emph{call} one another to create larger computations.
%
At a low level, a function call comprises its own data (private or shared), as
well as information about its \emph{caller} and \emph{callee} functions. The
runtime must keep track of the local contexts of all function activations
at any given time; the \emph{fundamental data structure} charged with realizing
this abstraction is the \emph{(call) stack}. But at the level of the ABI
\sna{Do we need to unpack the acronym ABI?}, the specification of a well-behaved
stack is minimal. It is not concerned with such questions as whether a caller's
frame should be readable or writable to its callee, leaving those concerns
to be determined by a high-level language built atop the stack.

The correct execution---and the security!---of a program is contingent on all of
its functions properly implementing the intended abstraction by means of a careful use
of the call stack. Be it accidental or intentional, incorrect management of the
stack is at the root of many faults whose effects range from (rarely)
innocuous to (usually) catastrophic.
%
From a security perspective, attacks on the stack (say, from a malicious
function that chooses to abuse its access to the contents of this data
structure) are as fundamental, varied and pervasive as the functional
abstraction itself.
%

%% \rb{\textbf{The call stack and its security.} Maybe a few opening words to set
%%   the stage and bring two things to the front: (1) functions and subroutines as
%%   fundamental building blocks of any kind of structured programming; and (2) the
%%   stack as the natural abstraction to manage these in a computer. And also maybe
%%   a little bit more about the width, the gravity and the \emph{foundational
%%   nature} of attacks on the stack, which the sentence below touches on
%%   summarily.
%% \rb{(+SNA) Connection to functions (and adversarial code?). Attacks on the stack
%%   are also attacks on this fundamental abstraction (functions, subroutines,
%%   procedures, methods, however you call them)}
%% }

Indeed, the call stack is a perennial target for low-level attacks, leading to
dire consequences, from leakage and corruption of private stack data
to control-flow hijacking.
%
The most recent release of the authoritative CWE Top 25
Most Dangerous Software Weaknesses
list\footnote{\url{https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html}}
shows general classes of vulnerabilities closely related to the stack \rb{(though not exclusively)}
consistently at and near the top, e.g., \#1 (CWE-787, Out-of-bounds Write), \#5 (CWE-125, Out-of-bounds Read), \#7 (CWE-416, Use After Free) or \#11 (CWE-476, NULL Pointer Dereference).
%
Moreover, many other types of faults involve some kind of control or data flow
using data stored in the stack \rb{cf. Eternal war in memory, Google/Microsoft
  memory safety statistics, etc.}.
\sna{Trying to think how to make the case that these CWEs are about the stack, since they are
  primarily described as memory attacks.}
%
To foil such attacks, a menagerie of
software and hardware protections have been proposed,
%
including stack canaries~\cite{Cowan+98},
bounds checking~\cite{NagarakatteZMZ09,NagarakatteZMZ10,DeviettiBMZ08},
split stacks~\cite{Kuznetsov+14},
shadow stacks~\cite{Dang+15,Shanbhogue+19},
capabilities~\cite{Woodruff+14,Chisnall+15,SkorstengaardLocal,SkorstengaardSTKJFP,Georges+21},
and hardware tagging~\cite{DBLP:conf/sp/RoesslerD18}---we discuss these in more
detail in \cref{XXX}.
  \ifaftersubmission\apt{Mostly from
  nick; there could be more}\bcp{Yes, going back to MIT days---we should
  include several more of these, if only to give readers the impression that
this is a well-studied mechanism (so formalizing its protections is
useful).}
\fi
%
\rb{Broad enough? Do we want to add more techniques?}
\sna{I think this is plenty unless there's a really major thing we're forgetting.}
%
Yet despite this wealth of potential solutions, the stack remains a central
security concern.

\paragraph{Formal Properties}

Security mechanisms designed to prevent a certain attack can be brittle---successfully
eliminating the attack as it exists at the time of publication, but leaving room for attackers
to find new, similar attacks.
%
%% \rb{And so the cat-and-mouse game continues.}
%
To mitigate this risk, we claim that mechanisms should aim to enforce \emph{formal
properties} of safe behavior that can be proven or tested. Such properties become the
\emph{specification} against which enforcement can be validated; even enforcement mechanisms that do
not fulfill a property benefit from the ability to articulate \emph{why} they fail.
%
%% \rb{Good stuff! There is some overlap between this discussion and the opening
%%   motivation, maybe we could restructure things a bit so that those threads are
%%   unified?}
%
Our work is focused on the creation of such properties for stack safety.

\subsection{Related Work}

The protections offered by stack protection mechanisms are commonly described by giving
concrete examples of attacks that they can prevent---corruption of return
addresses, buffer overflows, use of uninitialized variables, etc.---leaving
a more formal characterization to the reader's intuition.
%
To make these notions more precise, we review a selection of specimens from the
menagerie and begin to consider the difficulties involved in specifying and
verifying the protections they offer.
%
For an assessment of these methods in the context of our stack security
framework, see \cref{XXX}.

At the highest level, we can classify techniques into two large groups depending
on whether their protection is furnished at the software or the hardware level.
Up to date, most proposals, including all commonly deployed practical
protections, are implemented in software, so we start by considering exemplars
from this first group.

\subsubsection{Software Techniques}

\paragraph{Stack Canaries}
%
Canaries are special values inserted by the caller at certain points of the
stack and checked for corruption on return, primarily for protection against
some classes of control-flow hijacking (i.e., seeking to overwrite the caller's
return address through a buffer overflow that would also overwrite the canary
detectably).
%
Observe that this is a \emph{hardening} technique that increases the difficulty
of some control-flow attacks on the stack, but can never provide any absolute
guarantees on control flow integrity; neither does it do anything to protect
function data stored in the stack.
%
Also interestingly, a successful attack is not detected the moment it takes
place, instead action is \emph{deferred} until the attacker returns control to
the caller.

\paragraph{Shadow Stacks}
%
A shadow stack is a mirror image of the control-relevant parts of the stack,
maintained by the program to attempt to detect attempts to hijack its control
flow. They are similar in purpose and can be seen as related to stack canaries.
Like canaries, they offer hardened but not guaranteed, deferred protection
against control-flow attacks, ``restrict the flexibility available in creating
gadget chains'' \cite{Shanbhogue+19}, and do not cover the data-relevant regions
of the stack.
%
\rb{Could probably find other variants (e.g. SmashGuard, on hardware?), but this
  seems to be the basic idea. Some of those require OS support, etc.}

\paragraph{Bounds Checking}
%
Under a bounds checking discipline, all the pointers in a program are extended
with some disjoint metadata, and these are combined to gate memory accesses,
usually with the objective of enforcing some form of \emph{memory
safety} \rb{(relate this to the basic high-level concepts and types of attacks
we want to consider: control flow, some integrity and confidentiality?)}.
%
Compared to stack canaries and shadow stacks, bounds checking is eminently
a \emph{high-level} technique, designed with a particular programming language
in mind and implemented through a \emph{secure compiler} \cite{} that performs
the necessary code transformations. Also unlike those techniques (which make few
assumptions on callee code), it offers little to no protection
against \emph{adversarial low-level} code that is not constrained to obey the
bounds checking discipline.
%
\rb{Some related work, e.g. HardBound, is inspired by this but more closely
  related to hardware capabilities.}

\sna{Would HardBound warrant a section in the hardware techniques section,
  for hardware-accelerated bounds checking (that is not capability-based)?}

\paragraph{Split Stacks}
%
Code-pointer integrity seeks to prevent control-flow hijacking attacks by
splitting the program memory, including the stack, into a regular region and a
safe region; objects that require protection are placed in the latter and
all accesses to them protected by static or dynamic checks.
%
Like shadow stacks, bounds checking is a high-level technique designed to
protect code written in a high-level language, but it is designed to
offer protection under a stronger threat model that also considers the presence
of untrusted code. As with most other software-based methods, it purports to
protect exclusively the control-relevant parts of the stack, making no claims
about its data-relevant parts.

\subsubsection{Hardware Techniques}

In addition to the many software-based techniques developed to provide greater
degrees of protection to the stack, often incurring a significant performance penalty,
some proposals have turned to specialized hardware features to offset those
costs and attempt to offer greater levels of protection.

We focus in particular on two families of hardware mechanisms: capability machines
and tag-based reference monitors. Both types of system move beyond simply
offering hardware acceleration for software-based techniques, offering hardware
primitives for both memory and control-flow enforcement that can offer a degree
of protection even with minimal cooperation from the code.
%
\rb{Something about how realistic/practical these alternatives are? Are we
  selecting partly based on prototypes, etc.?}

\paragraph{Capabilities}
%
\rb{(There is plenty of variety here, should we focus on the Cerise-and-friends
  (CHERI-adjacent) work exclusively?)}

\sna{If we have good examples of other capability systems, we should absolutely
  talk about them. No need to privilege CHERI.}
%
Capability machines can represent and manipulate
unforgeable tokens of authority over specific regions of
memory using a combination of dedicated out-of-band memory and
specialized ISA instructions.
%
The most prominent contemporary representative of this long line of work is
CHERI \cite{}, a modern architecture designed to provide efficient fine-grained
memory protection and compartmentalization.
%
Previous work has uses these principles in simplified models to implement
\emph{secure calling conventions} for the call
stack \cite{}. Those conventions can be seen as combining the
protections of bounds-checking with software-based methods of control-flow protection.
%
They are closely related \rb{too strong?} to this work; we discuss them in more
detail in \cref{XXX}.
%

\paragraph{Micro-Policies}
%
\rb{(This partly overlaps with the technical preliminaries, try to offer a quick
  synthesis here.)}
%
Micro-policy machines are a family of tagged architectures that decorate
addressable memory and registers with arbitrary metadata tags, and extend the
processor with a programmable hardware monitor that uses custom rules on
metadata tags to implement many different kinds of security policies.
%
This flexibility can be harnessed to implement a wide array of stack protection policies with relative ease, covering and going beyond the capabilities \rb{word choice?} of the various software-based techniques \cite{} \rb{as demonstrated by}.
%
These policies comprise very general forms of \emph{lazy enforcement}, which can tolerate
potential but harmless violations \rb{the system programmer's motto: ``trust me,
  I know what I'm doing''} while still detecting them if and when their effects
become tangible.
%
Micro-policies are one of the centerpieces of our technical development; we
present them in more detail in \cref{XXX}.

\subsection{A Language-Based View of Stack Safety}

We begin to see that the security of the call stack and its contents is not
clearly defined. Different protection mechanisms aim to protect the stack
in fundamentally different ways, each offering a \emph{unique}, \emph{implicit}
specification of the meaning of ``stack safety.'' These specifications
may be more or less compatible with the needs of a given high-level language.
Moreover, different protections operate under different threat models, further
complicating their comparison and the assessment of the safeguards they
effectively offer their clients---the programs themselves.
It would be far preferable to have a \emph{standard}, \emph{explicit} specification.
Only a handful of works have offered any explicit specification.

Stack safety is challenging to specify in full generality, because the stack is
fundamentally an architecture-specific construct.
(Contrast Azevedo de Amorim et al.'s \cite{DBLP:conf/post/AmorimHP18} work on heap safety,
which is broadly consistent across architectures and language semantics, and therefore
amenable to a very general approach.)
The desired behavior of the stack varies based on ISA, calling convention,
and the features of whichever programming language originated the code.
%
For instance, the current state-of-the-art stack-safety specification from Georges et al.
\cite{Georges22:TempsDesCerises} supposes a machine with only straightforward call-and-return
control flow, and therefore defines {\it Well-bracketed Control Flow} (WBCF) under the assumption that
a callee should always return to its caller. But, in the presence of tail-call elimination, a
return from a callee to a distant ancestor is perfectly reasonable.

In this work, we propose an explicit specification, built from first principles
in the hopes that it will be widely applicable, and demonstrate that it supports
an enforcement mechanism that does not yet have one.
We use the formal tools of language-based
security~\cite{sabelfeld2003language}, decomposing stack safety into
the {\em integrity} and {\em confidentiality} of the callerâ€™s local state
and the callee's behavior during the callee's execution, plus the control-flow protection
of {\em well-bracketed control flow}~\cite{SkorstengaardSTKJFP} (\(\wbcf\)).
\ifexceptions
We also extend WBCF to a setting with exceptions,
in which there may be multiple points at which a callee can ``return.''
\fi
%
We treat stack safety as multiple properties, rather than one multi-faceted property, because
not all enforcement mechanisms attempt to implement all aspects of stack safety. Some focus
exclusively on control flow, some enforce integrity but not confidentiality, and many
focus on the caller over the callee.
%
\rb{Return to this after extended discussion? Forward ref?}
%
This gives us a total of five core properties: \(\wbcf\),
caller integrity (\(\clri\)), caller confidentiality (\(\clrc\)),
callee integrity (\(\clei\)), and callee confidentiality (\(\clec\)), defined formally
in \cref{sec:props}.
%

We are not attempting to create a universal definition of stack safety for all systems.
Rather, we define the stack safety of a single, fairly realistic system, decomposed into
(1) a lightweight model of the system and its security-relevant features, from which we
derive the integrity, confidentiality, and control-flow requirements of each call and
return, (2) the application of that model to a particular target system, and (3)
the formal criteria for integrity, confidentiality, and control flow
to obey the requirements. This decomposition can be thought of as a step toward
a universal definition, in that the definitions in (3) capture fundamental
notions of security that can then be applied flexibly to other systems by varying
the model in (1) and (2).
%
\rb{FIXME: Contrast some universal definitions (or a parametric framework) with
  the concrete instance we study, again with its interest properly motivated.
  (Coming in key ideas?) No ``gold standard''?}

\sna{Not sure what your FIXME means exactly. Can you elaborate?}

To demonstrate the utility of our formal characterization, we use these
properties to validate and improve an existing enforcement mechanism, the
{\em stack safety micro-policies} of Roessler and DeHon~\cite{DBLP:conf/sp/RoesslerD18}, re-implemented
in the Coq proof assistant on top of a \rb{formal} RISC-V specification.  We
use QuickChick~\cite{Denes:VSL2014,Pierce:SF4}, a property-based testing
tool for Coq, to generate random programs and check
that Roessler and DeHon's micro-policies correctly detect the ones that
attempt to violate one of our properties. Furthermore, we
check that the testing framework is able to generate counterexamples
that violate our properties but are \emph{not} halted by incorrect
variants of the enforcement mechanisms, including ones that we accidentally created
while implementating the micro-policy and ones that we
intentionally crafted to increase our confidence in the effectiveness
of our testing.
%
\rb{This and the following paragraph could start more generally (we need to
  answer the question of why these experiments, what is their interest), and
  probably motivate the use of PBT (experiment results below show there's
  benefit in them!) and, somewhere at least, talk about other points in the
  spectrum.}

We find that Roessler and DeHon's \emph{Lazy Tagging and Clearing}
violates the temporal aspect of confidentiality in
cases where data can leak across repeated calls to the same callee,
and also violates integrity if the leak uses the caller's frame. We
propose a variant of {\em Lazy Tagging and Clearing} that testably enforces
confidentiality, albeit at some performance cost.
%
\rb{Anything to add from personal communications? More details later? Shows
  these things are very hard to get right -- like the latest work on Cerise,
  also motivated by this very work.
\rb{(+SNA) At the very least, these models are subtle and getting them right,
  and describing them unambiguously, is hard without a framework like this.}
}

\subsection{Contributions}

In sum, we offer the following contributions:

\begin{itemize}
\item We formalize permissive stack confidentiality and integrity properties,
  which are parameterized over a notion of external
  observation, and are violated only if accessing secrets or overwriting
  data causes a visible change in system behavior.
\item We instantiate these definitions with a realistic
  system with features such as argument passing
  on the stack, callee-saves registers, and tail-call elimination.
  Our model is modular enough that adding these features is straightforward.
\item Our formalization of well-bracketed control flow in the presence of tail-call
  elimination \ifexceptions and exceptions \fi is a novelty over existing models.
\item We use property-based random testing to validate the relationship between
  our properties and micro-policies.
\end{itemize}

Our artifact contains Coq formalizations of our properties for illustrative purposes
as well as their testing implementation. There are no proofs---we use primarily Coq for the
QuickChick library and to ensure that the formalizations are unambiguous.
%
\rb{Will have another look after the full pass.}
