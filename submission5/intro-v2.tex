\subsection{The Call Stack and Its Security}

Computer programming relies on functions (or subroutines, procedures, methods, etc.)
as a foundational abstraction. Functions are units of computation that
can call one another to realize larger computations.
%
At a low level, a function activation comprises its own data, as
well as information about its \emph{caller} function, to which it must return.
The \emph{(call) stack} is the fundamental data structure charged with realizing
this abstraction. From a security perspective, attacks on the stack are really attacks
on the fundamental functional abstraction itself, and are therefore every bit as
pervasive.

Indeed, the call stack is a perennial target for low-level attacks.
%
The most recent release of the authoritative CWE Top 25
Most Dangerous Software Weaknesses
list\footnote{\url{https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html}}
shows general classes of vulnerabilities closely related to the stack
%% \rb{(though not exclusively)}
consistently at and near the top, e.g., \#1 (CWE-787, Out-of-bounds Write), \#5 (CWE-125, Out-of-bounds Read) or \#7 (CWE-416, Use After Free).
%
Moreover, many other types of faults involve some kind of control or data flow
using data stored in the stack \cite{DBLP:conf/raid/VeendCB12,
  DBLP:conf/sp/SzekeresPWS13,
  DBLP:conf/sp/HuSACSL16}.\footnote{\url{https://github.com/Microsoft/MSRC-Security-Research/blob/master/presentations/2019_02_BlueHatIL/}}\footnote{\url{https://www.chromium.org/Home/chromium-security/memory-safety/}}

The variety in attacks on the stack is mirrored by the 
software and hardware protections that aim to prevent them,
%
including stack canaries~\cite{Cowan+98},
bounds checking~\cite{NagarakatteZMZ09,NagarakatteZMZ10,DeviettiBMZ08},
split stacks~\cite{Kuznetsov+14},
shadow stacks~\cite{Dang+15,Shanbhogue+19},
capabilities~\cite{Woodruff+14,Chisnall+15,SkorstengaardLocal,SkorstengaardSTKJFP,Georges22:TempsDesCerises},
and hardware tagging~\cite{DBLP:conf/sp/RoesslerD18}.

Of these mechanisms, many are fundamentally ill-suited for offering formal guarantees,
as they aim to impede attackers but cannot provide universal protection. Shadow stacks,
for instance, aim to ``restrict the flexibility available in creating gadget chains''
\cite{Shanbhogue+19}, not to categorically
rule out attacks. Other mechanisms are stronger, but relatively few formally state their guarantees.
The Cerise work of Skorstengaard et al. \cite{SkorstengaardSTKJFP} and
Georges et al. \cite{Georges22:TempsDesCerises} is so far the sole line of work
to offer (various) stack safety formalizations.

Meanwhile, Roessler and DeHon \cite{DBLP:conf/sp/RoesslerD18} present an array of tag-based
micro-policies for stack safety, at least some of which should be amenable to making
formal guarantees. Among these is their ``Lazy Tagging and Clearing'' \(LTC\) micropolicy,
which is is peculiar in that function activations may write into one another's stack frames,
as long as the data cannot be accessed afterward. As a result, \(LTC\) definitely would not
fulfill a tag-based adaptation Georges et al.'s state-of-the-art property.

We believe that, nevertheless, \(LTC\) enforces stack safety.
It does not always protect individual addresses on the stack, but it aims
to prevent one function activation from interfering with another's behavior---to protect
the functional abstraction. We argue that a formal characterization of \(LTC\)'s protections
should fall under the umbrella of stack safety.

In this work, we propose such a characterization, built from first principles
in the hopes that it will be broadly applicable, and demonstrate
that it can distinguish between correct and flawed versions of Roessler and DeHon's
micro-policies. We use the formal tools of language-based
security~\cite{sabelfeld2003language}, decomposing stack safety into a family of
properties describing
the {\em integrity} and {\em confidentiality} of the callerâ€™s local state
and the callee's behavior during the callee's execution, plus the control-flow protection
of {\em well-bracketed control flow}~\cite{SkorstengaardSTKJFP} (\(\wbcf\)).

The structure of our properties enables them to be easily extended to systems with
sophisticated features such as callee-save registers, argument-passing on the stack,
and tailcall-elimination. We likewise extend \(LTC\) to protect these features, and
test the extended micro-policy. We find that, apart from the extensions, \(LTC\)
is flawed in a way that undermines integrity and confidentiality, and we correct
this flaw.

\paragraph{Towards a Formal Property for Stack Safety}

Security mechanisms can be brittle, successfully eliminating one attack while leaving room for
other, similar attacks. To avoid this, we seek formal properties of safe behavior that can be proven
or tested. Such properties become the specification against which enforcement can be validated;
even enforcement mechanisms that do not fulfill a property benefit from the ability to articulate
\emph{why} they fail.

We take the view that security properties should be motivated by security requirements,
and flexible enough to support various sets of security requirements depending on the
goals of the system that they validate.
Following this reasoning, our vision of stack safety is as a collection of properties
describing the security needs of a system with regard to its functional abstractions.
While the stack still plays a key role, our stack safety is about functions. The most
dramatic consequence of this is that we treat registers as part of a function activation's
state, and hold them to the same protection requirements as stack memory.

Flexibility is especially important for stack safety.
%
Most security properties are described at the level of a high-level programming language,
and translated to the target-level via a secure compiler. Stack safety cannot
be defined in this way, as the abstraction is completely transparent in most source languages.
(Contrast Azevedo de Amorim et al.'s \cite{DBLP:conf/post/AmorimHP18} work on heap safety,
which is broadly consistent across language semantics, and therefore
amenable to a very general high-level approach.)
%
But it is not satisfying as a low-level property; at the level of the ABI, the
specification of a well-behaved stack is minimal. The ABI is not concerned with such
questions as whether a caller's frame should be readable or writable to its callee,
leaving those concerns to be determined by a high-level language built atop the stack.
These are high-level security questions.

For instance, the current state-of-the-art stack-safety specification from Georges et al.
\cite{Georges22:TempsDesCerises} supposes a machine with only straightforward call-and-return
control flow, and therefore defines {\em Well-bracketed Control Flow} (WBCF) under the assumption that
a callee should always return to its caller. But, in the presence of tail-call elimination, a
return from a callee to a distant ancestor is perfectly reasonable. Related, their predecessor
Skorstengaard et al. \cite{SkorstengaardSTKJFP} made no mention of confidentiality, even though
their enforcement mechanism did protect the confidentiality of the caller (not the callee.)

These two cases represent two dimensions in which a stack safety definition requires
flexibility: what constitutes safe behavior differs between systems that support different
features, and different contexts have different top-level security requirements.

We are not attempting to present a universal definition of stack safety for all systems,
but we do construct our definition with these dimensions of flexibility in mind.
Our model is decomposed into:
(1) a lightweight model of the system and its security-relevant features, from which we
derive the integrity, confidentiality, and control-flow requirements of each call and
return, (2) the application of that model to a particular target system, and (3)
the formal criteria for the integrity, confidentiality, and control flow
requirements.

We show that we can extend our system to new features by first introducing a simple
example model, and then moving to a more realistic model with multiple new features:
callee-save registers, argument passing on the stack, and tailcall elimination, simply
by refining a few definitions in (1). This becomes the model that we validate.
In \cref{???}, we extend the model further with arbitrary sharing of memory-safe
pointers. Our criteria in (3) cover a total of five core requirements:
\(\wbcf\), caller integrity (\(\clri\)), caller confidentiality (\(\clrc\)),
callee integrity (\(\clei\)), and callee confidentiality (\(\clec\)).
They are related to one another as seen in
\cref{fig:propertydiagram}: \(\clei\) subsumes \(\clrc\) and \(\clec\) subsumes
\(\clri\), but otherwise the properties are orthogonal and can be taken piecemeal
according to the needs of a system.

In particular, many enforcement techniques focus purely on
well-bracketed control flow. Stack canaries aim to prevent certain attacks on the return
address, and shadow stacks with protection (e.g. Return Address Defender \cite{Chiueh2001RAD})
to enforce it completely. Others combine this protection with some degree of memory protection,
chiefly focusing on integrity. Interestingly, Skorstengaard et al. \cite{SkorstengaardSTKJFP}
describe their ``local state encapsulation'' in terms of integrity, but it is equivalent
to the combination of \(\clri\) and \(\clrc\). It is not until Georges et al. \cite{Georges22:TempsDesCerises}
that the Cerise line of work considers confidentiality; they also consider \(\clec\), but not
\(\clei\). \sna{It is really tempting to find a way to take credit for this.}
%
\rb{This is the direct support I can find: ``Following Anderson et al. [2021],
we must distinguish between {\em local state integrity} and {\em local state
confidentiality}.'' + similar discussion in their related work + their novel
claim of adding support for confidentiality properties, thus ``following'' us
\ldots + personal communication?}

%These are defined
%formally in \cref{sec:props}. . We further define two
%important combinations of properties: full stack safety \(\textnormal{\sc FSS}\),
%and caller safety \(\textnormal{\sc ClrS}\). Of these, most existing concepts of
%stack safety correspond to either \(\wbcf\) or \(\textnormal{\sc ClrS}\), which are
%concerned with the basic guarantees that the caller recieves during the call, while
%\(\textnormal{\sc FSS}\) is a natural extension that enforces a higher-level concept
%of a correct interface between caller and callee. \sna{Blah. Needs work.}

Flexibility aside, we show that our properties are useful for their purpose:
distinguishing correct enforcement from incorrect. We use
QuickChick~\cite{Denes:VSL2014,Pierce:SF4}, a property-based testing
tool for Coq, to generate random programs and check that the
stack safety {\em micro-policies} of Roessler and DeHon~\cite{DBLP:conf/sp/RoesslerD18}
correctly detect the ones that attempt to violate one of our properties. Furthermore, we
check that the testing framework is able to generate counterexamples
that violate our properties but are \emph{not} halted by incorrect
variants of the enforcement mechanisms---including the original \(LTC\)!

\subsection{Contributions}

In sum, we offer the following contributions:

\begin{itemize}
\item A novel characterization of stack safety as a collection of properties:
  confidentiality and integrity for callee and caller, and well-bracketed
  control-flow. These can characterize the security requirements of systems
  that support only some portion of stack safety, and are
  parameterized over a notion of external observation, so that they can characterize
  lazy enforcement.
\item An instantiation of these definitions in a realistic
  setting with features such as argument passing
  on the stack, callee-saves registers, and tail-call elimination.
  Our model is modular enough that handling these features is straightforward.
\item The validation, via property-based randomize testing, of tag-based
  stack-safety policies. We find that \emph{Lazy Tagging and Clearing}
  falls short of stack safety, and propose a fix.
\end{itemize}

Our artifact contains Coq formalizations of our properties for illustrative purposes
as well as their testing implementation. There are no proofs---we use primarily Coq for the
QuickChick library and to ensure that the formalizations are unambiguous.
%
\rb{Mention proofs in future work?}

\subsection{Threat Model and Limitations}

When our properties are used to evaluate a system, the threat model will depend on the
details of that system. However, there are some constraints that our design puts on
any system. We must trust that the method of distinguishing security-relevant operations is accurate; if it
involves labels placed on code by a compiler, that means trusting that the compiler placed
those labels correctly. If operations occur that are not recognized, those operations
might not be guaranteed to protect their principals---for instance, an unlabeled call
might not protect the caller's data from the callee. On the flip side, applying an incorrect
label most likely means that the property becomes too strong to be enforced.

Otherwise, we do not assume that the code adheres to any particular
calling convention or implements a source language construct.
In particular, while we are agnostic as to the source
language, we certainly aim to support C, and so any source function might contain undefined
behavior resulting in its compilation to arbitrary machine code. A given enforcement
mechanism may place additional constraints, particularly on the behavior of
call and return sequences. For instance, extant implementations tend to assume
implicitly that callee-saved registers are treated appropriately by whichever compiler
generated their code. Our properties explicitly require them to be treated as belonging
to the caller, which could be enforced by a micro-policy or by a well-behaved compiler.
%
\rb{This last bit about callee-saved registers belonging to the caller is subtle, I think it risks the reader missing the point.}

In general, it is impossible to distinguish buggy machine code from an attacker; in
our examples we will identify one function or another as an attacker, but we do not
require any static division between trusted and untrusted code, and we aim to protect
even buggy code.

This is a strong threat model, but it does omit some important aspects of
security enforcement: in particular, hardware and timing attacks are out of scope, and
we do not address concurrency.
%
\rb{Anything about concurrency in future work, though?}
